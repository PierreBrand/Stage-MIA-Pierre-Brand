{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rd\n",
    "import numpy.linalg as nla\n",
    "import pandas as pnd\n",
    "import sklearn.covariance as sklcov\n",
    "import sklearn.cluster as sklclu\n",
    "import sklearn.metrics.cluster as sklmc\n",
    "import itertools as itt\n",
    "import scipy.cluster.hierarchy as spch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''====================================\n",
    "    Ensemble de modules créés par Pierre\n",
    "    ====================================\n",
    "    \n",
    "    ======================================= ============================================================\n",
    "    Nécessite les bibliothèques suivantes :\n",
    "    --------------------------------------- ------------------------------------------------------------\n",
    "    numpy\n",
    "    matplotlib\n",
    "    numpy.random\n",
    "    numpy.linalg\n",
    "    pandas\n",
    "    sklearn.covariance\n",
    "    sklearn.cluster\n",
    "    sklearn.metrics.cluster\n",
    "    itertools\n",
    "    =============================== ====================================================================\n",
    "        \n",
    "    =============================== ====================================================================\n",
    "    Contient les modules suivants :\n",
    "    ------------------------------- --------------------------------------------------------------------\n",
    "    maybe_useful                    Fonctions peut-être utiles.\n",
    "    for_clus                        Fonctions utiles pour le clustering.\n",
    "    single_fa                       Fonctions d'estimation pour modèles simples.\n",
    "    clus_funs                       Fonctions de clustering.\n",
    "    data_rnr                        Fonctions pour reconstruire et représenter les données.\n",
    "    for_fs                          Fonctions utiles pour la sélection de variables.\n",
    "    mixed_fa                        Fonctions d'estimation pour mixtures de modèles.\n",
    "    simulate                        Fonctions pour simuler des paramètres et des données.\n",
    "    fs_funs                         Fonctions de sélection de variables.\n",
    "    =============================== ====================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions peut-être utiles (MBU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''==========================\n",
    "    Fonctions peut-être utiles\n",
    "    ==========================\n",
    "    \n",
    "    ================================== ====================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- --------------------------------------------------------------------\n",
    "    norme                              Norme L2 d'un vecteur.\n",
    "    angle_oriente                      Angle orienté entre un vecteur de taille 2 et le vecteur (1,0).\n",
    "    rotation                           Matrice de rotation de taille (2,2) associée à un angle.\n",
    "    erreur_Z                           Distance en norme L2 entre deux matrices à 2 colonnes,\n",
    "                                       après avoir rotaté l'une des deux.\n",
    "    orthogonalize                      Orthogonalisation d'une matrice injective.\n",
    "    normalize                          Normalisation des colonnes d'une matrice.\n",
    "    trace                              Trace d'une matrice carrée.\n",
    "    cov_emp                            Matrice de covariance empirique de vecteurs aléatoires i.i.d.\n",
    "    L_knee                             Emplacement du \"genou\" d'un vecteur, si celui-ci se trouve à gauche.\n",
    "    R_knee                             Emplacement du \"genou\" d'un vecteur, si celui-ci se trouve à droite.\n",
    "    R_elbow                            Emplacement du \"coude\" d'un vecteur, si celui-ci se trouve à droite.\n",
    "    L_elbow                            Emplacement du \"coude\" d'un vecteur, si celui-ci se trouve à gauche.\n",
    "    ================================== ====================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norme(x):\n",
    "    '''Norme L2 du vecteur x.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    x : 1-D ndarray,\n",
    "        Vecteur dont on veut calculer la norme.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    norme_x : float,\n",
    "        Norme L2 du vecteur x.\n",
    "    '''\n",
    "    return np.sqrt(x@x)\n",
    "\n",
    "def angle_oriente(x):\n",
    "    '''Angle orienté entre vecteur x et le vecteur (1,0).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    x : 1-D ndarray,\n",
    "        Vecteur non-nul de longueur 2 dont on veut calculer l'angle orienté avec le vecteur (1,0).\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    alpha : float,\n",
    "        Angle orienté entre vecteur x et le vecteur (1,0).\n",
    "    '''\n",
    "    \n",
    "    nx = x/norme(x)\n",
    "    if nx[1] >= 0:\n",
    "        return np.arccos(nx[0])\n",
    "    else :\n",
    "        return -np.arccos(nx[0])\n",
    "\n",
    "def rotation(a):\n",
    "    '''Matrice de rotation de taille (2,2) associée à l'angle a.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    a : float,\n",
    "        Angle dont on veut la matrice de rotation de taille (2,2) associée.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    R : 2-D ndarray,\n",
    "        Matrice de rotation de taille (2,2) associée à l'angle a.\n",
    "    '''\n",
    "    R = np.array([[np.cos(a), np.sin(a)],[-np.sin(a), np.cos(a)]])\n",
    "    return R\n",
    "\n",
    "def erreur_Z(Z1,Z2,a,sym=False):\n",
    "    '''Distance en norme L2 entre la matrice Z1, et le produit de la matrice de rotation associée à l'angle a par la matrice Z2.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Z1 : 2-D ndarray,\n",
    "        Matrice de taille (N,2).\n",
    "    \n",
    "    Z2 : 2-D ndarray,\n",
    "        Matrice de taille (N,2).\n",
    "        \n",
    "    a : float,\n",
    "        Angle avec lequel on veut rotater les lignes de la matrices Z2.\n",
    "    \n",
    "    sym : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, reflète orthogonalement les vecteurs de Z2 sur l'axe des y avant de les rotater.\n",
    "        Mis sur False par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance en norme L2 entre la matrice Z1, et le produit de la matrice de rotation associée à l'angle a par la matrice Z2.\n",
    "    '''\n",
    "    S = np.array([[1,0],[0,1-2*float(sym)]])\n",
    "    R = np.transpose(rotation(a)@S)\n",
    "    RZ2 = Z2@R\n",
    "    return np.sum((Z1-RZ2)**2)\n",
    "\n",
    "def orthogonalize(W):\n",
    "    '''Matrice de même taille que W dont les colonnes sont orthogonales.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice injective à orthogonaliser.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    W_orth : 2-D ndarray,\n",
    "        Matrice de même taille que W dont les colonnes sont orthogonales.\n",
    "    '''\n",
    "    R2 = np.transpose(W)@W\n",
    "    SpR2, P = nla.eig(R2)\n",
    "    R = np.real(P @ np.diag(1/np.sqrt(SpR2)) @ nla.inv(P))\n",
    "    W_2 = W @ R\n",
    "    return W_2\n",
    "\n",
    "def normalize(P):\n",
    "    '''Matrice de même ensemble d'images que P, mais dont les colonnes sont de norme 1.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    P : 2-D ndarray,\n",
    "        Matrice injective à normaliser.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    P_orth : 2-D ndarray,\n",
    "        Matrice de même ensemble d'images que P, mais dont les colonnes sont de norme 1.\n",
    "    '''\n",
    "    P_norms = np.sqrt(np.sum(P**2,axis=0))\n",
    "    D_P = np.diag(1/P_norms)\n",
    "    P2 = P@D_P\n",
    "    return P2\n",
    "\n",
    "def trace(A):\n",
    "    '''Trace de la matrice A.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    A : 2-D ndarray,\n",
    "        Matrice carrée dont on veut calculer la trace.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    tr_A : float,\n",
    "        Trace de la matrice A.\n",
    "    '''\n",
    "    N1,N2 = np.shape(A)\n",
    "    if N1 != N2 :\n",
    "        print('Erreur de dimensions sur A')\n",
    "    else :\n",
    "        return np.sum([A[n][n] for n in range(N1)])\n",
    "\n",
    "def cov_emp(Y):\n",
    "    '''Matrice de covariance empirique des vecteurs de la matrice Y.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice dont les lignes sont des vecteurs aléatoires, supposément indépendants et de même loi, dont on veut calculer la covariance.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance empirique des vecteurs de la matrice Y.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    mu_Y = np.mean(Y,axis=0)\n",
    "    Yc = Y - mu_Y\n",
    "    S = 1/N * np.transpose(Yc) @ Yc\n",
    "    return S\n",
    "\n",
    "def L_knee(y,x=None,alpha=1.0):\n",
    "    '''Emplacement du \"genou\" du vecteur y, si celui-ci se trouve à gauche.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    y : 1-D ndarray,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"genou\".\n",
    "    \n",
    "    x : 1-D ndarray, optional,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"genou\".\n",
    "        Mis par défaut sur np.range(0,N) ou N est la taille de y.\n",
    "    \n",
    "    alpha : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"genou\".\n",
    "        Plus alpha est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"genou\" sera grande, et donc plus le \"genou\" sera pris à droite.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    n_knee : int,\n",
    "        Emplacement du \"genou\" du vecteur y, si celui-ci se trouve à gauche.\n",
    "    '''\n",
    "    N = len(y)\n",
    "    ord_y = np.sort(y)\n",
    "    \n",
    "    if type(x) == type(None) or len(x) != N:\n",
    "        x = np.arange(0,N)\n",
    "    ord_x = np.sort(x)\n",
    "    \n",
    "    #Renormalisation\n",
    "    vert_length = ord_y[-1]-ord_y[0]\n",
    "    horz_length = ord_x[-1]-ord_x[0]\n",
    "    x1_list = np.array([(x-ord_x[0])/horz_length for x in ord_x])\n",
    "    y1_list = np.array([(y-ord_y[0])/vert_length for y in ord_y])\n",
    "    z1_list = alpha*y1_list - x1_list\n",
    "    \n",
    "    n_star = int(np.argmax(z1_list))\n",
    "    return n_star\n",
    "\n",
    "def R_knee(y,x=None,alpha=1.0):\n",
    "    '''Emplacement du \"genou\" du vecteur y, si celui-ci se trouve à droite.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    y : 1-D ndarray,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"genou\".\n",
    "    \n",
    "    x : 1-D ndarray, optional,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"genou\".\n",
    "        Mis par défaut sur np.range(0,N) ou N est la taille de y.\n",
    "    \n",
    "    alpha : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"genou\".\n",
    "        Plus alpha est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"genou\" sera grande, et donc plus le \"genou\" sera pris à gauche.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    n_knee : int,\n",
    "        Emplacement du \"genou\" du vecteur y, si celui-ci se trouve à droite.\n",
    "    '''    \n",
    "    N = len(y)\n",
    "    return N - L_knee(y,x,alpha)\n",
    "\n",
    "def R_elbow(y,x=None,alpha=1.0):\n",
    "    '''Emplacement du \"coude\" du vecteur y, si celui-ci se trouve à droite.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    y : 1-D ndarray,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"coude\".\n",
    "    \n",
    "    x : 1-D ndarray, optional,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"coude\".\n",
    "        Mis par défaut sur np.range(0,N) ou N est la taille de y.\n",
    "    \n",
    "    alpha : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"coude\".\n",
    "        Plus alpha est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"coude\" sera grande, et donc plus le \"coude\" sera pris à gauche.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    n_elbow : int,\n",
    "        Emplacement du \"coude\" du vecteur y, si celui-ci se trouve à droite.\n",
    "    '''\n",
    "    N = len(y)\n",
    "    ord_y = np.sort(y)\n",
    "    \n",
    "    if type(x) == type(None) or len(x) != N:\n",
    "        x = np.arange(0,N)\n",
    "    ord_x = np.sort(x)\n",
    "    \n",
    "    #Renormalisation\n",
    "    vert_length = ord_y[-1]-ord_y[0]\n",
    "    horz_length = ord_x[-1]-ord_x[0]\n",
    "    x1_list = np.array([(x-ord_x[0])/horz_length for x in ord_x])\n",
    "    y1_list = np.array([(y-ord_y[0])/vert_length for y in ord_y])\n",
    "    z1_list = x1_list - alpha*y1_list\n",
    "    \n",
    "    n_star = int(np.argmax(z1_list))\n",
    "    return n_star\n",
    "\n",
    "def L_elbow(y,x=None,alpha=1.0):\n",
    "    '''Emplacement du \"coude\" du vecteur y, si celui-ci se trouve à gauche.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    y : 1-D ndarray,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"coude\".\n",
    "    \n",
    "    x : 1-D ndarray, optional,\n",
    "        Vecteur d'ordonnées dont on veut calculer l'emplacement du \"coude\".\n",
    "        Mis par défaut sur np.range(0,N) ou N est la taille de y.\n",
    "    \n",
    "    alpha : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"coude\".\n",
    "        Plus alpha est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"coude\" sera grande, et donc plus le \"coude\" sera pris à droite.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    n_elbow : int,\n",
    "        Emplacement du \"coude\" du vecteur y, si celui-ci se trouve à gauche.\n",
    "    '''\n",
    "    N = len(y)\n",
    "    return N - R_elbow(y,x,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions utiles pour le clustering (UFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''===================================\n",
    "    Fonctions utiles pour le clustering\n",
    "    ===================================\n",
    "    \n",
    "    ================================== =========================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- -------------------------------------------------------------------------\n",
    "    d_SL                               Distance en Single-Linkage entre 2 clusters.\n",
    "    d_CL                               Distance en Complete-Linkage entre 2 clusters.\n",
    "    d_AL                               Distance en Average-Linkage entre 2 clusters.\n",
    "    d_L2_Ward                          Distance de Ward entre 2 clusters.\n",
    "    dissim_L2                          Matrice de dissimilarité en distance L2 entre les lignes d'une matrice.\n",
    "    condense                           Condensation en vecteur d'une matrice symétrique.\n",
    "    tri                                Tri des lignes d'une matrice selon un clustering donné.\n",
    "    omegate                            Transformation d'une liste de clusters en un vecteur d'entiers.\n",
    "    matrixage                          Transformation d'un vecteur contenant des numéros de clusters\n",
    "                                       en une matrice contenant des 0 et des 1.\n",
    "    occurences                         Nombre d'occurences de chaque coefficient dans un vecteur d'entiers.\n",
    "    perm_opt                           Permutation optimale pour faire correspondre ensemble\n",
    "                                       deux vecteurs d'entiers de même taille.\n",
    "    Dist_CP                            Distance L2 minimale d'un vecteur à une liste de vecteurs de même taille.\n",
    "    sil_coeff                          Coefficient silhouette d'un vecteur d'une matrice d'observations\n",
    "                                       pour un clustering donné.\n",
    "    sil_score                          Score silhouette d'une matrice observations pour un clustering donné.\n",
    "    distorsion                         Distorsion d'une matrice d'observations pour un clustering donné.\n",
    "    Lap                                Laplacienne normalisée d'une matrice de similarité.\n",
    "    ARS                                Adjusted Rand Score entre deux vecteurs d'entiers de même taille.\n",
    "    ================================== =========================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Single-linkage\n",
    "def d_SL(Pdm,G,H):\n",
    "    '''Distance en Single-Linkage entre les clusters G et H.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Pdm : 2-D ndarray,\n",
    "        Matrice symétrique d'ordre N de dissimilarité dont chaque coefficient est un réel positif quantifiant la dissimilarité entre deux individus (une distance par exemple). \n",
    "    \n",
    "    G : list,\n",
    "        Liste des numéros des individus du cluster G, devant être compris entre 0 et N-1.\n",
    "        \n",
    "    H : list,\n",
    "        Liste des numéros des individus du cluster H, devant être compris entre 0 et N-1.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance en Single-Linkage entre les clusters G et H.\n",
    "    '''\n",
    "    if np.any(Pdm-np.transpose(Pdm)) or np.any(Pdm<0):\n",
    "        print(\"Pdm n'est pas une matrice de dissimilarité\")\n",
    "    else :\n",
    "        N,N1 = np.shape(Pdm)\n",
    "        dist_tab = np.array([[Pdm[i][j] for j in H] for i in G])\n",
    "        return np.min(dist_tab)\n",
    "\n",
    "#Complete-linkage\n",
    "def d_CL(Pdm,G,H):\n",
    "    '''Distance en Complete-Linkage entre les clusters G et H.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Pdm : 2-D ndarray,\n",
    "        Matrice symétrique d'ordre N de dissimilarité dont chaque coefficient est un réel positif quantifiant la dissimilarité entre deux individus (une distance par exemple). \n",
    "    \n",
    "    G : list,\n",
    "        Liste des numéros des individus du cluster G, devant être compris entre 0 et N-1.\n",
    "        \n",
    "    H : list,\n",
    "        Liste des numéros des individus du cluster H, devant être compris entre 0 et N-1.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance en Complete-Linkage entre les clusters G et H.\n",
    "    '''\n",
    "    if np.any(Pdm-np.transpose(Pdm)) or np.any(Pdm<0):\n",
    "        print(\"Pdm n'est pas une matrice de dissimilarité\")\n",
    "    else :\n",
    "        N,N1 = np.shape(Pdm)\n",
    "        dist_tab = np.array([[Pdm[i][j] for j in H] for i in G])\n",
    "        return np.max(dist_tab)\n",
    "\n",
    "#Average-linkage\n",
    "def d_AL(Pdm,G,H):\n",
    "    '''Distance en Average-Linkage entre les clusters G et H.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Pdm : 2-D ndarray,\n",
    "        Matrice symétrique d'ordre N de dissimilarité dont chaque coefficient est un réel positif quantifiant la dissimilarité entre deux individus (une distance par exemple). \n",
    "    \n",
    "    G : list,\n",
    "        Liste des numéros des individus du cluster G, devant être compris entre 0 et N-1.\n",
    "        \n",
    "    H : list,\n",
    "        Liste des numéros des individus du cluster H, devant être compris entre 0 et N-1.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance en Average-Linkage entre les clusters G et H.\n",
    "    '''\n",
    "    if np.any(Pdm-np.transpose(Pdm)) or np.any(Pdm<0):\n",
    "        print(\"Pdm n'est pas une matrice de dissimilarité\")\n",
    "    else :\n",
    "        N,N1 = np.shape(Pdm)\n",
    "        dist_tab = np.array([[Pdm[i][j] for j in H] for i in G])\n",
    "        return np.mean(dist_tab)\n",
    "\n",
    "#Distance Ward\n",
    "def d_L2_Ward(X,G,H):\n",
    "    '''Distance de Ward entre les clusters G et H.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les individus à clusteriser.\n",
    "    \n",
    "    G : list,\n",
    "        Liste des numéros des individus du cluster G, devant être compris entre 0 et N-1.\n",
    "        \n",
    "    H : list,\n",
    "        Liste des numéros des individus du cluster H, devant être compris entre 0 et N-1.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance de Ward entre les clusters G et H.\n",
    "    '''    \n",
    "    N,D = np.shape(X)\n",
    "    \n",
    "    if max(G) >= N or max(H) >= N :\n",
    "        print(\"Pas assez d'individus\")\n",
    "    else :\n",
    "        mu_G = np.mean(np.array([X[n] for n in G]),axis=0)\n",
    "        mu_H= np.mean(np.array([X[n] for n in H]),axis=0)\n",
    "        return np.sum((mu_G - mu_H)**2)\n",
    "\n",
    "#Distance L2\n",
    "def dissim_L2(X):\n",
    "    '''Matrice de dissimilarité en distance L2 des lignes de X.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des individus.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    Pdm : 2-D ndarray,\n",
    "        Matrice carré d'ordre N, dont, pour tous i,j entre 0 et N-1, le coefficient à la i-ème ligne et la j-ième colonne est la distance L2 entre le i-ème et le j-ème vecteur ligne de X.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    return np.array([[np.sqrt(np.sum((X[i]-X[j])**2)) for i in range(N)] for j in range(N)])\n",
    "\n",
    "#Condensation d'une matrice de dissimilarité\n",
    "def condense(PdM):\n",
    "    '''Condensation d'une matrice symétrique.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    PdM : 2-D ndarray,\n",
    "        Matrice symétrique d'ordre N.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    conc : 1-D ndarray,\n",
    "        Concaténation des lignes de la partie triangulaire strictement supérieure de PdM.\n",
    "    '''\n",
    "    N,N1 = np.shape(PdM)\n",
    "    return np.concatenate([PdM[n][n+1:] for n in range(N-1)])\n",
    "\n",
    "#Tri des vecteurs\n",
    "def tri(X,omega,K=None):\n",
    "    '''Tri des vecteurs de X selon omega.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les individus à trier.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Mis à défaut sur la valeur maximale de omega + 1\n",
    "        Si renseigné et plus grand que la valeur maximale de omega + 1, rendra des clusters vides.\n",
    "        Si renseigné et plus petit que la valeur maximale de omega + 1, ne prendra pas en compte les individus dont le numéro de cluster est plus grand que K-1\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    tri_X : list of ndarray,\n",
    "        Liste à K éléments dont chaque élément est la matrice de taille (N_k,D) dont les lignes sont les individus d'un même cluster.\n",
    "    '''\n",
    "    N = len(omega)\n",
    "    if type(K) == type(None):\n",
    "        K = int(max(omega) + 1)\n",
    "        \n",
    "    for k in range(K):\n",
    "        if k not in omega :\n",
    "            print(k)\n",
    "            print(\"tri : Clusters vides\")\n",
    "    \n",
    "    tri_X = [np.array([]) for k in range(K)]\n",
    "    \n",
    "    for k in range(K):\n",
    "        tri_X[k] = np.array([X[n] for n in range(N) if omega[n]==k])\n",
    "    \n",
    "    return tri_X\n",
    "\n",
    "def omegate(clusters):\n",
    "    '''Transformation d'une liste de clusters en un vecteur d'entiers.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    \n",
    "    clusters : list of list,\n",
    "        Liste de K listes, où, pour tout k entre 0 et K-1, le k-ième liste contient les numéros des individus appartenant au k-ième cluster.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    K = len(clusters)\n",
    "    N = max([max(clus) for clus in clusters]) + 1\n",
    "    omega = np.zeros(N)\n",
    "    \n",
    "    for k in range(K) :\n",
    "        for n in clusters[k] :\n",
    "            omega[n] = k\n",
    "    \n",
    "    return omega.astype(int)\n",
    "\n",
    "def matrixage(omega):\n",
    "    '''Transformation d'un vecteur contenant des numéros de clusters en une matrice avec des 0 et des 1.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N et de valeur maximale K-1.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    O : 2-D ndarray,\n",
    "        Matrice de taille (N,K), dont, pour tout n entre 0 et N-1 et tout k entre 0 et K-1, le coefficient à la n-ième ligne et la k-ième colonne vaut 1 si le n-ième coefficient de omega vaut k et 0 sinon.\n",
    "    '''\n",
    "    N = len(omega)\n",
    "    K = int(np.max(omega) + 1)\n",
    "    O = np.array([[int(omega[n] == k) for k in range(K)] for n in range(N)])\n",
    "    \n",
    "    return O\n",
    "\n",
    "#Occurences\n",
    "def occurences(omega):\n",
    "    '''Nombres d'occurences de chaque coefficient d'un vecteur d'entiers.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N et de valeur maximale K-1.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    occ : 1-D ndarray,\n",
    "        Vecteur de taille K, dont, pour tout k entre K-1, le k-ième coefficient de omega est le nombre d'occurences de k dans omega.\n",
    "    '''\n",
    "    N = len(omega)\n",
    "    K = int(np.max(omega)) + 1\n",
    "    \n",
    "    occur = np.zeros(K)\n",
    "    for n in range(N):\n",
    "        occur[omega[n]] += 1\n",
    "    \n",
    "    return occur.astype(int)\n",
    "\n",
    "def perm_opt(omega1,omega2):\n",
    "    '''Permutation optimale pour faire correspondre ensemble deux vecteurs d'entiers de même taille.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    omega1 : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N et de valeur maximale K-1.\n",
    "        \n",
    "    omega2 : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N et de valeur maximale K-1.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    s : 1-D ndarray,\n",
    "        Permutation pour laquelle le nombre de coefficients différant entre s(omega1) et omega2 est minimal.\n",
    "    '''\n",
    "    N1 = len(omega1)\n",
    "    N2 = len(omega2)\n",
    "    occ1 = occurences(omega1)\n",
    "    occ2 = occurences(omega2)\n",
    "    K1 = len(occ1)\n",
    "    K2 = len(occ2)\n",
    "    \n",
    "    if N1 != N2 or K1 != K2 or np.any(occ1==0) or np.any(occ2==0):\n",
    "        print(\"Les omegas ne correspondent pas\")\n",
    "    else:\n",
    "        N = N1\n",
    "        K = K1\n",
    "        \n",
    "        O1 = matrixage(omega1)\n",
    "        O2 = matrixage(omega2)\n",
    "        R_occ = np.transpose(O1)@O2\n",
    "        R = np.diag(1/occ1) @ R_occ\n",
    "        \n",
    "        sure=[]\n",
    "        unsure=list(np.arange(K))\n",
    "        taken=[]\n",
    "        untaken=list(np.arange(K))\n",
    "        \n",
    "        s_sure = -np.ones(K)\n",
    "        \n",
    "        for k in range(K):\n",
    "            s_k = int(np.argmax(R[k]))\n",
    "            if k == int(np.argmax(R[:,s_k])):\n",
    "                sure.append(k)\n",
    "                unsure.remove(k)\n",
    "                taken.append(s_k)\n",
    "                untaken.remove(s_k)\n",
    "                s_sure[k] = s_k\n",
    "        \n",
    "        nb_unsure = len(unsure)\n",
    "        \n",
    "        errs = []\n",
    "        perms = list(itt.permutations(range(nb_unsure)))\n",
    "        for perm in perms :\n",
    "            s_test = s_sure\n",
    "            for i in range(nb_unsure):\n",
    "                j = perm[i]\n",
    "                s_test[unsure[i]] = untaken[j]\n",
    "            s_omega1 = np.array([s_test[o] for o in omega1]).astype(int)\n",
    "            err = np.sum(((s_omega1 - omega2).astype(bool)).astype(float))\n",
    "            errs.append(err)\n",
    "        \n",
    "        ind_opt = int(np.argmin(np.array(errs)))\n",
    "        us_opt = perms[ind_opt]\n",
    "        s_opt = s_sure\n",
    "        for i in range(nb_unsure):\n",
    "            j = perm[i]\n",
    "            s_opt[unsure[i]] = untaken[j]\n",
    "        \n",
    "        return s_opt.astype(int)\n",
    "\n",
    "#Distance to closest point\n",
    "def Dist_CP(x,M):\n",
    "    '''Distance L2 minimale d'un vecteur x à une liste M de vecteurs de même taille que x.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    x : 1-D ndarray,\n",
    "        Vecteur de taille D.\n",
    "        \n",
    "    M : 2-D ndarray,\n",
    "        Matrice de taille (t,D), dont les lignes sont les vecteurs dont il faut calculer la distance à x\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Distance L2 de x au vecteur ligne de M qui lui est le plus proche.\n",
    "    '''\n",
    "    t,D = np.shape(M)\n",
    "    D1 = len(x)\n",
    "    if D != D1:\n",
    "        print(\"x et les moyennes n'ont pas même dimensions\")\n",
    "    else :\n",
    "        return min([np.sum((x-M[k])**2) for k in range(t)])\n",
    "\n",
    "#Silhouette coefficient\n",
    "def sil_coeff(n,X,omega):\n",
    "    '''Coefficient silhouette du n-ième individu des observations X pour le clustering induit par omega.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    n : int,\n",
    "        Numéro de l'individu dont on veut le coefficient silhouette. Doit être compris entre 0 et N-1.\n",
    "        \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    coeff : float,\n",
    "        Coefficient silhouette du n-ième individu des observations X pour le clustering donné par omega.\n",
    "    '''\n",
    "    x = X[n]\n",
    "    N = len(X)\n",
    "    K = int(max(omega)+1)\n",
    "    \n",
    "    M = np.array([np.mean(np.array([X[j] for j in range(n) if omega[j]==k])) for k in range(K)])\n",
    "    \n",
    "    k_star = omega[n]\n",
    "    dists = np.array([np.sum((x-M[k])**2) for k in range(K)])\n",
    "    dists[k_star] += np.max(dists) + 1\n",
    "    k_prime = np.argmin(dists)\n",
    "    \n",
    "    a = np.mean(np.array([np.sum((x-X[j])**2) for j in range(N) if omega[j] == k_star]))\n",
    "    b = np.mean(np.array([np.sum((x-X[j])**2) for j in range(N) if omega[j] == k_prime]))\n",
    "    \n",
    "    return (b-a)/(max(a,b))\n",
    "\n",
    "#Silhouette score\n",
    "def sil_score(X,omega):\n",
    "    '''Score silhouette des observations X pour le clustering induit par omega.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    score : float,\n",
    "        Score silhouette des observations X pour le clustering donné par omega.\n",
    "    '''\n",
    "    N = len(X)\n",
    "    return np.mean([sil_coeff(n,X,omega) for n in range(N)])\n",
    "\n",
    "#Distorsion\n",
    "def distorsion(X,omega):\n",
    "    '''Distorsion des observations X pour le clustering induit par omega.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    dist : float,\n",
    "        Somme des erreurs en distance L2 de chaque individu au centre de son cluster.\n",
    "    '''\n",
    "    tri_X = tri(X,omega)\n",
    "    return np.sum(np.array([np.sum(np.var(x,axis=0)) for x in tri_X]))\n",
    "\n",
    "def Lap(Psm):\n",
    "    '''Laplacienne normalisée d'une matrice de similarité\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Psm : 2-D ndarray,\n",
    "        Matrice de similarité pairwise symétrique d'ordre N, dont les coefficients sont positifs et sont d'autant plus élevés que l'individu en abscisse et celui en ordonnée sont proches.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    Lapsym : 2-D ndarray,\n",
    "        Matrice Laplacienne normalisée de Psm\n",
    "    '''\n",
    "    N,N1 = np.shape(Psm)\n",
    "    \n",
    "    if np.any(Psm-np.transpose(Psm)) or np.any(Psm<0):\n",
    "        print(\"Psm n'est pas une matrice de poids symétrique\")\n",
    "    else :\n",
    "        vec_D = np.sum(Psm, axis=0)\n",
    "        rinv_D = np.diag(1/np.sqrt(vec_D))\n",
    "        \n",
    "        L = np.eye(N) - rinv_D @ Psm @ rinv_D\n",
    "        \n",
    "        return L\n",
    "\n",
    "def ARS(omega1,omega2):\n",
    "    '''Adjusted Rand Score entre deux vecteurs d'entiers de même taille.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    omega1 : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N.\n",
    "        \n",
    "    omega2 : 1-D ndarray,\n",
    "        Vecteur d'entiers de taille N.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    ars : float,\n",
    "        Adjusted Rand Score entre les clusterings induits par omega1 et omega2.\n",
    "    '''\n",
    "    return sklmc.adjusted_rand_score(omega1,omega2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions d'estimation, modèles simples (SFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''===========================================\n",
    "    Fonctions d'estimation pour modèles simples\n",
    "    ===========================================\n",
    "    \n",
    "    ================================== ========================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- ------------------------------------------------------------------------\n",
    "    L_opt                              Nombre optimal de dimensions latentes, estimé par la \"méthode du saut\"\n",
    "    L_opt_2                            Nombre optimal de dimensions latentes, estimé par la \"méthode du coude\".\n",
    "    L_opt_3                            Nombre optimal de dimensions latentes, estimé par la \"méthode du genou\".\n",
    "    PCA                                Analyse en Composante Principale (Adapté pour le modèle (M.1)).\n",
    "    bruit                              Estimation de la variance du bruit à partir d'une matrice de covariance.\n",
    "    PPCA_EM                            Analyse en Composante Principale Probabiliste, algorithme E-M\n",
    "                                       (Adapté pour le modèle (M.1)).\n",
    "    PPCA                               Analyse en Composante Principale Probabiliste, algorithme direct\n",
    "                                       (Adapté pour le modèle (M.1)).\n",
    "    ML_RCA                             Analyse en Composante Résiduelle, méthode itérative\n",
    "                                       (Adapté pour le modèle (M.2)).\n",
    "    MLE_Gauss                          Estimation de la moyenne et de la variance d'un N-échantillon Gaussien\n",
    "                                       multivarié de covariance isotrope.\n",
    "    ================================== ========================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_opt(S,L_min=1,detail=False):\n",
    "    '''Nombre optimal de dimensions latentes, estimé par la \"méthode du saut\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance empirique (symétrique positive d'ordre D) à diagonaliser.\n",
    "        \n",
    "    L_min : int, optional,\n",
    "        Nombre de dimensions minimal à renvoyer.\n",
    "        Mis sur 1 par défaut.\n",
    "        \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, détaille graphiquement le choix du nombre de dimensions latentes.\n",
    "        \n",
    "        Le coefficient d'incertitude donné est égal à log(total_span/taken_span)/log(D) où\n",
    "            - total_span est la différence entre la plus grande et la plus petite valeur propre de S.\n",
    "            - taken_span est la différence entre la L-ième et la (L+1)-ème plus grande valeur propre de S.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    L : int,\n",
    "        Nombre de dimensions latentes pour la matrice de covariance S minimisant le coefficient d'incertitude.\n",
    "    '''\n",
    "    D1,D2 = np.shape(S)\n",
    "    if D1 != D2:\n",
    "        print('Erreur de dimensions sur S')\n",
    "    else :\n",
    "        D = D1\n",
    "        SpS,P = nla.eig(S)\n",
    "        \n",
    "        ordre = np.sort(SpS)\n",
    "        if L_min <= 1:\n",
    "            diff_ordre = ordre[1:] - ordre[:-1]\n",
    "            L_star = D - int(np.argmax(diff_ordre)) - 1\n",
    "        else :\n",
    "            diff_ordre = ordre[1:1-L_min] - ordre[:-L_min]\n",
    "            L_star = D - int(np.argmax(diff_ordre)) - 1\n",
    "        \n",
    "        total_span = ordre[-1]-ordre[0]\n",
    "        taken_span = ordre[D-L_star]-ordre[D-L_star-1]\n",
    "        \n",
    "        coeff_incert = np.log(total_span/taken_span)/np.log(D)\n",
    "        \n",
    "        if detail :\n",
    "            plt.figure()\n",
    "            plt.step(np.arange(D),ordre)\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],ordre[D-L_star]])\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],0],'--',label='$D-L_{star}$')\n",
    "            plt.legend()\n",
    "            plt.title('Spectre ordonné de la matrice de covariance')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Le coefficient d'incertitude est de\",coeff_incert)\n",
    "        \n",
    "        return L_star\n",
    "\n",
    "def L_opt_2(S,beta=0.5,L_min=1,detail=False):\n",
    "    '''Nombre optimal de dimensions latentes, estimé par la \"méthode du coude\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance empirique (symétrique positive d'ordre D) à diagonaliser.\n",
    "        \n",
    "    beta : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"coude\".\n",
    "        Plus beta est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"coude\" sera grande, et donc plus la valeur de L renvoyée sera élevée.\n",
    "        Mis sur 0.5 par défaut.\n",
    "        \n",
    "    L_min : int, optional,\n",
    "        Nombre de dimensions minimal à renvoyer.\n",
    "        Mis sur 1 par défaut.\n",
    "        \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, détaille graphiquement le choix du nombre de dimensions latentes.\n",
    "        \n",
    "        Le coefficient d'incertitude donné est égal à log(total_span/taken_span)/log(D) où\n",
    "            - total_span est la différence entre la plus grande et la plus petite valeur propre de S.\n",
    "            - taken_span est la différence entre la L-ième et la (L+1)-ème plus grande valeur propre de S.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    L : int,\n",
    "        Nombre de dimensions latentes correspondant à l'emplacement du coude dans le spectre ordonné de S.\n",
    "    '''\n",
    "    D1,D2 = np.shape(S)\n",
    "    if D1 != D2:\n",
    "        print('Erreur de dimensions sur S')\n",
    "    else :\n",
    "        D = D1\n",
    "        SpS,P = nla.eig(S)\n",
    "        \n",
    "        ordre = np.sort(SpS)\n",
    "        if L_min <= 1:\n",
    "            L_star = D - mbu.R_elbow(ordre,beta) - 1\n",
    "        else :\n",
    "            L_star = D - mbu.R_elbow(ordre[:1-L_min],beta) - 1\n",
    "        \n",
    "        total_span = ordre[-1]-ordre[0]\n",
    "        taken_span = ordre[D-L_star]-ordre[D-L_star-1]\n",
    "        \n",
    "        coeff_incert = np.log(total_span/taken_span)/np.log(D)\n",
    "        \n",
    "        if detail :\n",
    "            plt.figure()\n",
    "            plt.step(np.arange(D),ordre)\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],ordre[D-L_star]],label='$D-L_{star}$')\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],0],'--',label='$D-L_{star}$')\n",
    "            plt.legend()\n",
    "            plt.title('Spectre ordonné de la matrice de covariance')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Le coefficient d'incertitude est de\",coeff_incert)\n",
    "        \n",
    "        return L_star\n",
    "\n",
    "def L_opt_3(S,beta=0.5,L_min=1,detail=False):\n",
    "    '''Nombre optimal de dimensions latentes, estimé par la \"méthode du genou\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance empirique (symétrique positive d'ordre D) à diagonaliser.\n",
    "        \n",
    "    beta : float, optional,\n",
    "        Coefficient pour ajuster la part d'importance des abscisses et des ordonnées dans le calcul de l'emplacement du \"genou\".\n",
    "        Plus beta est grand, plus la part d'importance des ordonnées dans le calcul de l'emplacement du \"genou\" sera grande, et donc plus la valeur de L renvoyée sera élevée.\n",
    "        Mis sur 0.5 par défaut.\n",
    "        \n",
    "    L_min : int, optional,\n",
    "        Nombre de dimensions minimal à renvoyer.\n",
    "        Mis sur 1 par défaut.\n",
    "        \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, détaille graphiquement le choix du nombre de dimensions latentes.\n",
    "        \n",
    "        Le coefficient d'incertitude donné est égal à log(total_span/taken_span)/log(D) où\n",
    "            - total_span est la différence entre la plus grande et la plus petite valeur propre de S.\n",
    "            - taken_span est la différence entre la L-ième et la (L+1)-ème plus grande valeur propre de S.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    L : int,\n",
    "        Nombre de dimensions latentes correspondant à l'emplacement du genou dans le scree plot induit par S.\n",
    "    '''\n",
    "    D1,D2 = np.shape(S)\n",
    "    if D1 != D2:\n",
    "        print('Erreur de dimensions sur S')\n",
    "    else :\n",
    "        D = D1\n",
    "        SpS,P = nla.eig(S)\n",
    "        \n",
    "        ordre = np.sort(SpS)\n",
    "        inertie = np.cumsum(ordre)\n",
    "        \n",
    "        if L_min <= 1:\n",
    "            L_star = D - mbu.R_elbow(inertie,beta) - 1\n",
    "        else :\n",
    "            L_star = D - mbu.R_elbow(inertie[:1-L_min],beta) - 1\n",
    "        \n",
    "        total_span = ordre[-1]-ordre[0]\n",
    "        taken_span = ordre[D-L_star]-ordre[D-L_star-1]\n",
    "        \n",
    "        coeff_incert = np.log(total_span/taken_span)/np.log(D)\n",
    "        \n",
    "        if detail :\n",
    "            plt.figure()\n",
    "            plt.step(np.arange(D),ordre)\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],ordre[D-L_star]],label='$D-L_{star}$')\n",
    "            plt.plot([D-L_star-1,D-L_star-1],[ordre[D-L_star-1],0],'--',label='$D-L_{star}$')\n",
    "            plt.legend()\n",
    "            plt.title('Spectre ordonné de la matrice de covariance')\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"Le coefficient d'incertitude est de\",coeff_incert)\n",
    "        \n",
    "        return L_star\n",
    "\n",
    "def PCA(Y,L=None):\n",
    "    '''Analyse en Composante Principale.\n",
    "    (Adapté pour le modèle (M.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance des vecteurs constituant les lignes de Y.\n",
    "        \n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la PCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PCA.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    #Centrage de Y\n",
    "    mu_ML = np.mean(Y,axis=0)\n",
    "    Yc = np.array([y-mu_ML for y in Y])\n",
    "    \n",
    "    #Diagonalisation de S, choix des axes principaux\n",
    "    S = mbu.cov_emp(Yc)\n",
    "    \n",
    "    if type(L) == type(None):\n",
    "        L = L_opt(S)\n",
    "    \n",
    "    SpS, P = nla.eig(S)\n",
    "    ordre = np.sort(SpS)\n",
    "    inlist = [k for k in range(D) if SpS[k] in ordre[D-L:]]\n",
    "    \n",
    "    #Estimation de W\n",
    "    P = mbu.normalize(P)\n",
    "    tW = np.array([P[:,k] for k in inlist])\n",
    "    W = np.transpose(tW)\n",
    "    \n",
    "    #Estimation de Z\n",
    "    Z = Yc @ W @ nla.inv(tW@W)\n",
    "    \n",
    "    return S, W, Z\n",
    "\n",
    "def bruit(S,L=None):\n",
    "    '''Estimation de la variance du bruit à partir d'une matrice de covariance.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    S : 2-D ndarray,\n",
    "        Matrice de covariance empirique (symétrique positive d'ordre D) à diagonaliser.\n",
    "    \n",
    "    L : int, optional\n",
    "        Nombre de dimensions latentes supposé.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    sigma2 : float,\n",
    "        Bruit estimé à partir de la matrice de covariance S, égal à la moyenne des D-L plus petites valeurs propres de S.\n",
    "    '''\n",
    "    D1,D2 = np.shape(S)\n",
    "    \n",
    "    if type(L) == type(None):\n",
    "        L = L_opt(S)\n",
    "        \n",
    "    if D1 != D2 or D1 <= L or D2 <= L :\n",
    "        print('Erreur de dimension sur S')\n",
    "        \n",
    "    else :\n",
    "        D = D1\n",
    "        SpS, P = nla.eig(S)\n",
    "        sigma2 = np.mean(np.sort(SpS)[D-L:])\n",
    "        return sigma2\n",
    "\n",
    "def PPCA_EM(Y,L=None,nb_steps=1000,err=0.0,tempo=True):\n",
    "    '''Analyse en Composante Principale Probabiliste, algorithme E-M.\n",
    "    (Adapté pour le modèle (M.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt\n",
    "        \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme.\n",
    "        Mis sur 1000 par défaut.\n",
    "        \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la PPCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "        \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance du bruit.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    #Centrage de Y\n",
    "    mu_Y = np.mean(Y,axis=0)\n",
    "    Yc = np.array([y-mu_Y for y in Y])\n",
    "    \n",
    "    #Initialisation\n",
    "    S = mbu.cov_emp(Y)\n",
    "    \n",
    "    if type(L) == type(None):\n",
    "        L = L_opt(S)\n",
    "    \n",
    "    #Estimation de sigma²\n",
    "    sigma2 = bruit(S,L)\n",
    "    \n",
    "    #Algorithme E-M\n",
    "    dist = err+1\n",
    "    t = 0\n",
    "    while dist > err and t < nb_steps :\n",
    "        new_Z = Yc @ W @ nla.inv(np.transpose(W)@W)\n",
    "        new_W = np.transpose(Yc) @ new_Z @ nla.inv(np.transpose(new_Z) @ new_Z)\n",
    "        dist = np.sum((Z-new_Z)**2) + np.sum((W-new_W)**2)\n",
    "        W = new_W\n",
    "        Z = new_Z\n",
    "        t += 1\n",
    "    if tempo :\n",
    "        print('t = ',t)\n",
    "    \n",
    "    return W, Z, sigma2\n",
    "\n",
    "def PPCA(Y,L=None):\n",
    "    '''Analyse en Composante Principale, algorithme direct.\n",
    "    (Adapté pour le modèle (M.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la PCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PCA.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance du bruit.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    #Centrage de Y\n",
    "    mu_ML = np.mean(Y,axis=0)\n",
    "    Yc = np.array([y-mu_ML for y in Y])\n",
    "    \n",
    "    #Estimation de sigma²\n",
    "    S = mbu.cov_emp(Y)    \n",
    "    if type(L) == type(None):\n",
    "        L = L_opt(S)\n",
    "    \n",
    "    SpS, P = nla.eig(S)\n",
    "    P = mbu.normalize(P)\n",
    "    ordre = np.sort(SpS)\n",
    "    sigma2 = np.mean(ordre[:D-L])\n",
    "    inlist = [k for k in range(D) if SpS[k] in ordre[D-L:]]\n",
    "    \n",
    "    #Estimation de W et Z\n",
    "    tU_L = np.array([P[:,k] for k in inlist])\n",
    "    L_L = np.diag(np.array([np.sqrt(SpS[k]-sigma2) for k in inlist]))\n",
    "    tW = L_L @ tU_L\n",
    "    W = np.transpose(tW)\n",
    "    Z = Yc @ W @ nla.inv(tW@W)\n",
    "    \n",
    "    return W, Z, sigma2\n",
    "\n",
    "def ML_RCA(Y,X,L,V=None,nb_steps=100,err=0.0,tempo=True):\n",
    "    '''Analyse en Composante Résiduelle, méthode itérative.\n",
    "    (Adapté pour le modèle (M.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        \n",
    "    V : 2-D ndarray, optional,\n",
    "        Matrice de taille (D,C) d'effets fixes donnée en argument initial de l'algorithme itératif.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme.\n",
    "        Mis sur 1000 par défaut.\n",
    "        \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la RCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la RCA.\n",
    "        \n",
    "    V_hat : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes estimée par la RCA.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance du bruit.\n",
    "    '''\n",
    "    N1,D = np.shape(Y)\n",
    "    N2,C = np.shape(X)\n",
    "    \n",
    "    if N1 != N2 :\n",
    "        print('Erreur de dimensions sur Y et X')\n",
    "        S, W, Z = PCA(Y,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        return W, Z, sigma2\n",
    "    else :\n",
    "        N = N1\n",
    "    \n",
    "    #Centrage de Y et X\n",
    "    mY = np.mean(Y,axis=0)\n",
    "    mX = np.mean(X,axis=0)\n",
    "    Yc = np.array([y-mY for y in Y])\n",
    "    Xc = np.array([x-mX for x in X])\n",
    "    \n",
    "    #Initialisation\n",
    "    \n",
    "    #Si V est donné\n",
    "    if type(V) != type(None) :\n",
    "        \n",
    "        #Copie de V s'il est donné\n",
    "        V_hat = V.copy()\n",
    "        \n",
    "        #Estimation de Z et W\n",
    "        W,Z,sigma2 = PPCA(Yc-Xc@np.transpose(V_hat),L)\n",
    "        \n",
    "    #Si V n'est pas donné\n",
    "    else :\n",
    "        #Initialisation\n",
    "        \n",
    "        #Estimation de V\n",
    "        V_hat = np.transpose(Yc)@Xc @ nla.inv(np.transpose(Xc)@Xc)\n",
    "        \n",
    "        #Estimation de Z et W\n",
    "        W,Z,sigma2 = PPCA(Yc-Xc@np.transpose(V_hat),L)\n",
    "        \n",
    "        dist = err+1\n",
    "        t = 0\n",
    "        \n",
    "        #Boucle\n",
    "        while dist > err and t < nb_steps :\n",
    "            \n",
    "            #Estimation de V\n",
    "            new_V = np.transpose(Yc-Z@np.transpose(W))@Xc @ nla.inv(np.transpose(Xc)@Xc)\n",
    "            \n",
    "            #Estimation de Z et W\n",
    "            new_W,new_Z,sigma2_hat = PPCA(Yc - Xc@np.transpose(new_V),L)\n",
    "            \n",
    "            #Vérification\n",
    "            dist = np.sum((Z@np.transpose(W) - new_Z@np.transpose(new_W))**2) + np.sum((V_hat-new_V)**2)\n",
    "            t += 1\n",
    "            \n",
    "            W = new_W\n",
    "            Z = new_Z\n",
    "            V_hat = new_V\n",
    "            \n",
    "        if tempo :\n",
    "            print('t =',t)\n",
    "    \n",
    "    return W, Z, V_hat, sigma2\n",
    "\n",
    "def tXX_estimator(Y,W,sigma2,Lambda):\n",
    "    \n",
    "    D,L = np.shape(W)\n",
    "    D1,D2 = np.shape(Lambda)\n",
    "    N,D3 = np.shape(Y)\n",
    "    \n",
    "    if D != D1 or D != D2 or D != D3 :\n",
    "        print('Erreur de dimensions sur Lambda, Y ou W')\n",
    "    else :\n",
    "        qty_1 = nla.inv(nla.inv(W@np.transpose(W) + sigma2*np.eye(D)) + Lambda)\n",
    "        qty_2 = np.array([qty_1 @ nla.inv(W@np.transpose(W) + sigma2*np.eye(D)) @ y for y in Y])\n",
    "        tXX = np.array([qty_1 + np.transpose(np.array([x]))@np.array([x]) for x in qty_2])\n",
    "        return tXX\n",
    "\n",
    "def Lambda_estimator(tXX,la):\n",
    "    \n",
    "    N,D1,D2 = np.shape(tXX)\n",
    "    \n",
    "    if D1 != D2 :\n",
    "        print('Erreur de dimensions sur tXX')\n",
    "    else :\n",
    "        D = D1\n",
    "        S = np.mean(tXX,axis=0)\n",
    "        Lambda, st_else = sklcov.graphical_lasso(S,la,max_iter=50)\n",
    "        return Lambda\n",
    "        \n",
    "def W_estimator(Y,Lambda,sigma2,L):\n",
    "    \n",
    "    N,D = np.shape(Y)\n",
    "    D1,D2 = np.shape(Lambda)\n",
    "    \n",
    "    if D != D1 or D != D2 :\n",
    "        print('Erreur de dimensions sur Y ou Lambda')\n",
    "    else :\n",
    "        Sigma = nla.inv(Lambda) + sigma2*np.eye(D)\n",
    "        S_hat = mbu.cov_emp(Y)\n",
    "        A = nla.inv(Sigma) @ S_hat\n",
    "        \n",
    "        #GEP\n",
    "        SpA, P = nla.eig(A)\n",
    "        ord_A = np.sort(SpA)\n",
    "        inlist_A = [k for k in range(D) if SpA[k] in ord_A[D-L:]]\n",
    "        P_W = mbu.normalize(np.transpose(np.array([P[:,k] for k in inlist_A])))\n",
    "        D_W = np.diag(np.array([SpA[k] for k in inlist_A]))\n",
    "        W = Sigma @ P_W\n",
    "        \n",
    "        return W\n",
    "\n",
    "def log_p_LRPSI(Y,W,Lambda,sigma2,la):\n",
    "    \n",
    "    N,D = np.shape(Y)\n",
    "    D1,L = np.shape(W)\n",
    "    D2,D3 = np.shape(Lambda)\n",
    "    \n",
    "    if D != D1 or D!= D2 or D != D3 :\n",
    "        print('Erreur de dimensions sur Y, W ou Lambda')\n",
    "    else :\n",
    "        Cov = W @ np.transpose(W) + nla.inv(Lambda) + sigma2*np.eye(D)\n",
    "        inv_Cov = nla.inv(Cov)\n",
    "        qty = np.sum(np.array([-np.log(np.abs(nla.det(Cov))) - 1/2 * np.array([y])@inv_Cov@y - la*np.sum(np.abs(Lambda)) for y in Y]))\n",
    "        return qty\n",
    "\n",
    "def EM_RCA_LRPSI(Y,X,L,Lambda=None,la=None,sigma2=None,nb_steps=1000,err=0.0,tempo=True):\n",
    "    \n",
    "    N1,D1 = np.shape(Y)\n",
    "    N2,D2 = np.shape(X)\n",
    "    \n",
    "    if N1 != N2 or D1 != D2 :\n",
    "        print('Erreur de dimensions sur Y et X')\n",
    "        S, W, Z = PCA(Y,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        return W, Z, sigma2\n",
    "    else :\n",
    "        N = N1\n",
    "        D = D1\n",
    "    \n",
    "    #Centrage de Y et X\n",
    "    mY = np.mean(Y,axis=0)\n",
    "    mX = np.mean(X,axis=0)\n",
    "    Yc = np.array([y-mY for y in Y])\n",
    "    Xc = np.array([x-mX for x in X])\n",
    "    \n",
    "    #Initialisation\n",
    "    \n",
    "    #Estimation de Lambda s'il n'est pas donné\n",
    "    if type(Lambda) == type(None):\n",
    "        covX = mbu.cov_emp(Xc)\n",
    "        Lambda_hat = nla.inv(covX)\n",
    "    else :\n",
    "        Lambda_hat = Lambda.copy()\n",
    "    \n",
    "    D1,D2 = np.shape(Lambda_hat)\n",
    "    if D != D1 or D != D2 :\n",
    "        print('Erreur de dimensions sur Lambda')\n",
    "        S, W, Z = PCA(Yc,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        return W, Z, Lambda_hat, sigma2\n",
    "    \n",
    "    #Estimation de lambda s'il n'est pas donné\n",
    "    if type(la) == type(None):\n",
    "        la_hat = D**2 * 2/mbu.trace(Lambda_hat)\n",
    "        calc_la = True\n",
    "    else :\n",
    "        la_hat = la.copy()\n",
    "        calc_la = False\n",
    "     \n",
    "    #Estimation de sigma2 s'il n'est pas donné\n",
    "    if type(sigma2) == type(None):\n",
    "        S,W_hat,Z = PCA(Yc-Xc,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "    \n",
    "    #Boucle EM/RCA pour estimer Z\n",
    "    gain = err + 1\n",
    "    t = 0\n",
    "    W_hat = W_estimator(Yc,Lambda_hat,sigma2,L)\n",
    "    log_p = log_p_LRPSI(Yc,W_hat,Lambda_hat,sigma2,la_hat)\n",
    "    \n",
    "    while gain > err and t < nb_steps :\n",
    "        \n",
    "        #E-step :\n",
    "        new_tXX = tXX_estimator(Yc,W_hat,sigma2,Lambda_hat)\n",
    "        \n",
    "        #M-step :\n",
    "        new_Lambda = Lambda_estimator(new_tXX,la_hat)\n",
    "        \n",
    "        #RCA-step :\n",
    "        new_W = W_estimator(Yc,new_Lambda,sigma2,L)\n",
    "        \n",
    "        #Vérification :\n",
    "        new_log_p = log_p_LRPSI(Yc,new_W,new_Lambda,sigma2,la_hat)\n",
    "        gain = new_log_p - log_p\n",
    "        \n",
    "        if gain >= 0 :\n",
    "            Lambda_hat = new_Lambda\n",
    "            W_hat = new_W\n",
    "            if calc_la :\n",
    "                la_hat = D**2 * 2/mbu.trace(Lambda_hat)\n",
    "        \n",
    "        t += 1\n",
    "        log_p = new_log_p\n",
    "        \n",
    "    if tempo :\n",
    "        print('t =',t)\n",
    "    \n",
    "    #Estimation de Z\n",
    "    Z = (Yc - Xc) @ W_hat @ nla.inv(np.transpose(W_hat)@W_hat)\n",
    "    \n",
    "    return W_hat,Z,Lambda_hat,sigma2\n",
    "\n",
    "def MLE_Gauss(Y):\n",
    "    '''Estimation de la moyenne et de la variance d'un N-échantillon Gaussien multivarié de covariance isotrope.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés, i.i.d. de loi normale.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    mu : 1-D ndarray,\n",
    "        Estimation de la moyenne de la loi des vecteurs lignes de Y.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance de la loi des vecteurs lignes de Y.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    mu_ML = np.mean(Y,axis=0)\n",
    "    sigma2_ML = np.var(Y)*(N/(N-1))\n",
    "    return mu_ML,sigma2_ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de clustering (CLF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''=======================\n",
    "    Fonctions de clustering\n",
    "    =======================\n",
    "    \n",
    "    ================================== ===================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- -------------------------------------------------------------------\n",
    "    HAC_SL                             Clustering Agglomératif Hiérarchique, en distance Single-Linkage.\n",
    "    HAC_CL                             Clustering Agglomératif Hiérarchique, en distance Complete-Linkage.\n",
    "    HAC_AL                             Clustering Agglomératif Hiérarchique, en distance Average-Linkage.\n",
    "    HAC_Ward                           Clustering Agglomératif Hiérarchique, en distance de Ward.\n",
    "    K_means                            Algorithme itératif K-means, ou \"K-moyennes\".\n",
    "    K_means_FPC                        Algorithme itératif K-means ++.\n",
    "    K_medoids                          Algorithme itératif K-medoids.\n",
    "    Lapras                             Clustering Spectral.\n",
    "    K_opt                              Estimation du nombre de clusters.\n",
    "    ================================== ===================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HAC_SL(X,K,tempo=False):\n",
    "    '''Clustering Agglomératif Hiérarchique, en distance Single-Linkage.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    tempo : bool, optional,\n",
    "        Ne sert à rien, quelle que soit sa valeur.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    clusters = sklclu.AgglomerativeClustering(K,linkage='single').fit(X)\n",
    "    omega = clusters.labels_\n",
    "    \n",
    "    return omega\n",
    "\n",
    "def HAC_CL(X,K,tempo=False):\n",
    "    '''Clustering Agglomératif Hiérarchique, en distance Complete-Linkage.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    tempo : bool, optional,\n",
    "        Ne sert à rien, quelle que soit sa valeur.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    clusters = sklclu.AgglomerativeClustering(K,linkage='complete').fit(X)\n",
    "    omega = clusters.labels_\n",
    "    \n",
    "    return omega\n",
    "\n",
    "def HAC_AL(X,K,tempo=False):\n",
    "    '''Clustering Agglomératif Hiérarchique, en distance Average-Linkage.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    tempo : bool, optional,\n",
    "        Ne sert à rien, quelle que soit sa valeur.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    clusters = sklclu.AgglomerativeClustering(K,linkage='average').fit(X)\n",
    "    omega = clusters.labels_\n",
    "    \n",
    "    return omega\n",
    "\n",
    "def HAC_Ward(X,K,tempo=False):\n",
    "    '''Clustering Agglomératif Hiérarchique, en distance de Ward.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    tempo : bool, optional,\n",
    "        Ne sert à rien, quelle que soit sa valeur.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    clusters = sklclu.AgglomerativeClustering(K,linkage='ward').fit(X)\n",
    "    omega = clusters.labels_\n",
    "    \n",
    "    return omega\n",
    "\n",
    "def K_means(X,omega,nb_steps=100,tempo=True):\n",
    "    '''Algorithme itératif K-means, ou \"K-moyennes\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        L'algorithme s'arrête de lui-même si jamais la configuration obtenue est déjà stable.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    occ = ufc.occurences(omega)\n",
    "    K = len(occ)\n",
    "    if np.any(occ==0) :\n",
    "        print(\"K_means : Clusters vides\")\n",
    "    \n",
    "    omega_hat = omega.copy()\n",
    "    t = 0\n",
    "    dist = 1\n",
    "    M = np.zeros((K,D))\n",
    "    \n",
    "    while dist > 0 and t < nb_steps :\n",
    "        \n",
    "        #Recalcul des centres\n",
    "        tri_X = ufc.tri(X,omega_hat,K)\n",
    "        new_M = np.zeros((K,D))\n",
    "        for k in range(K) :\n",
    "            if len(tri_X[k]) > 0:\n",
    "                new_M[k] = np.mean(tri_X[k],axis = 0)\n",
    "            else :\n",
    "                new_M[k] = M[k]\n",
    "        M = new_M\n",
    "    \n",
    "        #Recalcul des clusters\n",
    "        new_omega = np.zeros(N)\n",
    "        for n in range(N) :\n",
    "            x = X[n]\n",
    "            dists_L2 = np.array([np.sum((x-M[k])**2) for k in range(K)])\n",
    "            new_omega[n] = np.argmin(dists_L2)\n",
    "        \n",
    "        dist = np.sum((omega_hat-new_omega)**2)\n",
    "        omega_hat = new_omega.astype(int)\n",
    "        t += 1\n",
    "    \n",
    "    if tempo :\n",
    "        print('t = ',t)\n",
    "    \n",
    "    return omega_hat\n",
    "\n",
    "def K_means_FPC(X,K,determ=True,nb_steps=100,tempo=True):\n",
    "    '''Algorithme K-means ++, i.e. K-means mais qui s'initialise en prenant comme centres des clusters des vecteurs du jeu de données X.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    determ : bool, optional,\n",
    "        Si mis sur True, l'algorithme s'initialise en prenant comme centres des deux premiers clusters les deux vecteurs les plus éloignés, puis prend successivement, comme centres des autres clusters, les vecteurs dont la distance L2 minimale aux vecteurs déjà sélectionnés est maximale. \n",
    "        Si mis sur False, l'algorithme s'initialise en prenant comme centre du premier cluster un vecteur uniformément au hasard, puis prend successivement, comme centres des autres clusters, des vecteurs au hasard, chacun pondérés proportionnellement à leur distance L2 minimale aux vecteurs déjà sélectionnés.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        L'algorithme s'arrête de lui-même si jamais la configuration obtenue est déjà stable.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N = len(X)\n",
    "    if N < K :\n",
    "        print(\"N < K\")\n",
    "    else :\n",
    "        \n",
    "        #Initialisation\n",
    "        \n",
    "        if determ :\n",
    "            Pdm = ufc.dissim_L2(X)\n",
    "            ind_max = np.argmax(Pdm)\n",
    "            n0 = int(ind_max/N)\n",
    "            n1 = ind_max%N\n",
    "            \n",
    "            M = np.array([X[n0],X[n1]])\n",
    "            \n",
    "            for k in range(2,K):\n",
    "            \n",
    "                dists_CP = np.array([ufc.Dist_CP(x,M) for x in X])\n",
    "                n_k = np.argmax(dists_CP)\n",
    "                \n",
    "                M_list = list(M)\n",
    "                M_list.append(X[n_k])\n",
    "                M = np.array(M_list)\n",
    "        \n",
    "        else :\n",
    "            n0 = rd.choice(N)\n",
    "            M = np.array([X[n0]])\n",
    "            \n",
    "            for k in range(1,K):\n",
    "                \n",
    "                dists_CP = np.array([ufc.Dist_CP(x,M) for x in X])\n",
    "                \n",
    "                tot_dist = np.sum(dists_CP)\n",
    "                probas = dists_CP/tot_dist\n",
    "                n_k = rd.choice(N,p=probas)\n",
    "                \n",
    "                M_list = list(M)\n",
    "                M_list.append(X[n_k])\n",
    "                M = np.array(M_list)\n",
    "            \n",
    "        omega = (-np.ones(N)).astype(int)\n",
    "        for n in range(N):\n",
    "            x = X[n]\n",
    "            dists_L2 = np.array([np.sum((x-M[k])**2) for k in range(K)])\n",
    "            omega[n] = int(np.argmin(dists_L2))\n",
    "        \n",
    "        #K-means\n",
    "        return K_means(X,omega,nb_steps,tempo)\n",
    "\n",
    "def K_medoids(X,omega,nb_steps=100,tempo=True):\n",
    "    '''Algorithme itératif K-medoids, ou \"K-médoïdes\", ou encore \"K-centroïdes\" (ew).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        L'algorithme s'arrête de lui-même si jamais la configuration obtenue est déjà stable.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    occ = ufc.occurences(omega)\n",
    "    K = len(occ)\n",
    "    if np.any(occ==0) :\n",
    "        print(\"K_means : Clusters vides\")\n",
    "    \n",
    "    omega_hat = omega.copy()\n",
    "    t = 0\n",
    "    dist = 1\n",
    "    M = np.zeros((K,D))\n",
    "    \n",
    "    while dist > 0 and t < nb_steps :\n",
    "        \n",
    "        #Recalcul des médoïdes\n",
    "        tri_X = ufc.tri(X,omega_hat,K)\n",
    "        for k in range(K):\n",
    "            dist_sums = np.array([np.sum(np.array([np.sum((x-y)**2) for x in tri_X[k]])) for y in tri_X[k]])\n",
    "            n_k = np.argmin(dist_sums)\n",
    "            M[k] = X[n_k]\n",
    "        \n",
    "        #Recalcul des clusters\n",
    "        new_omega = np.zeros(N)\n",
    "        for n in range(N) :\n",
    "            x = X[n]\n",
    "            dists_L2 = np.array([np.sum((x-M[k])**2) for k in range(K)])\n",
    "            new_omega[n] = np.argmin(dists_L2)\n",
    "        \n",
    "        dist = np.sum((omega_hat-new_omega)**2)\n",
    "        omega_hat = new_omega.astype(int)\n",
    "        t += 1\n",
    "    \n",
    "    if tempo :\n",
    "        print('t = ',t)\n",
    "    \n",
    "    return omega_hat\n",
    "\n",
    "#Vecteurs propres du Laplacien du graphe\n",
    "\n",
    "def Lapras(X,K,determ=True,nb_steps=100,tempo=True):\n",
    "    '''Clustering Spectral utilisant, pour matrice de similarité, la matrice de dissimilarité donnée par dissim_L2 renormalisée, dont chaque coefficient est passé par la fonction inverse de l'exponentielle.\n",
    "        (La fonction s'appelle Lapras parce que c'est le nom en anglais d'un Pokémon dont le nom en japonais est Laplace.)\n",
    "        \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à former.\n",
    "    \n",
    "    determ : bool, optional,\n",
    "        Si mis sur True, l'algorithme K-means++ s'initialisera en prenant comme centres des deux premiers clusters les deux vecteurs les plus éloignés, puis prend successivement, comme centres des autres clusters, les vecteurs dont la distance L2 minimale aux vecteurs déjà sélectionnés est maximale. \n",
    "        Si mis sur False, l'algorithme K-means++ s'initialisera en prenant comme centre du premier cluster un vecteur uniformément au hasard, puis prend successivement, comme centres des autres clusters, des vecteurs au hasard, chacun pondérés proportionnellement à leur distance L2 minimale aux vecteurs déjà sélectionnés.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        L'algorithme s'arrête de lui-même si jamais la configuration obtenue est déjà stable.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    \n",
    "    #Initialisation\n",
    "    Pdm = ufc.dissim_L2(X)\n",
    "    alpha = np.mean(Pdm)\n",
    "    Psm = np.exp(-N/(N-1)/alpha*Pdm)\n",
    "    Lokh = ufc.Lap(Psm)\n",
    "\n",
    "    #EVP\n",
    "    SpL,P = nla.eig(Lokh)\n",
    "    P2 = mbu.normalize(P)\n",
    "    ordre = np.sort(SpL)\n",
    "    inlist = [k for k in range(N) if SpL[k] in ordre[:K]]\n",
    "    tU = np.array([P2[:,k] for k in inlist])\n",
    "    T = np.transpose(mbu.normalize(tU))\n",
    "    omega = K_means_FPC(T,K,determ=determ,nb_steps=nb_steps,tempo=tempo)\n",
    "    \n",
    "    return omega\n",
    "\n",
    "#K optimal\n",
    "def K_opt(X,K_min=2,alpha=None,detail=False):\n",
    "    '''Estimation du nombre de clusters à former à partir du spectre de la matrice de dissimilarité donnée par la fonction dissim_L2.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à clusteriser.\n",
    "    \n",
    "    K_min : int, optional,\n",
    "        Nombre minimal de clusters à dégager.\n",
    "    \n",
    "    alpha : float, optional,\n",
    "        Coefficient de renormalisation de la matrice de dissimilarité donnée par la fonction dissim_L2.\n",
    "        Si mis sur None, prendra comme valeur l'inverse de la moyenne des distances L2 entre les vecteurs.\n",
    "    \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le détail graphique de l'estimation du nombre de clusters.\n",
    "        Mis sur False par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    K : int,\n",
    "        Estimation du nombre optimal de clusters à partir du plus grand saut dans le log de l'opposé du spectre de la la matrice de dissimilarité donnée par la fonction dissim_L2, renormalisée.\n",
    "    '''\n",
    "    N,D = np.shape(X)    \n",
    "    Pdm = ufc.dissim_L2(X)\n",
    "    \n",
    "    if type(alpha) == type(None):\n",
    "        alpha = 1.0/np.mean(Pdm)\n",
    "    \n",
    "    norm_Pdm = alpha*Pdm\n",
    "    SpP,Q = nla.eig(norm_Pdm)\n",
    "    ordre = np.sort(SpP)[:-1]\n",
    "    \n",
    "    logm_ordre = np.log(-ordre)\n",
    "    diff = logm_ordre[:-1]-logm_ordre[1:]\n",
    "    \n",
    "    if K_min >= 2:\n",
    "        diff[:K_min-2] = [0]*(K_min-2)\n",
    "    K_star = int(np.argmax(diff)) + 2\n",
    "    \n",
    "    if detail:\n",
    "        \n",
    "        plt.figure()\n",
    "        plt.step(np.arange(2,N+1),logm_ordre)\n",
    "        plt.plot([K_star,K_star],[logm_ordre[0],logm_ordre[-1]],'--',label='$K_{star}$')\n",
    "        plt.title(\"Log de l'opposé du spectre de la matrice de dissimilarité\")\n",
    "        plt.legend()\n",
    "        plt.figure()\n",
    "    \n",
    "    return K_star"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions pour reconstruire et représenter les données (DRR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''======================================================\n",
    "    Fonctions pour reconstruire ou représenter les données\n",
    "    ======================================================\n",
    "    \n",
    "    ================================== ==================================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- ----------------------------------------------------------------------------------\n",
    "    PCA_rec                            Reconstruction des vecteurs observés après (P)PCA\n",
    "                                       (Adapté aux modèles (M.1) et (M.5.1)).\n",
    "    RCA_rec                            Reconstruction des vecteurs observés après RCA\n",
    "                                       (Adapté aux modèles (M.2) et (M.5.2)).\n",
    "    MFA_rec_1                          Reconstruction des vecteurs observés après clustering\n",
    "                                       puis (P)PCA sur les différents clusters (Adapté au modèle (M.4.1)).\n",
    "    MFA_rec_2                          Reconstruction des vecteurs observés après clustering\n",
    "                                       puis RCA sur les différents clusters (Adapté au modèle (M.4.2)).\n",
    "    CA_graph                           Représentation graphique de la différence entre deux ensembles de vecteurs\n",
    "                                       (Adapté aux modèles (M.1) et (M.2)).\n",
    "    MFA_graph                          Représentation graphique de la différence entre deux ensembles de vecteurs,\n",
    "                                       coloriés selon leur clusters (Adapté aux modèles (M.4) et (M.5)).\n",
    "    discard                            Amputation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1.\n",
    "    disarg                             Permutation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1\n",
    "                                       (opération inverse de la fonction rearg).\n",
    "    restit                             Ajout de colonnes vides à une matrice de vecteurs selon un vecteur de 0 et de 1.\n",
    "    rearg                              Permutation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1\n",
    "                                       (opération inverse de la fonction disarg).\n",
    "    da_matrix                          Matrice de permutation associée à la permutation disarg(.,iota)\n",
    "    ra_matrix                          Matrice de permutation associée à la permutation rearg(.,iota)\n",
    "    FS_rec1                            Reconstruction des vecteurs observés après (P)PCA puis sélection de variables\n",
    "                                       (Adapté aux modèles (M.6.1) et (M.6.3)).\n",
    "    FS_rec2                            Reconstruction des vecteurs observés après RCA puis sélection de variables\n",
    "                                       (Adapté aux modèles (M.6.2) et (M.6.4)).\n",
    "    FS_mixrec1                         Reconstruction des vecteurs observés après clustering, (P)PCA cluster par cluster,\n",
    "                                       puis sélection de variables cluster par cluster (Adapté au modèle (M.6.5)).\n",
    "    FS_mixrec2                         Reconstruction des vecteurs observés après clustering, RCA cluster par cluster,\n",
    "                                       puis sélection de variables cluster par cluster (Adapté au modèle (M.6.6)).\n",
    "    FS_sperec1                         Reconstruction des vecteurs observés après clustering, sélection de variables,\n",
    "                                       puis (P)PCA (Adapté au modèle (M.6.7)).\n",
    "    FS_sperec2                         Reconstruction des vecteurs observés après clustering, sélection de variables,\n",
    "                                       puis RCA (Adapté au modèle (M.6.8)).\n",
    "    ================================== ==================================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PCA_rec(W,Z,mu):\n",
    "    '''Reconstruction des vecteurs observés après (P)PCA.\n",
    "    (Adapté aux modèles (M.1) et (M.5.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, supposé être la moyenne des observations.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    Y = Z @ np.transpose(W) + mu\n",
    "    return Y\n",
    "\n",
    "def RCA_rec(W,Z,V,X,mu):\n",
    "    '''Reconstruction des vecteurs observés après RCA.\n",
    "    (Adapté aux modèles (M.2) et (M.5.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables.\n",
    "        L'algorithme s'assure que ces vecteurs sont centrés en les recentrant.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, supposé être la moyenne des observations.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    Xc = X - np.mean(X,axis=0)\n",
    "    Y = Z @ np.transpose(W) + Xc @ np.transpose(V) + mu\n",
    "    return Y\n",
    "\n",
    "def MFA_rec_1(thetas,Z,omega):\n",
    "    '''Reconstruction des vecteurs observés après clustering puis (P)PCA sur les différents clusters.\n",
    "    (Adapté au modèle (M.4.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    D,L = np.shape(thetas[0][0])\n",
    "    N = len(omega)\n",
    "    Y = np.zeros((N,D))\n",
    "    \n",
    "    for n in range(N):\n",
    "        W,mu,sigma2 = thetas[omega[n]]\n",
    "        z = Z[n]\n",
    "        Y[n] = W@z + mu\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def MFA_rec_2(thetas,Z,X,omega):\n",
    "    '''Reconstruction des vecteurs observés après clustering puis RCA sur les différents clusters.\n",
    "    (Adapté au modèle (M.4.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,V,mu,sigma2] où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables.\n",
    "        L'algorithme s'assure que ces vecteurs sont centrés en les recentrant, cluster par cluster.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    D,L = np.shape(thetas[0][0])\n",
    "    N = len(omega)\n",
    "    Y = np.zeros((N,D))\n",
    "    tri_X = ufc.tri(X,omega)\n",
    "    \n",
    "    for n in range(N):\n",
    "        W,V,mu,sigma2 = thetas[omega[n]]\n",
    "        z = Z[n]\n",
    "        x = X[n] - np.mean(tri_X[omega[n]],axis=0)\n",
    "        \n",
    "        Y[n] = W@z + V@x + mu\n",
    "    \n",
    "    return Y\n",
    "\n",
    "def CA_graph(Y,Y_hat):\n",
    "    '''Représentation graphique de la différence entre deux ensembles de même nombre de vecteurs de même taille.\n",
    "    (Adapté aux modèles (M.1) et (M.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à comparer.\n",
    "    \n",
    "    Y_hat : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à comparer.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    for j in range(int(D/2)):\n",
    "        \n",
    "        plt.figure()\n",
    "        \n",
    "        plt.scatter(Y[:,2*j],Y[:,2*j+1],label='$Y$')\n",
    "        plt.scatter(Y_hat[:,2*j],Y_hat[:,2*j+1],label='$\\hat{Y}$')\n",
    "        \n",
    "        for n in range(N):\n",
    "            plt.plot([Y[n][2*j],Y_hat[n][2*j]],[Y[n][2*j+1],Y_hat[n][2*j+1]],color='black')\n",
    "            \n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "def MFA_graph(Y,Y_hat,omega_hat,omega=None,labels=None):\n",
    "    '''Représentation graphique de la différence entre deux ensembles de même nombre de vecteurs de même taille, coloriés selon leur clusters.\n",
    "    (Adapté aux modèles (M.4) et (M.5))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à comparer.\n",
    "    \n",
    "    Y_hat : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à comparer.\n",
    "    \n",
    "    omega_hat : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu de l'ensemble de vecteurs Y_hat.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu de l'ensemble de vecteurs Y.\n",
    "        Si mis sur None, prend la valeur de omega_hat.\n",
    "        Sinon, sera permuté pour être optimal avec omega_hat avec la fonction perm_opt avant représentation graphique.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    labels : list of str, optional,\n",
    "        Liste de K éléments, contenant les noms des clusters.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    None\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    K = int(max(omega_hat) + 1)\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        s_omega = omega_hat\n",
    "        K = int(max(omega_hat) + 1)\n",
    "    else:\n",
    "        s_opt = ufc.perm_opt(omega,omega_hat)\n",
    "        s_omega = np.array([s_opt[k] for k in omega]).astype(int)\n",
    "        K = int(max(omega_hat) + 1)\n",
    "        \n",
    "    tri_Y = ufc.tri(Y,s_omega,K)\n",
    "    tri_Y_hat = ufc.tri(Y_hat,omega_hat,K)\n",
    "    colors_orig = ['#802020','#E08080','#208020','#80E080','#202080','#8080E0','#808020','#E0E080','#802080','#E080E0','#208080','#80E0E0','#805020','#E0B080','#508020','#B0E080','#208050','#80E0B0','#205080','#80B0E0','#502080','#B080E0','#802050','#E080B0','#202020','#E0E0E0']\n",
    "    nb_cyc = int(np.ceil(K/len(colors_orig)))\n",
    "    colors = colors_orig*nb_cyc\n",
    "    \n",
    "    if type(labels) == type(None):\n",
    "        for j in range(int(D/2)):\n",
    "            \n",
    "            plt.figure()\n",
    "            \n",
    "            for k in range(K):\n",
    "                if len(tri_Y[k]) > 0:\n",
    "                    plt.scatter(tri_Y[k][:,2*j],tri_Y[k][:,2*j+1],label='$Y$',color=colors[2*k])\n",
    "                if len(tri_Y_hat[k]) > 0:\n",
    "                    plt.scatter(tri_Y_hat[k][:,2*j],tri_Y_hat[k][:,2*j+1],label='$\\hat{Y}$',color=colors[2*k+1])\n",
    "            \n",
    "            for n in range(N):\n",
    "                plt.plot([Y[n][2*j],Y_hat[n][2*j]],[Y[n][2*j+1],Y_hat[n][2*j+1]],color='black')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "    else :\n",
    "        for j in range(int(D/2)):\n",
    "            \n",
    "            plt.figure()\n",
    "            \n",
    "            for k in range(K):\n",
    "                if len(tri_Y[k]) > 0:\n",
    "                    plt.scatter(tri_Y[k][:,2*j],tri_Y[k][:,2*j+1],label='$Y$ - '+labels[k],color=colors[2*k])\n",
    "                if len(tri_Y_hat[k]) > 0:\n",
    "                    plt.scatter(tri_Y_hat[k][:,2*j],tri_Y_hat[k][:,2*j+1],label='$\\hat{Y} - $'+labels[k],color=colors[2*k+1])\n",
    "            \n",
    "            for n in range(N):\n",
    "                plt.plot([Y[n][2*j],Y_hat[n][2*j]],[Y[n][2*j+1],Y_hat[n][2*j+1]],color='red')\n",
    "            \n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "\n",
    "def discard(Y,iota):\n",
    "    '''Amputation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs à amputer.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, où 0 signifie que la colonne est à jeter, et 1 signifie que la colonne est à garder.\n",
    "        On note U le nombre de 1 dans iota.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y_tilde : 2-D ndarray,\n",
    "        Matrice de taille (N,U) dont les colonnes ont été amputées selon iota.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    D1 = len(iota)\n",
    "    \n",
    "    if D != D1:\n",
    "        print(\"Le nombre de dimensions ne correspond pas\")\n",
    "    else :\n",
    "        if np.any((iota-iota**2).astype(bool)):\n",
    "            print(\"Vecteur non-booléen\")\n",
    "        else :\n",
    "            Y_tilde = np.transpose(np.array([Y[:,d] for d in range(D) if iota[d]]))\n",
    "            return Y_tilde\n",
    "\n",
    "def disarg(Y,iota):\n",
    "    '''Permutation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1, opération inverse de la fonction rearg.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les colonnes sont à permuter.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, où 0 signifie que la colonne est à placer à la fin, et 1 signifie que la colonne est à placer au début.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y_tilde : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les colonnes ont été permutées selon iota.\n",
    "    '''\n",
    "    Y_v = discard(Y,iota)\n",
    "    Y_u = discard(Y,1-iota)\n",
    "    Y_tilde = np.concatenate([Y_v,Y_u],axis=1)\n",
    "    return Y_tilde\n",
    "        \n",
    "def restit(Y,iota):\n",
    "    '''Ajout de colonnes vides à une matrice de vecteurs selon un vecteur de 0 et de 1.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,U) dont les lignes sont les vecteurs à amputer.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, dont le nombre de 1 est U, où 0 signifie qu'une colonne remplie de 0 est à placer, et 1 signifie qu'une colonne de Y est à placer.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y_tilde : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les colonnes ont été aérées de 0 selon iota.\n",
    "    '''\n",
    "    N,U = np.shape(Y)\n",
    "    D = len(iota)\n",
    "    \n",
    "    if np.any((iota-iota**2).astype(bool)):\n",
    "        print(\"Vecteur non-booléen\")\n",
    "    else :\n",
    "        iota_inv = np.array([d for d in range(D) if iota[d]])\n",
    "        if len(iota_inv) != U :\n",
    "            print(\"Le nombre de dimensions ne correspond pas\")\n",
    "        else :\n",
    "            Y_tilde = np.zeros((N,D))\n",
    "            for u in range(U):\n",
    "                Y_tilde[:,iota_inv[u]] = Y[:,u]\n",
    "            return Y_tilde\n",
    "\n",
    "def rearg(Y,iota):\n",
    "    '''Permutation de colonnes d'une matrice de vecteurs selon un vecteur de 0 et de 1, opération inverse de la fonction disarg.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les colonnes sont à permuter.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, dont le nombre de 1 est U, où 0 signifie que la colonne est à prendre parmi les D-U dernières, et 1 signifie que la colonne est à prendre parmi les U premières.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y_tilde : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les colonnes ont été permutées selon iota.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    D1 = len(iota)\n",
    "    \n",
    "    if D != D1:\n",
    "        print(\"Le nombre de dimensions ne correspond pas\")\n",
    "    else :\n",
    "        if np.any((iota-iota**2).astype(bool)):\n",
    "            print(\"Vecteur non-booléen\")\n",
    "        else :\n",
    "            Dv = np.sum(iota)\n",
    "            Y_v = restit(Y[:,:Dv],iota)\n",
    "            Y_u = restit(Y[:,Dv:],1-iota)\n",
    "        \n",
    "    return Y_u + Y_v\n",
    "\n",
    "def da_matrix(iota):\n",
    "    '''Matrice de permutation associée à la permutation disarg(.,iota), inverse de la matrice ra_matrix(iota).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, où 0 signifie que la colonne est à placer à la fin, et 1 signifie que la colonne est à placer au début.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    R : 2-D ndarray,\n",
    "        Matrice de permutation carrée d'ordre D associée à la permutation disarg(.,iota).\n",
    "    '''\n",
    "    D = len(iota)\n",
    "    if np.any((iota-iota**2).astype(bool)):\n",
    "        print(\"Vecteur non-booléen\")\n",
    "    else:\n",
    "        R = np.zeros((D,D)).astype(int)\n",
    "        Dv = np.sum(iota)\n",
    "        \n",
    "        u = 0\n",
    "        v = 0\n",
    "        for d in range(D):\n",
    "            if iota[d]:\n",
    "                R[v][d] = 1\n",
    "                v += 1\n",
    "            else :\n",
    "                R[Dv+u][d] = 1\n",
    "                u += 1\n",
    "        return R\n",
    "\n",
    "def ra_matrix(iota):\n",
    "    '''Matrice de permutation associée à la permutation rearg(.,iota), inverse de la matrice da_matrix(iota).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D rempli de 0 et de 1, dont le nombre de 1 est U, où 0 signifie que la colonne est à prendre parmi les D-U dernières, et 1 signifie que la colonne est à prendre parmi les U premières.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    R : 2-D ndarray,\n",
    "        Matrice de permutation carrée d'ordre D associée à la permutation rearg(.,iota).\n",
    "    '''\n",
    "    D = len(iota)\n",
    "    if np.any((iota-iota**2).astype(bool)):\n",
    "        print(\"Vecteur non-booléen\")\n",
    "    else:\n",
    "        R = np.zeros((D,D)).astype(int)\n",
    "        Dv = np.sum(iota)\n",
    "        \n",
    "        u = 0\n",
    "        v = 0\n",
    "        for d in range(D):\n",
    "            if iota[d]:\n",
    "                R[d][v] = 1\n",
    "                v += 1\n",
    "            else :\n",
    "                R[d][Dv+u] = 1\n",
    "                u += 1\n",
    "        return R\n",
    "\n",
    "def FS_rec1(W,Z,mu,iota):\n",
    "    '''Reconstruction des vecteurs observés après (P)PCA puis sélection de variables.\n",
    "    (Adapté aux modèles (M.6.1) et (M.6.3))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, supposé être la moyenne des observations.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D, rempli de 0 et de 1, dont le nombre de 1 est U, où 0 signifie qu'une colonne remplie de 0 est à placer, et 1 signifie qu'une colonne du produit de Z par la transposée de W est à placer.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    Y_tilde = Z@np.transpose(W)\n",
    "    Y_hat = restit(Y_tilde, iota) + mu\n",
    "    \n",
    "    return Y_hat\n",
    "\n",
    "def FS_rec2(W,Z,V,X,mu,iota):\n",
    "    '''Reconstruction des vecteurs observés après RCA puis sélection de variables.\n",
    "    (Adapté aux modèles (M.6.2) et (M.6.4))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables.\n",
    "        L'algorithme s'assure que ces vecteurs sont centrés en les recentrant.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, supposé être la moyenne des observations.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D, rempli de 0 et de 1, dont le nombre de 1 est U, où 0 signifie qu'une colonne remplie de 0 est à placer, et 1 signifie qu'une colonne du produit de Z par la transposée de W est à placer.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    mu_X = np.mean(X,axis=0)\n",
    "    Xc = X - mu_X\n",
    "    \n",
    "    Y_tilde = Z@np.transpose(W)\n",
    "    Y_hat = restit(Y_tilde, iota) + Xc@np.transpose(V) + mu\n",
    "    \n",
    "    return Y_hat\n",
    "\n",
    "def FS_mixrec1(thetas,Z,omega,iotas):\n",
    "    '''Reconstruction des vecteurs observés après clustering, (P)PCA cluster par cluster, puis sélection de variables cluster par cluster.\n",
    "    (Adapté au modèle (M.6.5))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) remplie de 0 et de 1, dont chaque ligne contient U fois le nombre 1, où, pour chaque ligne, 0 signifie que, pour le cluster correspondant, une colonne remplie de 0 est à placer, et 1 signifie que, pour le cluster correspondant, une colonne du produit de Z par la transposée du W correspondant est à placer.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    N = len(omega)\n",
    "    K,D = np.shape(iotas)\n",
    "    Y_hat = np.zeros((N,D))\n",
    "    \n",
    "    for n in range(N):\n",
    "        \n",
    "        k = omega[n]\n",
    "        W,mu,sigma2 = thetas[k]\n",
    "        Y_tilde_n = np.array([W@Z[n]])\n",
    "        Y_hat[n] = (restit(Y_tilde_n,iotas[k]))[0] + mu\n",
    "    \n",
    "    return Y_hat\n",
    "\n",
    "def FS_mixrec2(thetas,Z,X,omega,iotas):\n",
    "    '''Reconstruction des vecteurs observés après clustering, RCA cluster par cluster, puis sélection de variables cluster par cluster.\n",
    "    (Adapté au modèle (M.6.6))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,V,mu,sigma2] où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables.\n",
    "        L'algorithme s'assure que ces vecteurs sont centrés en les recentrant, cluster par cluster.\n",
    "        \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) remplie de 0 et de 1, dont chaque ligne contient U fois le nombre 1, où, pour chaque ligne, 0 signifie que, pour le cluster correspondant, une colonne remplie de 0 est à placer, et 1 signifie que, pour le cluster correspondant, une colonne du produit de Z par la transposée du W correspondant est à placer.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    N = len(omega)\n",
    "    K,D = np.shape(iotas)\n",
    "    Y_hat = np.zeros((N,D))\n",
    "    \n",
    "    tri_X = ufc.tri(X,omega)\n",
    "    \n",
    "    for n in range(N):\n",
    "        \n",
    "        k = omega[n]\n",
    "        W,V,mu,sigma2 = thetas[k]\n",
    "        x = X[n] - np.mean(tri_X[k],axis=0)\n",
    "        Y_tilde_n = np.array([W@Z[n]])\n",
    "        Y_hat[n] = (restit(Y_tilde_n,iotas[k]))[0] + V@x + mu\n",
    "    \n",
    "    return Y_hat\n",
    "\n",
    "def FS_sperec1(eta,Zv,Zu,iota):\n",
    "    '''Reconstruction des vecteurs observés après clustering, sélection de variables, puis (P)PCA.\n",
    "    (Adapté au modèle (M.6.7))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,mu,nu,sigma2,tau2] où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux sur lesquels la loi des variables aléatoires change en fonction du cluster.\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux sur lesquels la loi des variables aléatoires ne change pas en fonction du cluster.\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "    \n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents dont la loi change en fonction du cluster.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables.\n",
    "        L'algorithme s'assure que ces vecteurs sont centrés en les recentrant, cluster par cluster.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille Dv+Du rempli de 0 et de 1, dont le nombre de 1 est Dv, où 0 signifie que la colonne est à prendre parmi celles du produit de Zu avec la transposée de Wu, et 1 signifie que la colonne est à prendre parmi celles du produit de Zv avec la transposée de Wv.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,Dv+Du) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    Wv,Wu,mu,nu,sigma2,tau2 = eta\n",
    "    \n",
    "    Dv,Lv = np.shape(Wv)\n",
    "    Du,Lu = np.shape(Wu)\n",
    "    N1,Lv1 = np.shape(Zv)\n",
    "    N2,Lu1 = np.shape(Zu)\n",
    "    D = len(mu)\n",
    "    \n",
    "    if N1 != N2 :\n",
    "        print(\"Erreur de dimensions sur Zv et Zu\")\n",
    "    if D != Du+Dv:\n",
    "        print(\"Erreur de dimensions sur Wu, Wv et mu\")\n",
    "    if Lv != Lv1 :\n",
    "        print(\"Erreur de dimensions sur Wv et Zv\")\n",
    "    if Lu != Lu1 :\n",
    "        print(\"Erreur de dimensions sur Wu et Zu\")\n",
    "        \n",
    "    Y_tilde = np.concatenate([Zv@np.transpose(Wv),Zu@np.transpose(Wu)],axis=1)\n",
    "    Y_hat = rearg(Y_tilde,iota) + mu\n",
    "    \n",
    "    return Y_hat\n",
    "        \n",
    "def FS_sperec2(eta,Zv,Zu,X,iota):\n",
    "    '''Reconstruction des vecteurs observés après clustering, sélection de variables, puis (P)PCA.\n",
    "    (Adapté au modèle (M.6.8))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,V,mu,nu,sigma2,tau2] où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux sur lesquels la loi des variables aléatoires change en fonction du cluster.\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux sur lesquels la loi des variables aléatoires ne change pas en fonction du cluster.\n",
    "            - V est une matrice de taille (Dv+Du,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "    \n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents dont la loi change en fonction du cluster.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents dont la loi ne change pas en fonction du cluster.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille Dv+Du rempli de 0 et de 1, dont le nombre de 1 est Dv, où 0 signifie que la colonne est à prendre parmi les Du dernières, et 1 signifie que la colonne est à prendre parmi les Dv premières.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,Dv+Du) dont les lignes sont les vecteurs reconstruits.\n",
    "    '''\n",
    "    Wv,Wu,V,mu,nu,sigma2,tau2 = eta\n",
    "    \n",
    "    Dv,Lv = np.shape(Wv)\n",
    "    Du,Lu = np.shape(Wu)\n",
    "    N1,Lv1 = np.shape(Zv)\n",
    "    N2,Lu1 = np.shape(Zu)\n",
    "    N,C = np.shape(X)\n",
    "    D1,C1 = np.shape(V)\n",
    "    D = len(mu)\n",
    "    \n",
    "    if N1 != N2 :\n",
    "        print(\"Erreur de dimensions sur Zv et Zu\")\n",
    "    if D != Du+Dv:\n",
    "        print(\"Erreur de dimensions sur Wu, Wv et mu\")\n",
    "    if Lv != Lv1 :\n",
    "        print(\"Erreur de dimensions sur Wv et Zv\")\n",
    "    if Lu != Lu1 :\n",
    "        print(\"Erreur de dimensions sur Wu et Zu\")\n",
    "    if D != D1 :\n",
    "        print(\"Erreur de dimensions sur V et mu\")\n",
    "    if N != N1 :\n",
    "        print(\"Erreur de dimensions sur Zv et X\")\n",
    "    if N != N2 :\n",
    "        print(\"Erreur de dimensions sur Zu et X\")\n",
    "    if C != C1 :\n",
    "        print(\"Erreur de dimensions sur V et X\")\n",
    "        \n",
    "    Xc = X - np.mean(X,axis=0)\n",
    "    Y_tilde = np.concatenate([Zv@np.transpose(Wv),Zu@np.transpose(Wu)],axis=1)\n",
    "    Y_hat = rearg(Y_tilde,iota) + Xc@np.transpose(V) + mu\n",
    "    \n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions utiles pour la sélection de variables (UFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''===============================================\n",
    "    Fonctions utiles pour la sélection de variables\n",
    "    ===============================================\n",
    "    \n",
    "    ================================== ==========================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- --------------------------------------------------------------------------\n",
    "    cor_emp                            Matrice de corrélation empirique des matrices de vecteurs\n",
    "    FWIR                               \"Feature-Wise Inertia Rate\" ou \"Part d'inertie, variable par variable\".\n",
    "    U_opt                              Nombre optimal de dimensions à conserver, estimé par la \"méthode du saut\".\n",
    "    iotate                             Estimation du vecteur induisant une sélection de variables\n",
    "                                       (comparaison des parts d'inerties, variable par variable).\n",
    "    iotate_2                           Estimation du vecteur induisant une sélection de variables\n",
    "                                       (comparaison des coefficients de corrélation).\n",
    "    ================================== ==========================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cor_emp(Y,Z):\n",
    "    '''Matrice de corrélation empirique des matrices de vecteurs Y et Z.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D1) dont les lignes sont des réalisations supposément indépendantes de vecteurs aléatoires de taille D.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,D2) dont les lignes sont des réalisations supposément indépendantes de vecteurs aléatoires de taille L.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Cor : 2-D ndarray,\n",
    "        Matrice de taille (D2,D1) dont le coefficient pour chaque ligne et chaque colonne est le coefficient de corrélation entre la ligne de Z et la colonne de Y correspondantes.\n",
    "    '''\n",
    "    N1,D = np.shape(Y)\n",
    "    N2,L = np.shape(Z)\n",
    "    \n",
    "    if N1 != N2:\n",
    "        print(\"Y et Z sont de tailles différentes\")\n",
    "    else :\n",
    "        N = N1\n",
    "        \n",
    "        mu_Y = np.mean(Y,axis=0)\n",
    "        vars_Y = np.var(Y,axis=0)\n",
    "        Yc = Y - mu_Y\n",
    "        \n",
    "        mu_Z = np.mean(Z,axis=0)\n",
    "        vars_Z = np.var(Z,axis=0)\n",
    "        Zc = Z - mu_Z\n",
    "        \n",
    "        Cor = 1/N *(np.diag(1/np.sqrt(vars_Z)) @ np.transpose(Zc) @ Yc @ np.diag(1/np.sqrt(vars_Y)))\n",
    "        \n",
    "        return Cor\n",
    "\n",
    "def FWIR(X,omega):\n",
    "    '''\"Feature-Wise Inertia Rate\" ou \"Part d'inertie, variable par variable\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs appartenant à différents clusters.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "       \n",
    "    Renvois\n",
    "    -------\n",
    "    I_X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont le coefficient est la part d'inertie de l'individu en ligne selon l'axe en colonne.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    N1 = len(omega)\n",
    "    \n",
    "    if N != N1:\n",
    "        print(\"X et omega n'ont pas le même nombre d'individus\")\n",
    "    else :\n",
    "        occ = ufc.occurences(omega)\n",
    "        K = len(occ)\n",
    "        if not np.all(occ):\n",
    "            print(\"Au moins un des clusters est vide\")\n",
    "        else:\n",
    "\n",
    "            tri_X = ufc.tri(X,omega)\n",
    "            M = np.array([np.mean(tri_X[k],axis=0) for k in range(K)])\n",
    "            mu_glob = np.mean(X,axis=0)\n",
    "\n",
    "            I_loc = np.array([[(X[n][d] - M[omega[n]][d])**2 for d in range(D)] for n in range(N)])\n",
    "            I_glob = np.array([[(X[n][d] - mu_glob[d])**2 for d in range(D)] for n in range(N)])\n",
    "            I_X = I_glob/I_loc\n",
    "\n",
    "            return I_X\n",
    "\n",
    "def U_opt(contrib,U_min=1,detail=False):\n",
    "    '''Nombre optimal de dimensions à conserver, estimé par la \"méthode du saut\".\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    contrib : 1-D ndarray,\n",
    "        Vecteur de taille D dont les coefficients sont d'autant plus grands que la dimension correspondante est utile pour le clustering.\n",
    "    \n",
    "    U_min : int, optional,\n",
    "        Nombre minimal de variables à conserver.\n",
    "        Mis sur 1 par défaut.\n",
    "        \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le détail graphique de l'estimation du nombre de dimensions utiles.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    U : int,\n",
    "        Nombre optimal de dimensions à conserver.\n",
    "    '''\n",
    "    D = len(contrib)\n",
    "    \n",
    "    if U_min < 1:\n",
    "        U_min = 1\n",
    "    \n",
    "    if D <= U_min:\n",
    "        print(\"D inférieur ou égal à U_min\")\n",
    "    else:\n",
    "        ordre = np.sort(contrib)\n",
    "        diff_ordre = np.concatenate([[0],ordre[1:D-U_min+1] - ordre[:D-U_min]])\n",
    "        U_star = D - int(np.argmax(diff_ordre))\n",
    "        \n",
    "        if detail:\n",
    "            \n",
    "            plt.figure()\n",
    "            plt.step(np.arange(0,D),ordre,label='Contribution')\n",
    "            plt.plot([D-U_star-1,D-U_star-1],[ordre[D-U_star-1],ordre[D-U_star]])\n",
    "            plt.plot([D-U_star-1,D-U_star-1],[ordre[D-U_star-1],0],'--',label='$U_{star}$')\n",
    "            plt.legend()\n",
    "            plt.show()\n",
    "        \n",
    "        return U_star\n",
    "\n",
    "def iotate(X,omega,U=None,detail=False):\n",
    "    '''Estimation du vecteur iota induisant une sélection de variables, en comparant les parts d'inerties, variable par variable.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs appartenant à différents clusters.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de variables à conserver.\n",
    "        Si mis sur None, le nombre de variables à conserver est estimé à partir de la fonction U_opt.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le détail graphique de la sélection de variables.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est à conserver, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N,D = np.shape(X)\n",
    "    N1 = len(omega)\n",
    "    \n",
    "    if N != N1:\n",
    "        print(\"X et omega n'ont pas le même nombre d'individus\")\n",
    "    else :\n",
    "        occ = ufc.occurences(omega)\n",
    "        K = len(occ)\n",
    "        if not np.all(occ):\n",
    "            print(\"Au moins un des clusters est vide\")\n",
    "        else:\n",
    "            I_X = FWIR(X,omega)\n",
    "            contrib = np.sum(I_X,axis=0)\n",
    "            ordre = np.sort(contrib)\n",
    "\n",
    "            if type(U) == type(None):\n",
    "                U = U_opt(contrib,detail=detail)\n",
    "\n",
    "            iota = np.array([int(contrib[d] in ordre[D-U:]) for d in range(D)])\n",
    "\n",
    "            return iota\n",
    "\n",
    "def iotate_2(Y,Z,U=None,dist=2,detail=False):\n",
    "    '''Estimation du vecteur iota induisant une sélection de variables, en comparant les coefficients de corrélation, variable par variable.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont des vecteurs latents dont la loi change selon les clusters.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de variables à conserver.\n",
    "        Si mis sur None, le nombre de variables à conserver est estimé à partir de la fonction U_opt.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    dist = int, float, or str, optional,\n",
    "        Norme utilisée pour mesurer les colonnes de la matrice de corrélation empirique.\n",
    "    \n",
    "    detail : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le détail graphique de la sélection de variables.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est à conserver, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N1,D = np.shape(Y)\n",
    "    N2,L = np.shape(Z)\n",
    "    \n",
    "    if N1 != N2:\n",
    "        print(\"Y et Z sont de tailles différentes\")\n",
    "    else :\n",
    "        N = N1\n",
    "    \n",
    "        Cor = cor_emp(Y,Z)\n",
    "        \n",
    "        if (type(dist) == int or type(dist) == float) and dist >= 1:\n",
    "            contrib = (np.sum(np.abs(Cor)**dist,axis=0))**(1/dist)\n",
    "        else :\n",
    "            if dist == 'inf':\n",
    "                contrib = np.max(np.abs(Cor),axis=0)\n",
    "            else :\n",
    "                print(\"Distance non-reconnue.\")\n",
    "            \n",
    "            \n",
    "        ordre = np.sort(contrib)\n",
    "        \n",
    "        if type(U) == type(None):\n",
    "            U = U_opt(ordre,L,detail)\n",
    "        \n",
    "        brink = ordre[D-U]\n",
    "        iota_hat = (contrib>=brink).astype(int)\n",
    "        \n",
    "        return iota_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions d'estimation, mixtures de modèles (MFA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''===============================================\n",
    "    Fonctions d'estimation pour mixtures de modèles\n",
    "    ===============================================\n",
    "    \n",
    "    ================================== ==================================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- ----------------------------------------------------------------------------------\n",
    "    obs1                               Clustering, puis PPCA appliquée sur chaque cluster (Adapté pour le modèle (M.4.1))\n",
    "    obs2                               Clustering, puis RCA appliquée sur chaque cluster (Adapté pour le modèle (M.4.2))\n",
    "    lat1                               PPCA, puis clustering (Adapté pour le modèle (M.5.1)).\n",
    "    lat2                               RCA, puis clustering (Adapté pour le modèle (M.5.2)).\n",
    "    ================================== ==================================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-20076fbd7288>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mobs1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0momega\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLapras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtempo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0momega\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "def obs1(Y,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,tempo=True):\n",
    "    '''Clustering, puis PPCA appliquée sur chaque cluster.\n",
    "    (Adapté pour le modèle (M.4.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA, cluster par cluster.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if type(K) == type(None):\n",
    "            K = clf.K_opt(Y)\n",
    "                \n",
    "        omega_hat = fun(Y,K,tempo=tempo)\n",
    "        omega_hat = clf.K_means(Y,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    reclus = [[n for n in range(N) if omega_hat[n] == k] for k in range(K)]\n",
    "    tri_Y = ufc.tri(Y,omega_hat)\n",
    "    thetas_hat = [[] for k in range(K)]\n",
    "    Z_hat = np.zeros((N,L))\n",
    "    \n",
    "    for k in range(K):\n",
    "        \n",
    "        y = tri_Y[k]\n",
    "        card_k = len(y)\n",
    "        mu_k = np.mean(y,axis=0)\n",
    "        W_k_hat, Z_k_hat, sigma2_k_hat = sfa.PPCA(y,L)\n",
    "        \n",
    "        thetas_hat[k] = [W_k_hat, mu_k, sigma2_k_hat]\n",
    "        for j in range(card_k):\n",
    "            Z_hat[reclus[k][j]] = Z_k_hat[j]\n",
    "        \n",
    "    return thetas_hat, Z_hat, omega_hat\n",
    "\n",
    "def obs2(Y,X,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,err=0.0,tempo=True):\n",
    "    '''Clustering, puis RCA appliquée sur chaque cluster.\n",
    "    (Adapté pour le modèle (M.4.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force, cluster par cluster.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,V,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la RCA, cluster par cluster.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if type(K) == type(None):\n",
    "            K = clf.K_opt(Y)\n",
    "                \n",
    "        omega_hat = fun(Y,K,tempo=tempo)\n",
    "        omega_hat = clf.K_means(Y,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    reclus = [[n for n in range(N) if omega_hat[n] == k] for k in range(K)]\n",
    "    tri_Y = ufc.tri(Y,omega_hat)\n",
    "    tri_X = ufc.tri(X,omega_hat)\n",
    "    thetas_hat = [[] for k in range(K)]\n",
    "    Z_hat = np.zeros((N,L))\n",
    "    \n",
    "    for k in range(K):\n",
    "        \n",
    "        y = tri_Y[k]\n",
    "        x = tri_X[k]\n",
    "        card_k = len(y)\n",
    "        mu_k = np.mean(y,axis=0)\n",
    "        W_k_hat, Z_k_hat, V_k_hat, sigma2_k_hat = sfa.ML_RCA(y,x,L,nb_steps=nb_steps,err=err,tempo=tempo)\n",
    "        \n",
    "        thetas_hat[k] = [W_k_hat, V_k_hat, mu_k, sigma2_k_hat]\n",
    "        for j in range(card_k):\n",
    "            Z_hat[reclus[k][j]] = Z_k_hat[j]\n",
    "        \n",
    "    return thetas_hat, Z_hat, omega_hat\n",
    "\n",
    "def lat1(Y,L=None,K=None,omega=None,fun=clf.Lapras,nb_steps=100,tempo=True,latent=True):\n",
    "    '''PPCA, puis clustering.\n",
    "    (Adapté pour le modèle (M.5.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    latent : bool, optional,\n",
    "        Si mis sur False, le clustering se fait sur la vecteurs observés.\n",
    "        Si mis sur True, le clustering se fait sur la vecteurs latents.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    W_prov, Z_prov, sigma2_hat = sfa.PPCA(Y,L)\n",
    "    D,L = np.shape(W_prov)\n",
    "    \n",
    "    D_W = np.diag(np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    D_W_inv = np.diag(1/np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    Z_hat = Z_prov @ D_W\n",
    "    W_hat = W_prov @ D_W_inv\n",
    "    \n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    eta_hat = W_hat,mu_hat,sigma2_hat\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if latent:\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Z_hat)\n",
    "\n",
    "            omega_hat = fun(Z_hat,K,tempo=tempo)\n",
    "            omega_hat = clf.K_means(Z_hat,omega_hat,nb_steps,tempo=tempo)\n",
    "        else :\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Y)\n",
    "\n",
    "            omega_hat = fun(Y,K,tempo=tempo)\n",
    "            omega_hat = clf.K_means(Y,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    tri_Z = ufc.tri(Z_hat,omega_hat)\n",
    "    thetas_hat = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        z = tri_Z[k]\n",
    "        thetas_k = sfa.MLE_Gauss(z)\n",
    "        thetas_hat.append(thetas_k)\n",
    "        \n",
    "    return eta_hat, thetas_hat, Z_hat, omega_hat\n",
    "\n",
    "def lat2(Y,X,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,err=0.0,tempo=True):\n",
    "    '''RCA, puis clustering.\n",
    "    (Adapté pour le modèle (M.5.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    latent : bool, optional,\n",
    "        Si mis sur False, le clustering se fait sur la vecteurs observés.\n",
    "        Si mis sur True, le clustering se fait sur la vecteurs latents.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    N1,C = np.shape(X)\n",
    "    W_prov, Z_prov, V_hat, sigma2_hat = sfa.ML_RCA(Y,X,L,nb_steps=nb_steps,err=err,tempo=tempo)\n",
    "    \n",
    "    D_W = np.diag(np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    D_W_inv = np.diag(1/np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    Z_hat = Z_prov @ D_W\n",
    "    W_hat = W_prov @ D_W_inv\n",
    "    \n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    eta_hat = W_hat,V_hat,mu_hat,sigma2_hat\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if type(K) == type(None):\n",
    "            K = clf.K_opt(Z_hat)\n",
    "                \n",
    "        omega_hat = fun(Z_hat,K,tempo=tempo)\n",
    "        omega_hat = clf.K_means(Z_hat,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    tri_Z = ufc.tri(Z_hat,omega_hat)\n",
    "    thetas_hat = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        z = tri_Z[k]\n",
    "        thetas_k = sfa.MLE_Gauss(z)\n",
    "        thetas_hat.append(thetas_k)\n",
    "        \n",
    "    return eta_hat, thetas_hat, Z_hat, omega_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions pour simuler les données (SIM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''====================================================\n",
    "    Fonctions pour simuler des paramètres et des données\n",
    "    ====================================================\n",
    "    \n",
    "    ================================== ======================================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- --------------------------------------------------------------------------------------\n",
    "    param_lin                          Ensemble de paramètres pour le modèle linéaire Gaussien simple (Modèle (M.1)).\n",
    "    param_cov                          Ensemble de paramètres pour le modèle linéaire Gaussien mixte (Modèle (M.2)).\n",
    "    param_obsmix_1                     Ensembles de paramètres pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens simples (Modèle (M.4.1)).\n",
    "    param_obsmix_2                     Ensembles de paramètres pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens mixtes (Modèle (M.4.2)).\n",
    "    param_latmix_1                     Ensembles de paramètres pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens simples (Modèle (M.5.1)).\n",
    "    param_latmix_2                     Ensembles de paramètres pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens mixtes (Modèle (M.5.2)).\n",
    "    noisy_param_1                      Ensemble de paramètres pour le modèle linéaire Gaussien simple\n",
    "                                       avec variables impertinentes (Modèle (M.6.1)).\n",
    "    noisy_param_2                      Ensemble de paramètres pour le modèle linéaire Gaussien mixte\n",
    "                                       avec variables impertinentes (Modèle (M.6.2)).\n",
    "    noisy_param_latmix_1               Ensembles de paramètres pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens simples, avec variables impertinentes (Modèle (M.6.3)).\n",
    "    noisy_param_latmix_2               Ensembles de paramètres pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens mixtes, avec variables impertinentes (Modèle (M.6.4)).\n",
    "    noisy_param_obsmix_1               Ensembles de paramètres pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens simples, avec variables impertinentes (Modèle (M.6.5)).\n",
    "    noisy_param_obsmix_2               Ensembles de paramètres pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens mixtes, avec variables impertinentes (Modèle (M.6.6)).\n",
    "    noisy_param_spemix_1               Ensembles de paramètres pour la mixture sur seulement certaines dimensions des\n",
    "                                       espaces observé et latent de modèles linéaires Gaussiens simples (Modèle (M.6.7)).\n",
    "    noisy_param_spemix_2               Ensembles de paramètres pour la mixture sur seulement certaines dimensions des\n",
    "                                       espaces observé et latent de modèles linéaires Gaussiens mixtes (Modèle (M.6.8)).\n",
    "    \n",
    "    sim_omega                          Vecteur aléatoire de taille rempli d'entiers positifs.\n",
    "    \n",
    "    data_lin                           Ensemble de données simulées pour le modèle linéaire Gaussien simple (Modèle (M.1)).\n",
    "    data_cov                           Ensemble de données simulées pour le modèle linéaire Gaussien mixte (Modèle (M.2)).\n",
    "    data_obsmix_1                      Ensemble de données simulées pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens simples (Modèle (M.4.1)).\n",
    "    data_obsmix_2                      Ensemble de données simulées pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens mixtes (Modèle (M.4.2)).\n",
    "    data_latmix_1                      Ensemble de données simulées pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens simples (Modèle (M.5.1)).\n",
    "    data_latmix_2                      Ensemble de données simulées pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens mixtes (Modèle (M.5.2)).\n",
    "    noisy_data_1                       Ensemble de données simulées pour le modèle linéaire Gaussien simple\n",
    "                                       avec variables impertinentes (Modèle (M.6.1)).\n",
    "    noisy_data_2                       Ensemble de données simulées pour le modèle linéaire Gaussien mixte\n",
    "                                       avec variables impertinentes (Modèle (M.6.2)).\n",
    "    noisy_data_latmix_1                Ensemble de données simulées pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens simples, avec variables impertinentes (Modèle (M.6.3)).\n",
    "    noisy_data_latmix_2                Ensemble de données simulées pour la mixture sur l'espace latent\n",
    "                                       de modèles linéaires Gaussiens mixtes, avec variables impertinentes (Modèle (M.6.4)).\n",
    "    noisy_data_obsmix_1                Ensemble de données simulées pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens simples, avec variables impertinentes (Modèle (M.6.5)).\n",
    "    noisy_data_obsmix_2                Ensemble de données simulées pour la mixture sur l'espace observé\n",
    "                                       de modèles linéaires Gaussiens mixtes, avec variables impertinentes (Modèle (M.6.6)).\n",
    "    noisy_data_spemix_1                Ensemble de données simulées pour la mixture sur seulement certaines dimensions des\n",
    "                                       espaces observé et latent de modèles linéaires Gaussiens simples (Modèle (M.6.7)).\n",
    "    noisy_data_spemix_2                Ensemble de données simulées pour la mixture sur seulement certaines dimensions des\n",
    "                                       espaces observé et latent de modèles linéaires Gaussiens mixtes (Modèle (M.6.8)).\n",
    "    ================================== ======================================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_lin(D,L,m1=0.0,m2=0.0,m3=0.0,s1=1.0,s2=1.0,s3=1.0,disp=False,orthog=True):\n",
    "    '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien simple.\n",
    "    (Modèle (M.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes d'une matrice de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²)\n",
    "        Si mis sur True, les axes principaux seront les colonnes d'une matrice de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1.0), passée par la fonction orthogonalize, puis multipliée par s1.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    mu = rd.normal(m2,s2**2,D)\n",
    "    sigma2 = rd.normal(m3,s3**2)**2\n",
    "    \n",
    "    if orthog:\n",
    "        W = rd.normal(m1,1.0,(D,L))\n",
    "        W = s1*mbu.orthogonalize(W)\n",
    "    else:\n",
    "        W = rd.normal(m1,s1**2,(D,L))\n",
    "    \n",
    "    if disp:\n",
    "        print('$W = $', W)\n",
    "        print('$\\mu = $', mu)\n",
    "        print('$\\sigma^2 = $', sigma2)\n",
    "        \n",
    "    return W, mu, sigma2\n",
    "\n",
    "def data_lin(W,mu,sigma2,N,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien simple.\n",
    "    (Modèle (M.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "        D doit être strictement supérieur à L.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, moyenne des observations.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, variance du bruit des observations.\n",
    "    \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    alors y et z sont liés par la relation suivante : y = W.z + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    D,L = np.shape(W)\n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    Y = np.array([W@z + mu + rd.normal(0,sigma2,D) for z in Z])\n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "    return Z, Y\n",
    "\n",
    "def param_cov(D,L,C,m1=0.0,m2=0.0,m3=0.0,m4=0.0,s1=1.0,s2=1.0,s3=1.0,s4=1.0,disp=False,orthog=True):\n",
    "    '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien mixte.\n",
    "    (Modèle (M.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (D,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²) et (m2,s2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (D,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1) et (m2,1), passées par la fonction orthogonalize, puis multipliées par s1 et s2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    mu = rd.normal(m3,s3**2,D)\n",
    "    sigma2 = rd.normal(m4,s4**2)**2\n",
    "    \n",
    "    if orthog:\n",
    "        W = rd.normal(m1,1.0,(D,L))\n",
    "        V = rd.normal(m2,1.0,(D,C))\n",
    "        W = s1*mbu.orthogonalize(W)\n",
    "        V = s2*mbu.orthogonalize(V)\n",
    "    else :\n",
    "        W = rd.normal(m1,s1**2,(D,L))\n",
    "        V = rd.normal(m2,s2**2,(D,C))\n",
    "    \n",
    "    if disp:\n",
    "        print('$W = $', W)\n",
    "        print('$V = $', V)\n",
    "        print('$\\mu = $', mu)\n",
    "        print('$\\sigma^2 = $', sigma2)\n",
    "        \n",
    "    return W, V, mu, sigma2\n",
    "\n",
    "def data_cov(W,V,mu,sigma2,N,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien mixte.\n",
    "    (Modèle (M.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "        D doit être strictement supérieur à L.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        D doit être supérieur ou égal à C.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, moyenne des observations.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, variance du bruit des observations.\n",
    "    \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Z.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    alors x, y et z sont liés par la relation suivante : y = W.z + V.x + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z et x, de variance sigma2*Id.\n",
    "    '''\n",
    "    D1,L = np.shape(W)\n",
    "    D2,C = np.shape(V)\n",
    "    if D1 != D2 :\n",
    "        print('Erreur de dimension sur W et V')\n",
    "    else :\n",
    "        D = D1\n",
    "        \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    E = np.ones((N,1)) @ np.array([mu]) + rd.normal(0,sigma2,(N,D))\n",
    "    \n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    \n",
    "    Y = Z@np.transpose(W) + X@np.transpose(V) + E\n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$X = $', X)\n",
    "    return Z, Y, X\n",
    "\n",
    "def sim_Lambda(D,la=1.0,p=0.1):\n",
    "    pos_def = False\n",
    "    while not pos_def:\n",
    "        P = rd.exponential(np.sqrt(la),(D,D))\n",
    "        signes = 2*rd.choice(2,(D,D)) - 1\n",
    "        Q = P * signes\n",
    "        full_LA = np.transpose(Q) @ Q\n",
    "        \n",
    "        q = np.sqrt(1-p)\n",
    "        occur1 = rd.choice(2,(D,D),p=[q,1-q])\n",
    "        occur2 = ((occur1 + np.transpose(occur1) + np.eye(D)).astype(bool)).astype(float)\n",
    "        Lambda = occur2*full_LA\n",
    "        \n",
    "        SpL,P = nla.eig(Lambda)\n",
    "        pos_def = np.all(SpL>0)\n",
    "    return Lambda\n",
    "\n",
    "def param_LRPSI(D,L,m1=0.0,m2=0.0,s1=0.0,s2=0.0,la=1.0,p=0.1,disp=False,orthog=True):\n",
    "    \n",
    "    if orthog:\n",
    "        W = rd.normal(m1,1.0,(D,L))\n",
    "        W = s1*mbu.orthogonalize(W)\n",
    "    else :\n",
    "        W = rd.normal(m1,s1**2,(D,L))\n",
    "    sigma2 = rd.normal(m2,s2**2)**2\n",
    "    Lambda = sim_Lambda(D,la,p)\n",
    "    \n",
    "    return W, Lambda, sigma2\n",
    "\n",
    "def data_LRPSI(W,Lambda,N,sigma2,disp=False):\n",
    "    D,L = np.shape(W)\n",
    "    D1,D2 = np.shape(Lambda)\n",
    "    if D1 != D2 or D1 != D :\n",
    "        print('Erreur de dimension sur W et Lambda')\n",
    "        \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    E = rd.normal(0,sigma2,(N,D))\n",
    "    X = rd.multivariate_normal(np.zeros(D),nla.inv(Lambda),N)\n",
    "    Y = Z@np.transpose(W) + X + E\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$X = $', X)\n",
    "        \n",
    "    return Z, Y, X\n",
    "\n",
    "def param_obsmix_1(K,D,L,m1=0.0,m2=0.0,m3=0.0,s1=1.0,s2=1.0,s3=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur l'espace observé de modèles linéaires Gaussiens simples.\n",
    "    (Modèle (M.4.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes de matrices de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²)\n",
    "        Si mis sur True, les axes principaux seront les colonnes de matrices de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1.0), passée par la fonction orthogonalize, puis multipliée par s1.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    thetas = [param_lin(D,L,m1,m2,m3,s1,s2,s3,disp,orthog) for k in range(K)]\n",
    "    return thetas\n",
    "\n",
    "def param_obsmix_2(K,D,L,C,m1=0.0,m2=0.0,m3=0.0,m4=0.0,s1=1.0,s2=1.0,s3=1.0,s4=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur l'espace observé de modèles linéaires Gaussiens mixtes.\n",
    "    (Modèle (M.4.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes de matrices de taille (D,L) et des matrices de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²) et (m2,s2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes de matrices de taille (D,L) et des matrices de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1) et (m2,1), passées par la fonction orthogonalize, puis multipliées par s1 et s2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster correspondant.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster correspondant.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    thetas = [param_cov(D,L,C,m1,m2,m3,m4,s1,s2,s3,s4,disp,orthog) for k in range(K)]\n",
    "    return thetas\n",
    "\n",
    "def param_obsmix_3(K,D,L,m1=0.0,m2=0.0,s1=0.0,s2=0.0,la=1.0,p=0.1,disp=False,orthog=True):\n",
    "    thetas = [param_LRPSI(D,L,m1,m2,s1,s2,la,p,disp,orthog) for k in range(K)]\n",
    "    return thetas\n",
    "\n",
    "def param_latmix_1(K,D,L,m2=0.0,m3=0.0,s2=1.0,s3=1.0,m_glob1=0.0,m_glob2=0.0,m_glob3=0.0,s_glob2=1.0,s_glob3=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur l'espace latent de modèles linéaires Gaussiens simples\n",
    "    (Modèle (M.5.1)).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    m_glob1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes d'une matrice de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1).\n",
    "        Si mis sur True, les axes principaux seront les colonnes d'une matrice de taille (D,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1), passée par la fonction orthogonalize.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob2,s_glob2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m_glob3,s_glob3²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille L dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    eta = param_lin(D,L,m_glob1,m_glob2,m_glob3,1.0,s_glob2,s_glob3,disp,orthog)\n",
    "    thetas = [param_lin(L,L,0.0,m2,m3,1.0,s2,s3,disp,orthog)[1:] for k in range(K)]\n",
    "    return eta, thetas\n",
    "\n",
    "def param_latmix_2(K,D,L,C,m3=0.0,m4=0.0,s3=1.0,s4=1.0,m_glob1=0.0,m_glob2=0.0,m_glob3=0.0,m_glob4=0.0,s_glob2=1.0,s_glob3=1.0,s_glob4=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur l'espace latent de modèles linéaires Gaussiens mixtes, avec variables impertinentes.\n",
    "    (Modèle (M.6.4))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    m_glob1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (D,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1) et (m_glob2,s_glob2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (D,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1) et (m_glob2,1), passées par la fonction orthogonalize, puis multipliées par 1.0 et s_glob2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,V,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob3,s_glob3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m_glob4,s_glob4²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille L dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    eta = param_cov(D,L,C,m_glob1,m_glob2,m_glob3,m_glob4,1.0,s_glob2,s_glob3,s_glob4,disp,orthog)\n",
    "    thetas = [param_lin(L,L,0.0,m3,m4,1.0,s3,s4,disp,orthog)[1:] for k in range(K)]\n",
    "    return eta, thetas\n",
    "\n",
    "def param_latmix_3(K,D,L,m2=0.0,m3=0.0,s2=1.0,s3=1.0,m_glob1=0.0,m_glob2=0.0,s_glob2=1.0,la=1.0,p=0.1,disp=False,orthog=True):\n",
    "    eta = param_LRPSI(D,L,m_glob1,m_glob2,1.0,s_glob2,la,p,disp,orthog)\n",
    "    thetas = [param_lin(L,L,0.0,m2,m3,1.0,s2,s3,disp,orthog)[1:] for k in range(K)]\n",
    "    return eta, thetas\n",
    "\n",
    "def sim_omega(N,K,N_min=2):\n",
    "    '''Simule d'un vecteur de taille N rempli d'entiers compris entre 0 et K-1.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    N : int,\n",
    "        Taille du vecteur à simuler.\n",
    "    \n",
    "    K : int,\n",
    "        Nombre de clusters à simuler.\n",
    "        Doit être strictement inférieur à N.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur renvoyé.\n",
    "        Mis sur 2 par défaut.\n",
    "        K*N_min doit être inférieur ou égal à N.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    '''\n",
    "    \n",
    "    if N < K*N_min:\n",
    "        K = int(N/N_min)\n",
    "    \n",
    "    nb_random = N - K*N_min\n",
    "    random_part = rd.choice(K,nb_random)\n",
    "    sorted_omega = np.concatenate([np.concatenate([k*np.ones(N_min) for k in range(K)]),random_part])\n",
    "    omega = rd.permutation(sorted_omega)\n",
    "    return omega.astype(int)\n",
    "\n",
    "def data_obsmix_1(thetas,N,N_min=0,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur l'espace observé de modèles linéaires Gaussiens simples.\n",
    "    (Modèle (M.4.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne de chaque cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations de chaque cluster.\n",
    "        D doit être strictement supérieur à L.\n",
    "        \n",
    "    N : int, optional,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur L+1 par défaut.\n",
    "        N doit être strictement supérieur à K*(L+1) et K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    k est le n-ième coefficient de omega, et [W,mu,sigma2] est k-ième ensemble de paramètres de la liste thetas,\n",
    "    alors y et z sont liés par la relation suivante : y = W.z + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    K = len(thetas)\n",
    "    D,L = np.shape(thetas[0][0])\n",
    "    \n",
    "    omega = sim_omega(N,K,int(max(L+1,N_min)))\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    Y = np.array([thetas[omega[n]][0]@Z[n] + thetas[omega[n]][1] + rd.normal(0,thetas[omega[n]][2],D) for n in range(N)])\n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\omega = $', omega)\n",
    "    return Z, omega, Y\n",
    "\n",
    "def data_obsmix_2(thetas,N,N_min=0,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur l'espace observé de modèles linéaires Gaussiens mixtes.\n",
    "    (Modèle (M.4.2)).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux du cluster correspondant.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster correspondant.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne de chaque cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations de chaque cluster.\n",
    "        D doit être strictement supérieur à L et supérieur ou égal à C.\n",
    "        \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur le max(L+1,C+1) par défaut.\n",
    "        N doit être strictement supérieur à K*(L+1), K*(C+1) et K*N_min.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Z.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    k est le n-ième coefficient de omega, et [W,V,mu,sigma2] est k-ième ensemble de paramètres de la liste thetas,\n",
    "    alors x, y et z sont liés par la relation suivante : y = W.z + V.x + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z et x, de variance sigma2*Id.\n",
    "    '''\n",
    "    K = len(thetas)\n",
    "    \n",
    "    D1,L = np.shape(thetas[0][0])\n",
    "    D2,C = np.shape(thetas[0][1])\n",
    "    \n",
    "    omega = sim_omega(N,K,int(max(L+1,C+1,N_min)))\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    if D1 != D2 :\n",
    "        print('Erreur de dimension sur W et V')\n",
    "    else :\n",
    "        D = D1\n",
    "    \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    \n",
    "    Y = np.array([thetas[omega[n]][0]@Z[n] + thetas[omega[n]][1]@X[n] + thetas[omega[n]][2] + rd.normal(0,thetas[omega[n]][3],D) for n in range(N)])\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "        \n",
    "    return Z, omega, Y, X\n",
    "\n",
    "def data_obsmix_3(thetas,N,N_min=0,disp=False):\n",
    "    \n",
    "    K = len(thetas)\n",
    "    \n",
    "    D,L = np.shape(thetas[0][0])\n",
    "    D1,D2 = np.shape(thetas[0][1])\n",
    "    if D1 != D2 or D1 != D :\n",
    "        print('Erreur de dimension sur W et Lambda')\n",
    "    \n",
    "    omega = sim_omega(N,K,int(max(L+1,N_min)))\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    X = np.array([rd.multivariate_normal(np.zeros(D),nla.inv(thetas[omega[n]][1])) for n in range(N)])\n",
    "    Y = np.array([thetas[omega[n]][0]@Z[n] + X[n] + rd.normal(0,thetas[omega[n]][2],D) for n in range(N)])\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "        \n",
    "    return Z, omega, Y, X\n",
    "\n",
    "def data_latmix_1(eta,thetas,N,N_min=2,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien mixte sur l'espace latent.\n",
    "    (Modèle (M.5.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "        D doit être strictement supérieur à L.\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    alors y et z sont liés par la relation suivante : y = W.z + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    W, mu, sigma2 = eta\n",
    "    D,L = np.shape(W)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,L))\n",
    "    Z = np.zeros((N,L))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Z[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "        \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    Y = Z@np.transpose(W) + mu + noise\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\omega = $', omega)\n",
    "    \n",
    "    return Z, omega, Y\n",
    "\n",
    "def data_latmix_2(eta,thetas,N,N_min=2,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien mixte sur l'espace latent, avec covariables.\n",
    "    (Modèle (M.5.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (D,L) dont les colonnes sont les axes principaux.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille D supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "        D doit être strictement supérieur à L et supérieur ou égal à C.\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    alors x, y et z sont liés par la relation suivante : y = W.z + V.x + mu + epsilon[n],\n",
    "    où epsilon[n] est un vecteur gaussien centré, indépendant de z et x, de variance sigma2*Id.\n",
    "    '''\n",
    "    W, V, mu, sigma2 = eta\n",
    "    D,L = np.shape(W)\n",
    "    D2,C = np.shape(V)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,L))\n",
    "    Z = np.zeros((N,L))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Z[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "        \n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    \n",
    "    Y = Z@np.transpose(W) + X@np.transpose(V) + mu + noise\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "    \n",
    "    return Z, omega, Y, X\n",
    "\n",
    "def data_latmix_3(eta,thetas,N,N_min=2,Sigma_X=None,disp=False):\n",
    "    \n",
    "    W, Lambda, mu, sigma2 = eta\n",
    "    D,L = np.shape(W)\n",
    "    D1,D2 = np.shape(Lambda)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,L))\n",
    "    Z = np.zeros((N,L))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Z[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "        \n",
    "    X = np.array([rd.multivariate_normal(np.zeros(D),nla.inv(Lambda)) for n in range(N)])\n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    \n",
    "    Y = Z@np.transpose(W) + X + mu + noise\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "    \n",
    "    return Z, omega, Y, X\n",
    "\n",
    "def noisy_param_1(D,L,U,m1=0.0,m2=0.0,m3=0.0,s1=1.0,s2=1.0,s3=1.0,disp=False,orthog=True):\n",
    "    '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien simple avec variables impertinentes.\n",
    "    (Modèle (M.6.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de variables pertinentes de l'espace observé.\n",
    "        Doit être strictement comprsi entre L et D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes d'une matrice de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²)\n",
    "        Si mis sur True, les axes principaux seront les colonnes d'une matrice de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1.0), passée par la fonction orthogonalize, puis multipliée par s1.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    mu = rd.normal(m2,s2**2,D)\n",
    "    sigma2 = rd.normal(m3,s3**2)**2\n",
    "    \n",
    "    if orthog:\n",
    "        W = rd.normal(m1,1.0,(U,L))\n",
    "        W = s1*mbu.orthogonalize(W)\n",
    "    else:\n",
    "        W = rd.normal(m1,s1**2,(U,L))\n",
    "    \n",
    "    if disp:\n",
    "        print('$W = $', W)\n",
    "        print('$\\mu = $', mu)\n",
    "        print('$\\sigma^2 = $', sigma2)\n",
    "        \n",
    "    return W, mu, sigma2\n",
    "\n",
    "def noisy_data_1(W,mu,sigma2,N,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien avec variables impertinentes.\n",
    "    (Modèle (M.6.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "        U doit être strictement supérieur à L.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, moyenne des observations.\n",
    "        D doit être strictement supérieur à U.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, variance du bruit des observations.\n",
    "    \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    et R est la matrice ra_matrix(iota), alors y et z sont liés par la relation suivante :\n",
    "    y = R.Concatenate(W.z,0_{D-U}) + mu + epsilon[n], où 0_{D-U} est le vecteur nul de taille D-U,\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    U,L = np.shape(W)\n",
    "    D = len(mu)\n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    Y_prov = Z@np.transpose(W)\n",
    "    iota_prov = np.concatenate([np.ones(U), np.zeros(D-U)]).astype(int)\n",
    "    \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    iota = rd.perumtation(iota_prov)\n",
    "    Y = restit(Y_prov,iota) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\iota = $', iota)\n",
    "    return Z, Y, iota\n",
    "\n",
    "def noisy_param_2(D,L,C,U,m1=0.0,m2=0.0,m3=0.0,m4=0.0,s1=1.0,s2=1.0,s3=1.0,s4=1.0,disp=False,orthog=True):\n",
    "     '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien mixte avec variables impertinentes.\n",
    "     (Modèle (M.6.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de variables pertinentes de l'espace observé.\n",
    "        Doit être strictement compris entre L et D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (U,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²) et (m2,s2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (U,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1) et (m2,1), passées par la fonction orthogonalize, puis multipliées par s1 et s2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    mu = rd.normal(m3,s3**2,D)\n",
    "    sigma2 = rd.normal(m4,s4**2)**2\n",
    "    \n",
    "    if orthog:\n",
    "        W = rd.normal(m1,1.0,(U,L))\n",
    "        V = rd.normal(m2,1.0,(D,C))\n",
    "        W = s1*mbu.orthogonalize(W)\n",
    "        V = s2*mbu.orthogonalize(V)\n",
    "    else:\n",
    "        W = rd.normal(m1,s1**2,(U,L))\n",
    "        V = rd.normal(m2,s2**2,(D,C))\n",
    "    \n",
    "    if disp:\n",
    "        print('$W = $', W)\n",
    "        print('$V = $', V)\n",
    "        print('$\\mu = $', mu)\n",
    "        print('$\\sigma^2 = $', sigma2)\n",
    "        \n",
    "    return W, V, mu, sigma2\n",
    "\n",
    "def noisy_data_2(W,V,mu,sigma2,N,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien avec covariables et variables impertinentes.\n",
    "    (Modèle (M.6.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "        U doit être supérieur ou égal à L.\n",
    "    \n",
    "    V : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes.\n",
    "        D doit être supérieur ou égal à C, et strictement supérieur à U.\n",
    "    \n",
    "    mu : 1-D ndarray,\n",
    "        Vecteur de taille D, moyenne des observations.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Réel positif, variance du bruit des observations.\n",
    "    \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Z.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    et R est la matrice ra_matrix(iota), alors x, y et z sont liés par la relation suivante :\n",
    "    y = R.Concatenate(W.z,0_{D-U}) + V.x + mu + epsilon[n], où 0_{D-U} est le vecteur nul de taille D-U,\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    U,L = np.shape(W)\n",
    "    D,C = np.shape(V)\n",
    "        \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    \n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    \n",
    "    Y_prov = Z@np.transpose(W)\n",
    "    iota_prov = np.concatenate([np.ones(U), np.zeros(D-U)]).astype(int)\n",
    "    \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    iota = rd.perumtation(iota_prov)\n",
    "    Y = restit(Y_prov,iota) + X@np.transpose(V) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$X = $', X)\n",
    "        print('$\\iota = $', iota)\n",
    "        \n",
    "    return Z, Y, X, iota\n",
    "\n",
    "def noisy_param_obsmix_1(K,D,L,U,m1=0.0,m2=0.0,m3=0.0,s1=1.0,s2=1.0,s3=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour le modèle linéaire Gaussien mixte sur l'espace des observations, avec variables impertinentes.\n",
    "    (Modèle (M.6.5))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de variables pertinentes de l'espace observé.\n",
    "        Doit être strictement compris entre L et D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes de matrices de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²)\n",
    "        Si mis sur True, les axes principaux seront les colonnes de matrices de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1.0), passée par la fonction orthogonalize, puis multipliée par s1.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    thetas = [noisy_param_1(D,L,U,m1,m2,m3,s1,s2,s3,disp,orthog) for k in range(K)]\n",
    "    return thetas\n",
    "\n",
    "def noisy_param_obsmix_2(K,D,L,C,U,m1=0.0,m2=0.0,m3=0.0,m4=0.0,s1=1.0,s2=1.0,s3=1.0,s4=1.0,disp=False,orthog=True):\n",
    "    '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien mixte sur l'espace observé, avec covariables et variables impertinentes.\n",
    "    (Modèle (M.6.6))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de dimensions pertinentes de l'espace observé.\n",
    "        Doit être strictement compris entre L et D.\n",
    "    \n",
    "    m1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes de matrices de taille (U,L) et des matrices de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,s1²) et (m2,s2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes de matrices de taille (U,L) et des matrices de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1,1) et (m2,1), passées par la fonction orthogonalize, puis multipliées par s1 et s2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,V,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster correspondant.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster correspondant.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    thetas = [noisy_param_2(D,L,C,U,m1,m2,m3,m4,s1,s2,s3,s4,disp,orthog) for k in range(K)]\n",
    "    return thetas\n",
    "\n",
    "def noisy_param_latmix_1(K,D,L,U,m2=0.0,m3=0.0,s2=1.0,s3=1.0,m_glob1=0.0,m_glob2=0.0,m_glob3=0.0,s_glob2=1.0,s_glob3=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur l'espace latent de modèles linéaires Gaussiens simples, avec variables impertinentes.\n",
    "    (Modèle (M.6.3))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de dimensions pertinentes de l'espace observé.\n",
    "        Doit être strictement compris entre L et D.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    m_glob1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux seront les colonnes d'une matrice de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1).\n",
    "        Si mis sur True, les axes principaux seront les colonnes d'une matrice de taille (U,L) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1), passée par la fonction orthogonalize.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob2,s_glob2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m_glob3,s_glob3²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille L dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2,s2²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3,s3²).\n",
    "    '''\n",
    "    eta = noisy_param_1(D,L,U,m_glob1,m_glob2,m_glob3,1.0,s_glob2,s_glob3,disp,orthog)\n",
    "    thetas = [param_lin(L,L,0.0,m2,m3,1.0,s2,s3,disp,orthog)[1:] for k in range(K)]\n",
    "    return eta, thetas\n",
    "\n",
    "def noisy_param_latmix_2(K,D,L,C,U,m3=0.0,m4=0.0,s3=1.0,s4=1.0,m_glob1=0.0,m_glob2=0.0,m_glob3=0.0,m_glob4=0.0,s_glob2=1.0,s_glob3=1.0,s_glob4=1.0,disp=False,orthog=True):\n",
    "    '''Simule un ensemble de paramètres pour le modèle linéaire Gaussien mixte sur l'espace latent, avec covariables et variables et variables impertinentes.\n",
    "    (Modèle (M.6.4))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    D : int,\n",
    "        Nombre de dimensions de l'espace observé.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "        Doit être strictement inférieur à D-1.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à D.\n",
    "    \n",
    "    U : int,\n",
    "        Nombre de dimensions pertinentes de l'espace observé.\n",
    "        Doit être strictement compris entre L et D.\n",
    "    \n",
    "    m3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance des vecteurs latents.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance des vecteurs latents.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    m_glob1 : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m_glob4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s_glob2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob3 : float, optional,\n",
    "        Paramètre influent sur la génération de la moyenne des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s_glob4 : float, optional,\n",
    "        Paramètre influent sur la génération de la variance du bruit des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (U,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1) et (m_glob2,s_glob2²).\n",
    "        Si mis sur True, les axes principaux et les effets fixes seront respectivement les colonnes d'une matrice de taille (U,L) et une matrice de taille (D,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob1,1) et (m_glob2,1), passées par la fonction orthogonalize, puis multipliées par 1.0 et s_glob2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,V,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille D dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m_glob3,s_glob3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m_glob4,s_glob4²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille L dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3,s3²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4,s4²).\n",
    "    '''\n",
    "    eta = noisy_param_2(D,L,C,U,m_glob1,m_glob2,m_glob3,m_glob4,1.0,s_glob2,s_glob3,s_glob4,disp,orthog)\n",
    "    thetas = [param_lin(L,L,0.0,m3,m4,1.0,s3,s4,disp,orthog)[1:] for k in range(K)]\n",
    "    return eta, thetas\n",
    "\n",
    "def noisy_data_obsmix_1(thetas,N,N_min=0,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur l'espace observé de modèles linéaires Gaussiens simples, avec variables impertinentes.\n",
    "    (Modèle (M.6.5)).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne de chaque cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations de chaque cluster.\n",
    "        On doit avoir D > U > L.\n",
    "        \n",
    "    N : int, optional,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur L+1 par défaut.\n",
    "        N doit être strictement supérieur à K*(L+1) et K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) dont chaque ligne contient U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    k est le n-ième coefficient de omega, [W,mu,sigma2] est k-ième ensemble de paramètres de la liste thetas,\n",
    "    iota est la k-ième ligne de iotas et R est la matrice ra_matrix(iota), alors y et z sont liés par la\n",
    "    relation suivante : y = R.Concatenate(W.z,0_{D-U}) + mu + epsilon[n], où 0_{D-U} est le vecteur nul de\n",
    "    taille D-U, et epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    K = len(thetas)\n",
    "    U,L = np.shape(thetas[0][0])\n",
    "    D = len(thetas[0][1])\n",
    "    \n",
    "    omega = sim_omega(N,K,int(max(L+1,N_min)))\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    iotas_prov = np.concatenate([np.ones((K,U)),np.zeros((K,D-U))],axis=1).astype(int)\n",
    "    iotas = np.array([rd.permutation(iota) for iota in iotas_prov])\n",
    "    \n",
    "    Y = drr.FS_mixrec1(thetas,Z,omega,iotas) + np.array([rd.normal(0,thetas[omega[n]][2],D) for n in range(N)])\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iotas = $', iotas)\n",
    "        \n",
    "    return Z, omega, Y, iotas\n",
    "\n",
    "def noisy_data_obsmix_2(thetas,N,N_min=0,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur l'espace observé de modèles linéaires Gaussiens mixtes, avec variables impertinentes.\n",
    "    (Modèle (M.6.6)).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster correspondant.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster correspondant.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne de chaque cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations de chaque cluster.\n",
    "        On doit avoir D > U > L, et C doit être inférieur ou égal à D.\n",
    "        \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur max(L+1,C+1) par défaut.\n",
    "        N doit être strictement supérieur à K*(L+1), K*(C+1) et K*N_min.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Z.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) dont chaque ligne contient U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    k est le n-ième coefficient de omega, [W,V,mu,sigma2] est k-ième ensemble de paramètres de la liste thetas,\n",
    "    iota est la k-ième ligne de iotas et R est la matrice ra_matrix(iota), alors x, y et z sont liés par\n",
    "    la relation suivante : y = R.Concatenate(W.z,0_{D-U}) + V.x + mu + epsilon[n], où 0_{D-U} est le vecteur nul\n",
    "    de taille D-U, et epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    K = len(thetas)\n",
    "    U,L = np.shape(thetas[0][0])\n",
    "    D,C = np.shape(thetas[0][1])\n",
    "    \n",
    "    omega = sim_omega(N,K,int(max(L+1,C+1,N_min)))\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z = rd.normal(0,1,(N,L))\n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    \n",
    "    iotas_prov = np.concatenate([np.ones((K,U)),np.zeros((K,D-U))],axis=1).astype(int)\n",
    "    iotas = np.array([rd.permutation(iota) for iota in iotas_prov])\n",
    "    \n",
    "    Y = drr.FS_mixrec2(thetas,Z,X,omega,iotas) + np.array([rd.normal(0,thetas[omega[n]][3],D) for n in range(N)])\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iotas = $', iotas)\n",
    "        \n",
    "    return Z, omega, Y, X, iotas\n",
    "\n",
    "def noisy_data_latmix_1(eta,thetas,N,N_min=2,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien mixte sur l'espace latent, avec variables impertinentes.\n",
    "    (Modèle (M.6.3))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "        On doit avoir : D > U > L.\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y et z sont les n-ièmes lignes respectives de Y et Z,\n",
    "    et R est la matrice ra_matrix(iota), alors y et z sont liés par la relation suivante :\n",
    "    y = R.Concatenate(W.z,0_{D-U}) + mu + epsilon[n], où 0_{D-U} est le vecteur nul de taille D-U,\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de z, de variance sigma2*Id.\n",
    "    '''\n",
    "    W, mu, sigma2 = eta\n",
    "    U,L = np.shape(W)\n",
    "    D = len(mu)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,L))\n",
    "    Z = np.zeros((N,L))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Z[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "        \n",
    "    Y_prov = Z@np.transpose(W)\n",
    "    iota_prov = np.concatenate([np.ones(U), np.zeros(D-U)]).astype(int)\n",
    "    \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    iota = rd.permutation(iota_prov)\n",
    "    \n",
    "    Y = drr.restit(Y_prov,iota) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iota = $', iota)\n",
    "    \n",
    "    return Z, omega, Y, iota\n",
    "\n",
    "def noisy_data_latmix_2(eta,thetas,N,N_min=2,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon le modèle linéaire Gaussien mixte sur l'espace latent, avec covariables.\n",
    "    (Modèle (M.6.4))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2], où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille D supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "        On doit avoir : D > U > L, et C doit être inférieur ou égal à D.\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    Sigma_X : 2-D ndarray, optional,\n",
    "        Matrice carrée d'ordre C, symétrique positive, de covariance des covariables.\n",
    "        Si mis sur None, prend comme valeur la matrice identité d'ordre C.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents simulés.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés obtenus.\n",
    "        \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Z.\n",
    "        \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si x, y et z sont les n-ièmes lignes respectives de X, Y et Z,\n",
    "    et R est la matrice ra_matrix(iota), alors x, y et z sont liés par la relation suivante :\n",
    "    y = R.Concatenate(W.z,0_{D-U}) + V.x + mu + epsilon[n], où 0_{D-U} est le vecteur nul de taille D-U,\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de z et x, de variance sigma2*Id.\n",
    "    '''\n",
    "    W, V, mu, sigma2 = eta\n",
    "    U,L = np.shape(W)\n",
    "    D,C = np.shape(V)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,L))\n",
    "    Z = np.zeros((N,L))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Z[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "        \n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "        \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    Y_prov = np.concatenate([Z@np.transpose(W),np.zeros((N,D-U))],axis=1)\n",
    "    iota_prov = np.concatenate([np.ones((1,U)),np.zeros((1,D-U))],axis=1).astype(int)\n",
    "    iota = rd.permutation(iota_prov)\n",
    "    \n",
    "    Y = drr.restit(Y_prov,iota) + X@np.transpose(V) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iota = $', iota)\n",
    "    \n",
    "    return Z, omega, Y, X, iota\n",
    "\n",
    "def noisy_param_spemix_1(K,Dv,Du,Lv,Lu,m1u=0.0,m1v=0.0,m2u=0.0,m2v=0.0,m2t=0.0,m3u=0.0,m3v=0.0,m3t=0.0,s1u=1.0,s1v=1.0,s2u=1.0,s2v=1.0,s2t=1.0,s3u=1.0,s3v=1.0,s3t=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur seulement certaines dimensions des espaces observé et latent de modèles linéaires Gaussiens simples.\n",
    "    (Modèle (M.6.7))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    Dv : int,\n",
    "        Nombre de dimensions de l'espace observé sur lesquelles le modèle est mixte.\n",
    "    \n",
    "    Du : int,\n",
    "        Nombre de dimensions de l'espace observé sur lesquelles le modèle n'est pas mixte.\n",
    "    \n",
    "    Lv : int,\n",
    "        Nombre de dimensions de l'espace latent sur lesquelles le modèle est mixte.\n",
    "        Doit être strictement inférieur à Dv.\n",
    "    \n",
    "    Lu : int,\n",
    "        Nombre de dimensions de l'espace latent sur lesquelles le modèle n'est pas mixte.\n",
    "        Doit être strictement inférieur à Du.\n",
    "    \n",
    "    m1u : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"non-mixtes\".\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m1v : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"mixtes\".\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2u : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m2v : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2t : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3u : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m3v : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3t : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1u : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"non-mixtes\".\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s1v : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"mixtes\".\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2u : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s2v : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2t : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3u : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s3v : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3t : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux des dimensions \"mixtes\" et \"non-mixtes\" seront respectivement les colonnes d'une matrice de taille (Dv,Lv) et (Du,Lu) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1v,s1v²) et (m1u,s1u²).\n",
    "        Si mis sur True, les axes principaux des dimensions \"mixtes\" et \"non-mixtes\" seront respectivement les colonnes d'une matrice de taille (Dv,Lv) et (Du,Lu) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1v,1) et (m1u,s1), passée par la fonction orthogonalize puis multipliée par s1v et s1u.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - mu est un vecteur de taille Dv+Du dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2t,s2t²).\n",
    "            - nu est un vecteur de taille Lu dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2u,s2u²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3t,s3t²).\n",
    "            - tau2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3u,s3u²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille Lv dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m2v,s2v²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m3v,s3v²).\n",
    "    '''\n",
    "    D = Du+Dv\n",
    "    mu = rd.normal(m2t,s2t**2,D)\n",
    "    nu = rd.normal(m2u,s2u**2,Lu)\n",
    "    sigma2 = rd.normal(m3t,s3t**2)**2\n",
    "    tau2 = rd.normal(m3u,s3u**2)**2\n",
    "    \n",
    "    thetas = [[] for k in range(K)]    \n",
    "    for k in range(K):\n",
    "        mu_k = rd.normal(m2v,s2v**2,Lv)\n",
    "        sigma2_k = rd.normal(m3v,s3v**2)**2\n",
    "        thetas[k] = [mu_k,sigma2_k]    \n",
    "    \n",
    "    if orthog:\n",
    "        Wu = rd.normal(m1u,1.0,(Du,Lu))\n",
    "        Wv = rd.normal(m1v,1.0,(Dv,Lv))\n",
    "        Wu = s1u*mbu.orthogonalize(Wu)\n",
    "        Wv = s1v*mbu.orthogonalize(Wv)\n",
    "    else:\n",
    "        Wu = rd.normal(m1u,s1u**2,(Du,Lu))\n",
    "        Wv = rd.normal(m1v,s1v**2,(Dv,Lv))\n",
    "    \n",
    "    eta = [Wv,Wu,mu,nu,sigma2,tau2]\n",
    "    \n",
    "    if disp:\n",
    "        print(\"eta =\",eta)\n",
    "        print(\"thetas =\",thetas)\n",
    "        \n",
    "    return eta, thetas\n",
    "\n",
    "def noisy_param_spemix_2(K,Dv,Du,Lv,Lu,C,m1u=0.0,m1v=0.0,m2=0.0,m3u=0.0,m3v=0.0,m3t=0.0,m4u=0.0,m4v=0.0,m4t=0.0,s1u=1.0,s1v=1.0,s2=1.0,s3u=1.0,s3v=1.0,s3t=1.0,s4u=1.0,s4v=1.0,s4t=1.0,disp=False,orthog=True):\n",
    "    '''Simule K ensembles de paramètres pour la mixture sur seulement certaines dimensions des espaces observé et latent de modèles linéaires Gaussiens mixtes.\n",
    "    (Modèle (M.6.8))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    K : int,\n",
    "        Nombre de clusters.\n",
    "    \n",
    "    Dv : int,\n",
    "        Nombre de dimensions de l'espace observé sur lesquelles le modèle est mixte.\n",
    "    \n",
    "    Du : int,\n",
    "        Nombre de dimensions de l'espace observé sur lesquelles le modèle n'est pas mixte.\n",
    "    \n",
    "    Lv : int,\n",
    "        Nombre de dimensions de l'espace latent sur lesquelles le modèle est mixte.\n",
    "        Doit être strictement inférieur à Dv.\n",
    "    \n",
    "    Lu : int,\n",
    "        Nombre de dimensions de l'espace latent sur lesquelles le modèle n'est pas mixte.\n",
    "        Doit être strictement inférieur à Du.\n",
    "    \n",
    "    C : int,\n",
    "        Nombre de dimensions des vecteurs de covariables.\n",
    "        Doit être inférieur ou égal à Dv+Du.\n",
    "    \n",
    "    m1u : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"non-mixtes\".\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m1v : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"mixtes\".\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3u : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m3v : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m3t : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4u : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    m4v : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    m4t : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs observés.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    s1u : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"non-mixtes\".\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s1v : float, optional,\n",
    "        Paramètre influent sur la génération des axes principaux des dimensions \"mixtes\".\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s2 : float, optional,\n",
    "        Paramètre influent sur la génération des effets fixes.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3u : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s3v : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s3t : float, optional,\n",
    "        Paramètre influent sur la génération des moyennes des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4u : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi ne dépend pas du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    s4v : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs latents dont la loi dépend du cluster.\n",
    "        Mis sur 1.0 par défaut.\n",
    "    \n",
    "    s4t : float, optional,\n",
    "        Paramètre influent sur la génération des variances des vecteurs observés.\n",
    "        Mis sur 1.0 par défaut.\n",
    "        \n",
    "    disp : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les paramètres obtenus.\n",
    "        Mis sur False par défaut.\n",
    "    \n",
    "    orthog : bool, optional,\n",
    "        Si mis sur False, les axes principaux des dimensions \"mixtes\" et \"non-mixtes\" et les effets fixes seront respectivement les colonnes d'une matrice de taille (Dv,Lv), (Du,Lu) et (Dv+Du,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1v,s1v²), (m1u,s1u²) et (m2,s2²).\n",
    "        Si mis sur True, les axes principaux des dimensions \"mixtes\" et \"non-mixtes\" et les effets fixes seront respectivement les colonnes d'une matrice de taille (Dv,Lv), (Du,Lu) et (Dv+Du,C) dont les coefficients seront des variables aléatoires gaussiennes i.i.d. de paramètres (m1v,1), (m1u,s1) et (m2,1) passée par la fonction orthogonalize puis multipliée par s1v, s1u et s2.\n",
    "        Mis sur True par défaut.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,V,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille Dv+Du dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3t,s3t²).\n",
    "            - nu est un vecteur de taille Lu dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3u,s3u²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4t,s4t²).\n",
    "            - tau2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4u,s4u²).\n",
    "    \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu,sigma2], où :\n",
    "            - mu est un vecteur de taille Lv dont les coefficients sont des variables aléatoires gaussiennes i.i.d. de paramètres (m3v,s3v²).\n",
    "            - sigma2 est un réel positif, obtenu en élevant au carré une variable aléatoire gaussienne de paramètres (m4v,s4v²).\n",
    "    '''\n",
    "    D = Du+Dv\n",
    "    \n",
    "    mu = rd.normal(m3t,s3t**2,D)\n",
    "    nu = rd.normal(m3u,s3u**2,Lu)\n",
    "    sigma2 = rd.normal(m4t,s4t**2)**2\n",
    "    tau2 = rd.normal(m4u,s4u**2)**2\n",
    "    \n",
    "    thetas = [[] for k in range(K)]    \n",
    "    for k in range(K):\n",
    "        mu_k = rd.normal(m3v,s3v**2,Lv)\n",
    "        sigma2_k = rd.normal(m4v,s4v**2)**2\n",
    "        thetas[k] = [mu_k,sigma2_k]    \n",
    "    \n",
    "    if orthog:\n",
    "        Wu = rd.normal(m1u,1.0,(Du,Lu))\n",
    "        Wv = rd.normal(m1v,1.0,(Dv,Lv))\n",
    "        V = rd.normal(m2,1.0,(D,C))\n",
    "        Wu = s1u*mbu.orthogonalize(Wu)\n",
    "        Wv = s1v*mbu.orthogonalize(Wv)\n",
    "        V = s2*mbu.orthogonalize(V)\n",
    "    else:\n",
    "        Wu = rd.normal(m1u,s1u**2,(Du,Lu))\n",
    "        Wv = rd.normal(m1v,s1v**2,(Dv,Lv))\n",
    "        V = rd.normal(m2,s2**2,(D,C))\n",
    "    \n",
    "    eta = [Wv,Wu,V,mu,nu,sigma2,tau2]\n",
    "    \n",
    "    if disp:\n",
    "        print(\"eta =\",eta)\n",
    "        print(\"thetas =\",thetas)\n",
    "        \n",
    "    return eta, thetas\n",
    "\n",
    "def noisy_data_spemix_1(eta,thetas,N,N_min=2,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur seulement certaines dimensions des espaces observé et latent de modèles linéaires Gaussiens simples.\n",
    "    (Modèle (M.6.7)).\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des vecteurs observés.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "        On doit avoir Dv > Lv, et Du > Lu.\n",
    "        \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents dont la loi change selon les clusters.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents dont la loi ne change pas selon les clusters.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,Dv+Du) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille Dv+Du contenant Dv fois le nombre 1 et Du fois le nombre 0, où le nombre 1 signifie que la loi des observations sur l'axe correspondant diffère selon les clusters, et le nombre 0 signifie que la loi des observations sur l'axe correspondant ne diffère pas selon les clusters.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y, zv et zu sont les n-ièmes lignes respectives de Y, Zv et Zu,\n",
    "    et R est la matrice ra_matrix(iota), alors y, zv et zu sont liés par la relation suivante :\n",
    "    y = R.Concatenate(Wv.zv,Wu.zu) + mu + epsilon[n],\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de zv et zu, de variance sigma2*Id.\n",
    "    '''\n",
    "    Wv, Wu, mu, nu, sigma2, tau2 = eta\n",
    "    Du,Lu = np.shape(Wu)\n",
    "    Dv,Lv = np.shape(Wv)\n",
    "    D = len(mu)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    if D != Du + Dv:\n",
    "        print(\"Erreur de dimensions sur Wu, Wv et mu\")\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,Lv))\n",
    "    Zv = np.zeros((N,Lv))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Zv[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "    \n",
    "    Zu = rd.normal(nu,tau2,(N,Lu))\n",
    "    \n",
    "    Y_prov = np.concatenate([Zv@np.transpose(Wv),Zu@np.transpose(Wu)],axis=1)\n",
    "    iota_prov = np.concatenate([np.ones(Dv), np.zeros(Du)]).astype(int)\n",
    "    \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    iota = rd.permutation(iota_prov)\n",
    "    \n",
    "    Y = drr.rearg(Y_prov,iota) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iota = $', iota)\n",
    "    \n",
    "    return Zv, Zu, omega, Y, iota\n",
    "\n",
    "def noisy_data_spemix_2(eta,thetas,N,N_min=2,Sigma_X=None,disp=False):\n",
    "    '''Simule un jeu de données selon la mixture sur seulement certaines dimensions des espaces observé et latent de modèles linéaires Gaussiens mixtes.\n",
    "    (Modèle (M.6.8))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,V,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des vecteurs observés.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "        On doit avoir : Dv > Lv et Du > Lu, et C doit être inférieur ou égal à Dv+Du.\n",
    "        \n",
    "    thetas : list,\n",
    "        Liste à K éléments, dont chacun est un ensemble de paramètres de la forme [mu_k,sigma2_k], où :\n",
    "            - mu_k est un vecteur de taille Lv, supposé être une moyenne locale de vecteurs latents dont la loi change selon le cluster.\n",
    "            - sigma2_k est un réel positif, supposé être une variance locale de vecteurs latents dont la loi change selon le cluster.\n",
    "           \n",
    "    N : int,\n",
    "        Nombre d'individus à simuler.\n",
    "    \n",
    "    N_min : int, optional,\n",
    "        Nombre minimal d'occurences de chaque entier entre 0 et K-1 dans le vecteur omega renvoyé.\n",
    "        Prend comme valeur 2 par défaut.\n",
    "        N doit être strictement supérieur à K*N_min.\n",
    "    \n",
    "    disp : float, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche les données simulées.\n",
    "        Mis sur False par défaut. \n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents dont la loi change selon les clusters.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents dont la loi ne change pas selon les clusters, indépendante de Zv.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,Dv+Du) dont les lignes sont les vecteurs observés obtenus.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont les vecteurs de covariables simulés, indépendante de Zv et Zu.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille Dv+Du contenant Dv fois le nombre 1 et Du fois le nombre 0, où le nombre 1 signifie que la loi des observations sur l'axe correspondant diffère selon les clusters, et le nombre 0 signifie que la loi des observations sur l'axe correspondant ne diffère pas selon les clusters.\n",
    "    \n",
    "    Pour tout n entre 0 et N-1, si y, zv et zu sont les n-ièmes lignes respectives de Y, Zv et Zu,\n",
    "    et R est la matrice ra_matrix(iota), alors y, zv et zu sont liés par la relation suivante :\n",
    "    y = R.Concatenate(Wv.zv,Wu.zu) + mu + epsilon[n],\n",
    "    et epsilon[n] est un vecteur gaussien centré, indépendant de zv et zu, de variance sigma2*Id.\n",
    "    '''\n",
    "    Wv, Wu, V, mu, nu, sigma2, tau2 = eta\n",
    "    Du,Lu = np.shape(Wu)\n",
    "    Dv,Lv = np.shape(Wv)\n",
    "    D,C = np.shape(V)\n",
    "    K = len(thetas)\n",
    "    \n",
    "    if D != Du + Dv:\n",
    "        print(\"Erreur de dimensions sur Wu, Wv et V\")\n",
    "    \n",
    "    omega = sim_omega(N,K,N_min)\n",
    "    K = int(max(omega)) + 1\n",
    "    \n",
    "    Z_orig = rd.normal(0,1,(N,Lv))\n",
    "    Zv = np.zeros((N,Lv))\n",
    "    for n in range(N):\n",
    "        k = omega[n]\n",
    "        mu_k,sigma2_k = thetas[k]\n",
    "        Zv[n] = np.sqrt(sigma2_k)*Z_orig[n] + mu_k\n",
    "    \n",
    "    Zu = rd.normal(nu,tau2,(N,Lu))\n",
    "    \n",
    "    Y_prov = np.concatenate([Zv@np.transpose(Wv),Zu@np.transpose(Wu)],axis=1)\n",
    "    iota_prov = np.concatenate([np.ones(Dv), np.zeros(Du)]).astype(int)\n",
    "    \n",
    "    noise = rd.normal(0,sigma2,(N,D))\n",
    "    iota = rd.permutation(iota_prov)\n",
    "    \n",
    "    if type(Sigma_X) == type(None) :\n",
    "        X = rd.normal(0,1,(N,C))\n",
    "    else :\n",
    "        X = rd.multivariate_normal(np.zeros(C),Sigma_X,N)\n",
    "    \n",
    "    Y = drr.rearg(Y_prov,iota) + X@np.transpose(V) + noise + mu\n",
    "    \n",
    "    if disp:\n",
    "        print('$Z = $', Z)\n",
    "        print('$Y = $', Y)\n",
    "        print('$Y = $', X)\n",
    "        print('$\\omega = $', omega)\n",
    "        print('$\\iota = $', iota)\n",
    "    \n",
    "    return Zv, Zu, omega, Y, X, iota"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fonctions de sélection de variables (FSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''======================================\n",
    "    Fonctions de la sélection de variables\n",
    "    ======================================\n",
    "    \n",
    "    ================================== ==========================================================================\n",
    "    Contient les fonctions suivantes :\n",
    "    ---------------------------------- --------------------------------------------------------------------------\n",
    "    PPCA                               Analyse en Composante Principale, puis Sélection de Variables\n",
    "                                       (Adapté pour le modèle (M.6.1)).\n",
    "    RCA                                Analyse en Composante Résiduelle (méthode itérative), puis Sélection de Variables\n",
    "                                       (Adapté pour le modèle (M.6.2)).\n",
    "    lat1                               PPCA, puis Sélection de Variables, puis clustering\n",
    "                                       (Adapté pour le modèle (M.6.3)).\n",
    "    lat2                               RCA, puis Sélection de Variables, puis clustering\n",
    "                                       (Adapté pour le modèle (M.6.4)).\n",
    "    obs1                               Clustering, puis PPCA et Sélection de Variables appliquées sur chaque cluster\n",
    "                                       (Adapté pour le modèle (M.6.5)).\n",
    "    obs2                               Clustering, puis RCA et Sélection de Variables appliquées sur chaque cluster\n",
    "                                       (Adapté pour le modèle (M.6.6)).\n",
    "    spe1                               PPCA, puis clustering, puis Sélection de Variables\n",
    "                                       (Adapté pour le modèle (M.6.7)).\n",
    "    spe2                               RCA, puis clustering, puis Sélection de Variables\n",
    "                                       (Adapté pour le modèle (M.6.8)).\n",
    "    ================================== ==========================================================================\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-98b23750a1f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mW_hac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mZ_hac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mV_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma2_hac\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miota_hat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mlat1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0momega\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLapras\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnb_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtempo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mU\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "def PPCA(Y,L=None,U=None):\n",
    "    '''Analyse en Composante Principale, puis Sélection de Variables.\n",
    "    (Adapté pour le modèle (M.6.1))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "        \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "        \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la PCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PCA.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance du bruit.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    W_hat,Z_hat,sigma2_hat = sfa.PPCA(Y,L)\n",
    "    iota_hat = ufs.iotate(Y,Z_hat,U)\n",
    "    \n",
    "    U,L = np.shape(W_hat)\n",
    "    N,D = np.shape(Y)\n",
    "    Y_tilde = drr.discard(Y,iota_hat)\n",
    "    \n",
    "    W_hac,Z_hac,sigma2_hac = sfa.PPCA(Y_tilde,L)\n",
    "    \n",
    "    return W_hac,Z_hac,sigma2_hac,iota_hat\n",
    "\n",
    "def RCA(Y,X,L,V=None,nb_steps=100,err=0.0,tempo=True,U=None):\n",
    "    '''Analyse en Composante Résiduelle (méthode itérative), puis Sélection de Variables.\n",
    "    (Adapté pour le modèle (M.6.2))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        \n",
    "    V : 2-D ndarray, optional,\n",
    "        Matrice de taille (D,C) d'effets fixes donnée en argument initial de l'algorithme itératif.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme.\n",
    "        Mis sur 1000 par défaut.\n",
    "        \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    W : 2-D ndarray,\n",
    "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la RCA.\n",
    "        \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la RCA.\n",
    "        \n",
    "    V_hat : 2-D ndarray,\n",
    "        Matrice de taille (D,C) d'effets fixes estimée par la RCA.\n",
    "    \n",
    "    sigma2 : float,\n",
    "        Estimation de la variance du bruit.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    W_hat, Z_hat, V_hat, sigma2_hat = sfa.ML_RCA(Y,X,L,V,nb_steps,err,tempo)\n",
    "    mu_X = np.mean(X,axis=0)\n",
    "    Xc = X - mu_X\n",
    "    \n",
    "    iota_hat = ufs.iotate(Y-Xc@np.transpose(V_hat),Z_hat,U)\n",
    "    D,C = np.shape(V_hat)\n",
    "    U,L = np.shape(W_hat)\n",
    "    N = len(Y)\n",
    "    Y_tilde = drr.discard(Y-Xc@np.transpose(V_hat),iota_hat)\n",
    "    \n",
    "    W_hac,Z_hac,sigma2_hac = sfa.PPCA(Y_tilde,L)\n",
    "    \n",
    "    return W_hac, Z_hac, V_hat, sigma2_hac, iota_hat\n",
    "\n",
    "def lat1(Y,L=None,K=None,omega=None,fun=clf.Lapras,nb_steps=100,tempo=True,U=None):\n",
    "    '''PPCA, puis Sélection de Variables, puis clustering.\n",
    "    (Adapté pour le modèle (M.6.3))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    W_prov,Z_prov,sigma2_hat = sfa.PPCA(Y,L)\n",
    "    D,L = np.shape(W_prov)\n",
    "    \n",
    "    D_W = np.diag(np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    D_W_inv = np.diag(1/np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    Z_hat = Z_prov @ D_W\n",
    "    W_hat = W_prov @ D_W_inv\n",
    "    \n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    \n",
    "    iota_hat = ufs.iotate(Y,Z_hat,U)\n",
    "    \n",
    "    U = np.sum(iota_hat)\n",
    "    Y_tilde = drr.discard(Y,iota_hat)\n",
    "    \n",
    "    W_hac,Z_hac,sigma2_hac = sfa.PPCA(Y_tilde,L)\n",
    "        \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if type(K) == type(None):\n",
    "            K = clf.K_opt(Z_hac)\n",
    "                \n",
    "        omega_hat = fun(Z_hac,K,tempo=tempo)\n",
    "        omega_hat = clf.K_means(Z_hac,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    tri_Z = ufc.tri(Z_hac,omega_hat)\n",
    "    thetas_hac = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        z = tri_Z[k]\n",
    "        thetas_k = sfa.MLE_Gauss(z)\n",
    "        thetas_hac.append(thetas_k)\n",
    "    \n",
    "    Y_hat = drr.FS_rec2(W_hac,Z_hac,mu_hat,iota_hat)\n",
    "    sigma2_hac = np.mean((Y-Y_hat)**2)\n",
    "    eta_hac = W_hac,mu_hat,sigma2_hac\n",
    "    \n",
    "    return eta_hac, thetas_hac, Z_hac, omega_hat, iota_hat\n",
    "\n",
    "def lat2(Y,X,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,err=0.0,tempo=True,U=None):\n",
    "    '''RCA, puis Sélection de Variables, puis clustering.\n",
    "    (Adapté pour le modèle (M.6.4))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "    \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "    \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations.\n",
    "            \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    N1,C = np.shape(X)\n",
    "    W_prov, Z_prov, V_hat, sigma2_hat = sfa.ML_RCA(Y,X,L,nb_steps=nb_steps,err=err,tempo=tempo)\n",
    "    \n",
    "    D_W = np.diag(np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    D_W_inv = np.diag(1/np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "    Z_hat = Z_prov @ D_W\n",
    "    W_hat = W_prov @ D_W_inv\n",
    "    \n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    mu_X = np.mean(X,axis=0)\n",
    "    Xc = X - mu_X\n",
    "    \n",
    "    iota_hat = ufs.iotate(Y-Xc@np.transpose(V_hat),Z_hat,U)\n",
    "    \n",
    "    U = np.sum(iota_hat)\n",
    "    Y_tilde = drr.discard(Y-Xc@np.transpose(V_hat),iota_hat)\n",
    "    \n",
    "    W_hac,Z_hac,sigma2_hac = sfa.PPCA(Y_tilde,L)\n",
    "    \n",
    "    if type(omega) == type(None):\n",
    "        \n",
    "        if type(K) == type(None):\n",
    "            K = clf.K_opt(Z_hac)\n",
    "                \n",
    "        omega_hat = fun(Z_hac,K,tempo=tempo)\n",
    "        omega_hat = clf.K_means(Z_hac,omega_hat,nb_steps,tempo=tempo)\n",
    "    \n",
    "    else:\n",
    "        omega_hat = omega.copy()\n",
    "        K = int(max(omega) + 1)\n",
    "    \n",
    "    tri_Z = ufc.tri(Z_hac,omega_hat)\n",
    "    thetas_hat = []\n",
    "    \n",
    "    for k in range(K):\n",
    "        z = tri_Z[k]\n",
    "        thetas_k = sfa.MLE_Gauss(z)\n",
    "        thetas_hat.append(thetas_k)\n",
    "    \n",
    "    Y_hat = drr.FS_rec2(W_hac,Z_hac,V_hat,X,mu_hat,iota_hat)\n",
    "    sigma2_hac = np.mean((Y-Y_hat)**2)\n",
    "    eta_hac = W_hac,V_hat,mu_hat,sigma2_hac\n",
    "        \n",
    "    return eta_hac, thetas_hat, Z_hac, omega_hat, iota_hat\n",
    "\n",
    "def obs1(Y,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,tempo=True,U=None):\n",
    "    '''Clustering, puis PPCA appliquée sur chaque cluster, puis Sélection de Variables sur chaque cluster.\n",
    "    (Adapté pour le modèle (M.6.5))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions de l'espace latent.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la PPCA, cluster par cluster.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) dont chaque ligne contient U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    thetas_hat, Z_hat, omega_hat = mfa.obs1(Y,L,K,omega,fun,nb_steps,tempo)\n",
    "    \n",
    "    K = len(thetas_hat)\n",
    "    tri_Y = ufc.tri(Y,omega_hat)\n",
    "    tri_Z = ufc.tri(Z_hat,omega_hat)\n",
    "    \n",
    "    iotas_hat = np.zeros((K,D)).astype(int)\n",
    "    reclus = ufc.tri((np.arange(N)).astype(int),omega_hat)\n",
    "    Z_hac = np.zeros((N,L))\n",
    "    thetas_hac = [[] for k in range(K)]\n",
    "    \n",
    "    for k in range(K):\n",
    "        \n",
    "        Y_k = tri_Y[k]\n",
    "        Z_k = tri_Z[k]\n",
    "        card_k = len(Y_k)\n",
    "        \n",
    "        mu_k_hac = np.mean(Y_k,axis=0)\n",
    "        iota_k_hat = ufs.iotate(Y_k,Z_k,U)\n",
    "        iotas_hat[k] = iota_k_hat\n",
    "        U = np.sum(iota_k_hat)\n",
    "        \n",
    "        Y_k_tilde = drr.discard(Y_k,iota_k_hat)\n",
    "        W_k_hac, Z_k_hac, sigma2_k_hac = sfa.PPCA(Y_k_tilde,L)\n",
    "        \n",
    "        for j in range(card_k):\n",
    "            Z_hac[reclus[k][j]] = Z_k_hac[j]\n",
    "        \n",
    "        Y_k_hac = drr.FS_rec1(W_k_hac,Z_k_hac,mu_k_hac,iota_k_hat)\n",
    "        sigma2_k_hac = np.mean((Y_k-Y_k_hac)**2)\n",
    "            \n",
    "        thetas_hac[k] = [W_k_hac,mu_k_hac,sigma2_k_hac]\n",
    "        \n",
    "    return thetas_hac, Z_hac, omega_hat, iotas_hat\n",
    "\n",
    "def obs2(Y,X,L,K=None,omega=None,fun=clf.Lapras,nb_steps=100,err=0.0,tempo=True,U=None):\n",
    "    '''Clustering, puis RCA appliquée sur chaque cluster, puis Sélection de Variables sur chaque cluster.\n",
    "    (Adapté pour le modèle (M.6.6))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force, cluster par cluster.\n",
    "    \n",
    "    L : int,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "    \n",
    "    nb_steps : int, optional,\n",
    "        Nombre maximal d'itérations de l'algorithme K-means.\n",
    "        Mis sur 100 par défaut.\n",
    "        \n",
    "    err : float, optional,\n",
    "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
    "        Mis sur 0.0 par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    U : int, optional,\n",
    "        Nombre de dimensions pertinentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de U renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [W,V,mu,sigma2] où :\n",
    "            - W est une matrice de taille (U,L) dont les colonnes sont les axes principaux du cluster.\n",
    "            - V est la matrice de taille (D,C) d'effets fixes du cluster.\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des observations du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des observations du cluster.\n",
    "            \n",
    "    Z : 2-D ndarray,\n",
    "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la RCA, cluster par cluster.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iotas : 2-D ndarray,\n",
    "        Matrice de taille (K,D) dont chaque ligne contient U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la dimension correspondante est pertinente, et le nombre 0 signifie qu'elle ne l'est pas.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    thetas_hat, Z_hat, omega_hat = mfa.obs2(Y,X,L,K,omega,fun,nb_steps,tempo)\n",
    "    \n",
    "    K = len(thetas_hat)\n",
    "    tri_Y = ufc.tri(Y,omega_hat)\n",
    "    tri_Z = ufc.tri(Z_hat,omega_hat)\n",
    "    tri_X = ufc.tri(X,omega_hat)\n",
    "    \n",
    "    iotas_hat = np.zeros((K,D)).astype(int)\n",
    "    reclus = ufc.tri((np.arange(N)).astype(int),omega_hat)\n",
    "    Z_hac = np.zeros((N,L))\n",
    "    thetas_hac = [[] for k in range(K)]\n",
    "    \n",
    "    for k in range(K):\n",
    "        \n",
    "        Y_k = tri_Y[k]\n",
    "        Z_k = tri_Z[k]\n",
    "        X_k = tri_X[k]\n",
    "        card_k = len(Y_k)\n",
    "        W_k_hat, V_k_hat, mu_k_hat, sigma_2_k_hat = thetas_hat[k]\n",
    "        \n",
    "        mu_k_hac = np.mean(Y_k,axis=0)\n",
    "        mu_k_X = np.mean(X_k,axis=0)\n",
    "        Xc_k = X_k - mu_k_X\n",
    "        \n",
    "        iota_k_hat = ufs.iotate(Y_k-Xc_k@np.transpose(V_k_hat),Z_k,U)\n",
    "        iotas_hat[k] = iota_k_hat\n",
    "        U = np.sum(iota_k_hat)\n",
    "        \n",
    "        Y_k_tilde = drr.discard(Y_k-Xc_k@np.transpose(V_k_hat),iota_k_hat)\n",
    "        W_k_hac, Z_k_hac, sigma2_k_hac = sfa.PPCA(Y_k_tilde,L)\n",
    "        \n",
    "        for j in range(card_k):\n",
    "            Z_hac[reclus[k][j]] = Z_k_hac[j]\n",
    "        \n",
    "        Y_k_hac = drr.FS_rec2(W_k_hac,Z_k_hac,V_k_hat,Xc_k,mu_k_hac,iota_k_hat)\n",
    "        sigma2_k_hac = np.mean((Y_k-Y_k_hac)**2)\n",
    "            \n",
    "        thetas_hac[k] = [W_k_hac,V_k_hat,mu_k_hac,sigma2_k_hac]\n",
    "        \n",
    "    return thetas_hac, Z_hac, omega_hat, iotas_hat\n",
    "\n",
    "def spe1(Y,L=None,K=None,omega=None,fun=clf.Lapras,tempo=True,latent=True,Dv=None,Lv=None):\n",
    "    '''PPCA, puis clustering, puis Sélection de Variables.\n",
    "    (Adapté pour le modèle (M.6.7))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    latent : bool, optional,\n",
    "        Si mis sur False, le clustering se fait sur la vecteurs observés.\n",
    "        Si mis sur True, le clustering se fait sur la vecteurs latents.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Dv : int, optional,\n",
    "        Nombre de dimensions pertinentes de l'espace observé souhaité.\n",
    "        Doit être inférieur ou égal à D.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None ou strictement supérieur à D, utilise la valeur de Dv renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Lv : int, optional,\n",
    "        Nombre de dimensions pertinentes de l'espace observé souhaité.\n",
    "        Doit être inférieur ou égal à L.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None ou strictement supérieur à L, utilise la valeur de Lv renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des vecteurs observés.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "        \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents obtenus par la PPCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la loi des variables aléatoires diffère selon les clusters sur la dimension correspondante, et le nombre 0 signifie qu'elle ne diffère pas selon les clusters sur la dimension correspondante.\n",
    "    '''\n",
    "    N,D = np.shape(Y)    \n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    \n",
    "    if type(L) != type(None) and L >= D:\n",
    "        print(\"L >= D\")\n",
    "        L = None\n",
    "    \n",
    "    if type(Dv) != type(None) and Dv > D:\n",
    "        print(\"Dv > D\")\n",
    "        Dv = None\n",
    "    \n",
    "    if latent :\n",
    "        \n",
    "        W_prov, Z_prov, sigma2_hat = sfa.PPCA(Y,L)\n",
    "        N,L = np.shape(Z_prov)\n",
    "        \n",
    "        D_W = np.diag(np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "        D_W_inv = np.diag(1/np.array([mbu.norme(W_prov[:,l]) for l in range(L)]))\n",
    "        Z_hat = Z_prov @ D_W\n",
    "        W_hat = W_prov @ D_W_inv\n",
    "        \n",
    "        if type(Lv) != type(None) and Lv > L:\n",
    "            print(\"Lv > L\")\n",
    "            Lv = None\n",
    "            \n",
    "        if type(omega) == type(None):\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Z_hat)\n",
    "            omega_hat = fun(Z_hat,K,tempo=tempo)\n",
    "        else:\n",
    "            omega_hat = omega\n",
    "        \n",
    "        iota_lat = ufs.iotate(Z_hat,omega_hat,Lv)\n",
    "        Lv = np.sum(iota_lat)\n",
    "        Lu = L-Lv\n",
    "        tZu_hat,tZv_hat = ufc.tri(np.transpose(Z_hat),iota_lat)\n",
    "        Zu_hat = np.transpose(tZu_hat)\n",
    "        Zv_hat = np.transpose(tZv_hat)\n",
    "        \n",
    "        iota_hat = ufs.iotate_2(Y,Zv_hat,Dv)\n",
    "        \n",
    "    else:\n",
    "        if type(omega) == type(None):\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Y)\n",
    "            omega_hat = fun(Y,K,tempo=tempo)\n",
    "        else:\n",
    "            omega_hat = omega\n",
    "        iota_hat = ufs.iotate(Y,omega_hat,Dv)\n",
    "    \n",
    "    Dv = np.sum(iota_hat)\n",
    "    tYu,tYv = ufc.tri(np.transpose(Y),iota_hat)\n",
    "    Yu = np.transpose(tYu)\n",
    "    Yv = np.transpose(tYv)\n",
    "\n",
    "    etav_hat, thetas_hat, Zv_hat, omega_hat = mfa.lat1(Yv,L=Lv,omega=omega_hat,tempo=tempo)\n",
    "    Wv_hat = etav_hat[0]\n",
    "    \n",
    "    if type(L) != None and type(Lv) != None and L>=Lv:\n",
    "        Lu = L - Lv\n",
    "    else :\n",
    "        Lu = None\n",
    "    \n",
    "    Wu_hat, Zu_hat, tau2_usef = sfa.PPCA(Yu,Lu)\n",
    "    nu_hat, tau2_hat = sfa.MLE_Gauss(Zu_hat)\n",
    "    \n",
    "    eta_hac = [Wv_hat,Wu_hat,mu_hat,nu_hat,0.0,tau2_hat]\n",
    "    Y_hat = drr.FS_sperec1(eta_hac,Zv_hat,Zu_hat,iota_hat)\n",
    "    eta_hac[4] = np.mean((Y-Y_hat)**2)\n",
    "    \n",
    "    return eta_hac, thetas_hat, Zv_hat, Zu_hat, omega_hat, iota_hat\n",
    "\n",
    "def spe2(Y,X,L,K=None,omega=None,fun=clf.Lapras,V=None,nb_steps=100,err=0.0,tempo=True,latent=True,Dv=None,Lv=None):\n",
    "    '''RCA, puis clustering, puis Sélection de Variables.\n",
    "    (Adapté pour le modèle (M.6.8))\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    Y : 2-D ndarray,\n",
    "        Matrice de taille (N,D) dont les lignes sont des vecteurs observés.\n",
    "    \n",
    "    X : 2-D ndarray,\n",
    "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
    "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
    "    \n",
    "    L : int, optional,\n",
    "        Nombre de dimensions latentes souhaité.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None, utilise la valeur de L renvoyée par la fonction L_opt.\n",
    "    \n",
    "    K : int, optional,\n",
    "        Nombre de clusters à identifier.\n",
    "        Si omega et K sont mis sur None, le nombre de clusters à identifier est estimé à partir de la fonction K_opt.\n",
    "        Si omega est renseigné mais pas K, K prend la valuer du coefficient maximal de omega + 1.\n",
    "        Mis sur None par défaut.\n",
    "    \n",
    "    omega : 1-D ndarray, optional,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "        Si mis sur None, omega est estimé à l'aide d'un algorithme de clustering.\n",
    "        Mis sur None par défaut.\n",
    "        \n",
    "    fun : function, optional,\n",
    "        Fonction de clustering à utiliser.\n",
    "        Mis sur clf.Lapras() par défaut.\n",
    "        \n",
    "    tempo : bool, optional,\n",
    "        Si mis sur False, ne sert à rien.\n",
    "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme K-means.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    latent : bool, optional,\n",
    "        Si mis sur False, le clustering se fait sur la vecteurs observés.\n",
    "        Si mis sur True, le clustering se fait sur la vecteurs latents.\n",
    "        Mis sur True par défaut.\n",
    "    \n",
    "    Dv : int, optional,\n",
    "        Nombre de dimensions pertinentes de l'espace observé souhaité.\n",
    "        Doit être inférieur ou égal à D.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None ou strictement supérieur à D, utilise la valeur de Dv renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Lv : int, optional,\n",
    "        Nombre de dimensions pertinentes de l'espace observé souhaité.\n",
    "        Doit être inférieur ou égal à L.\n",
    "        Mis sur None par défaut.\n",
    "        Si mis sur None ou strictement supérieur à L, utilise la valeur de Lv renvoyée par la fonction U_opt.\n",
    "    \n",
    "    Renvois\n",
    "    -------\n",
    "    eta : list,\n",
    "        Liste de paramètres de la forme [Wv,Wu,V,mu,nu,sigma2,tau2], où :\n",
    "            - Wv est une matrice de taille (Dv,Lv) dont les colonnes sont les axes principaux des dimensions \"mixtes\".\n",
    "            - Wu est une matrice de taille (Du,Lu) dont les colonnes sont les axes principaux des dimensions \"non-mixtes\".\n",
    "            - V est une matrice de taille (D,C) d'effets fixes.\n",
    "            - mu est un vecteur de taille Dv+Du, supposé être la moyenne des vecteurs observés.\n",
    "            - nu est un vecteur de taille Lu, supposé être la moyenne des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance du bruit des vecteurs observés.\n",
    "            - tau2 est un réel positif, supposé être la variance des vecteurs latents dont la loi ne change pas selon le cluster.\n",
    "        \n",
    "    thetas : list,\n",
    "        Liste de K éléments, dont chaque élément est une liste de paramètres de la forme [mu,sigma2] où :\n",
    "            - mu est un vecteur de taille D, supposé être la moyenne des vecteurs du cluster.\n",
    "            - sigma2 est un réel positif, supposé être la variance des vecteurs du cluster.\n",
    "            \n",
    "    Zv : 2-D ndarray,\n",
    "        Matrice de taille (N,Lv) dont les lignes sont les vecteurs latents obtenus par la RCA.\n",
    "    \n",
    "    Zu : 2-D ndarray,\n",
    "        Matrice de taille (N,Lu) dont les lignes sont les vecteurs latents obtenus par la RCA.\n",
    "    \n",
    "    omega : 1-D ndarray,\n",
    "        Vecteur de taille N dont, pour tout n entre 0 et N-1, la n-ième valeur est un entier entre 0 et K-1 indiquant le numéro du cluster auquel appartient le n-ième individu.\n",
    "    \n",
    "    iota : 1-D ndarray,\n",
    "        Vecteur de taille D contenant U fois le nombre 1 et D-U fois le nombre 0, où le nombre 1 signifie que la loi des variables aléatoires diffère selon les clusters sur la dimension correspondante, et le nombre 0 signifie qu'elle ne diffère pas selon les clusters sur la dimension correspondante.\n",
    "    '''\n",
    "    N,D = np.shape(Y)\n",
    "    N1,C = np.shape(X)\n",
    "    mu_hat = np.mean(Y,axis=0)\n",
    "    Xc = X - np.mean(X,axis=0)\n",
    "    \n",
    "    if type(Dv) != type(None) and Dv > D:\n",
    "        print(\"Dv > D\")\n",
    "        Dv = None\n",
    "    \n",
    "    if type(Lv) != type(None) and Lv > L:\n",
    "            print(\"Lv > L\")\n",
    "            Lv = None\n",
    "    \n",
    "    if latent :\n",
    "        \n",
    "        W_hat, Z_hat, V_hat, sigma2_hat = sfa.ML_RCA(Y,X,L,V,nb_steps,err,tempo)\n",
    "            \n",
    "        if type(omega) == type(None):\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Z_hat)\n",
    "            omega_hat = fun(Z_hat,K,tempo=tempo)\n",
    "        else:\n",
    "            omega_hat = omega\n",
    "        \n",
    "        iota_lat = ufs.iotate(Z_hat,omega_hat,Lv)\n",
    "        Lv = np.sum(iota_lat)\n",
    "        Lu = L-Lv\n",
    "        tZu_hat,tZv_hat = ufc.tri(np.transpose(Z_hat),iota_lat)\n",
    "        Zu_hat = np.transpose(tZu_hat)\n",
    "        Zv_hat = np.transpose(tZv_hat)\n",
    "        iota_hat = ufs.iotate_2(Y-Xc@np.transpose(V_hat),Zv_hat,Dv)\n",
    "        \n",
    "    else:\n",
    "        if type(omega) == type(None):\n",
    "            if type(K) == type(None):\n",
    "                K = clf.K_opt(Y)\n",
    "            omega_hat = fun(Y,K,tempo=tempo)\n",
    "        else:\n",
    "            omega_hat = omega\n",
    "        iota_hat = ufs.iotate(Y,omega_hat,Dv)\n",
    "    \n",
    "    Dv = np.sum(iota_hat)\n",
    "    tYu,tYv = ufc.tri(np.transpose(Y-Xc@np.transpose(V_hat)),iota_hat)\n",
    "    Yu = np.transpose(tYu)\n",
    "    Yv = np.transpose(tYv)\n",
    "\n",
    "    etav_hat, thetas_hat, Zv_hat, omega_hat = mfa.lat1(Yv,L=Lv,omega=omega_hat,tempo=tempo)\n",
    "    Wv_hat = etav_hat[0]\n",
    "    \n",
    "    N,Lv = np.shape(Zv_hat)\n",
    "    Lu = L-Lv\n",
    "    \n",
    "    Wu_hat, Zu_hat, tau2_usef = sfa.PPCA(Yu,Lu)\n",
    "    nu_hat, tau2_hat = sfa.MLE_Gauss(Zu_hat)\n",
    "    \n",
    "    eta_hac = [Wv_hat,Wu_hat,V_hat,mu_hat,nu_hat,0.0,tau2_hat]\n",
    "    Y_hat = drr.FS_sperec2(eta_hac,Zv_hat,Zu_hat,X,iota_hat)\n",
    "    eta_hac[5] = np.mean((Y-Y_hat)**2)\n",
    "    \n",
    "    return eta_hac, thetas_hat, Zv_hat, Zu_hat, omega_hat, iota_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydoc as doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pydoc?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function norme in module __main__:\n",
      "\n",
      "norme(x)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "doc.help(norme)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paramètres\n",
    "\n",
    "N1 = 200\n",
    "Dv1 = 12\n",
    "Du1 = 8\n",
    "D1 = Dv1+Du1\n",
    "D1 = 20\n",
    "Lv1 = 5\n",
    "Lu1 = 3\n",
    "L1 = Lv1+Lu1\n",
    "L1 = 10\n",
    "C1 = 4\n",
    "K1 = 5\n",
    "U1 = 8\n",
    "\n",
    "K_tab = 2**np.arange(1,5)\n",
    "\n",
    "eps = 1/10**6\n",
    "la = 1.0\n",
    "p = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mbu' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-6bc99f7bb666>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_latmix_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_glob3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-b5e3efd78cf6>\u001b[0m in \u001b[0;36mparam_latmix_1\u001b[1;34m(K, D, L, m2, m3, s2, s3, m_glob1, m_glob2, m_glob3, s_glob2, s_glob3, disp, orthog)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mparam_latmix_1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob1\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_glob2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_glob3\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morthog\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 133\u001b[1;33m     \u001b[0meta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_lin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm_glob3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_glob2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms_glob3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morthog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    134\u001b[0m     \u001b[0mthetas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mparam_lin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdisp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0morthog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthetas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-b5e3efd78cf6>\u001b[0m in \u001b[0;36mparam_lin\u001b[1;34m(D, L, m1, m2, m3, s1, s2, s3, disp, orthog)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0morthog\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ms1\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mmbu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morthogonalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mW\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0ms1\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mD\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mbu' is not defined"
     ]
    }
   ],
   "source": [
    "eta,thetas = param_latmix_1(K1,D1,L1,s_glob3=0.5,s2=2.0,s3=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat,Z_hat,sigma2_hat = PPCA(Yc,L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W,V,mu,sigma2 = sim_param_cov(D1,L1,C1,s1=2.0,s2=2.0,s4=0.5)\n",
    "Z,Y,X = sim_data_cov(W,V,mu,sigma2,N1)\n",
    "Sigma = X@np.transpose(X) + sigma2*np.eye(N1)\n",
    "Yc = Y - mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_hat,Z_hat,V_hat,Sigma_hat,sigma2_hat = ML_RCA(Y,X,L1,err=eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XtV = X@np.transpose(V)\n",
    "XtV_hat = X@np.transpose(V_hat)\n",
    "\n",
    "for d in range(int(D1/2)):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.scatter(XtV[:,2*d],XtV[:,2*d+1],label='$X.^t \\check{V}$')\n",
    "    plt.scatter(XtV_hat[:,2*d],XtV_hat[:,2*d+1],label='$X.^t \\hat{V}$')\n",
    "    \n",
    "    for n in range(N1):\n",
    "        plt.plot([XtV[n][2*d],XtV_hat[n][2*d]],[XtV[n][2*d+1],XtV_hat[n][2*d+1]],color='red')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZtW = Z@np.transpose(W)\n",
    "ZtW_hat = Z_hat@np.transpose(W_hat)\n",
    "\n",
    "for d in range(int(D1/2)):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    plt.scatter(ZtW[:,2*d],ZtW[:,2*d+1],label='$Z.^tW$')\n",
    "    plt.scatter(ZtW_hat[:,2*d],ZtW_hat[:,2*d+1],label='$Z.^t \\hat{W}$')\n",
    "    \n",
    "    for n in range(N1):\n",
    "        plt.plot([ZtW[n][2*d],ZtW_hat[n][2*d]],[ZtW[n][2*d+1],ZtW_hat[n][2*d+1]],color='red')\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "W_hat,Z_hat,V_hat,Sigma_hat,mu_hat = ML_RCA(Y,X,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_hat, thetas_hat, Zv_hat, Zu_hat, omega_hat, iota_hat = FS_MFA_spe1(Y,L1,K1,fun=K_means_FPC,Dv=Dv1,Lv=Lv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hat = FS_sperec1(eta_hat,Zv_hat,Zu_hat,iota_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ARS(omega,omega_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iota)\n",
    "print(iota_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MFA_graph(Y,Y_hat,omega_hat,omega=omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette fonction ne marche pas à cause d'un problème de rang\n",
    "def EM_RCA(Y,X,L,V=None,Lambda=None,la=None,sigma2=None,nb_steps=1000,err=0.0,tempo=True):\n",
    "    \n",
    "    N1,D = np.shape(Y)\n",
    "    N2,C = np.shape(X)\n",
    "    \n",
    "    if N1 != N2 :\n",
    "        print('Erreur de dimensions sur Y et X')\n",
    "        S, W, Z = PCA(Y,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        return W, Z, sigma2\n",
    "    else :\n",
    "        N = N1\n",
    "    \n",
    "    #Centrage de Y et X\n",
    "    mY = np.mean(Y,axis=0)\n",
    "    mX = np.mean(X,axis=0)\n",
    "    Yc = np.array([y-mY for y in Y])\n",
    "    Xc = np.array([x-mX for x in X])\n",
    "    \n",
    "    #Initialisation\n",
    "    \n",
    "    if type(V) != type(None) :\n",
    "        \n",
    "        #Copie de V s'il est donné\n",
    "        V_hat = V.copy()\n",
    "    \n",
    "    #Estimation de V sinon\n",
    "    else :\n",
    "        #Initialisation\n",
    "        S, W, Z = PCA(Yc,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        Sigma_hat = Xc@np.transpose(Xc) + sigma2 * np.eye(N)\n",
    "        V_hat = V_estimator(Yc,Xc,Sigma_hat)\n",
    "        \n",
    "        dist = err+1\n",
    "        t = 0\n",
    "        \n",
    "        #Boucle\n",
    "        while dist > err and t < nb_steps :\n",
    "            new_Sigma = Sigma_estimator(Yc,Xc,V_hat,L)\n",
    "            new_V = V_estimator(Yc,Xc,new_Sigma)\n",
    "            dist = np.sum((V_hat-new_V)**2) + np.sum((Sigma_hat-new_Sigma)**2)\n",
    "            V_hat = new_V\n",
    "            Sigma_hat = new_Sigma\n",
    "            t += 1\n",
    "        if tempo :\n",
    "            print('t =',t)\n",
    "    \n",
    "    D1,C1 = np.shape(V_hat)\n",
    "    if D != D1 or C != C1 :\n",
    "        print('Erreur de dimensions sur V')\n",
    "        S, W, Z = PCA(Yc,L)\n",
    "        sigma2 = bruit(S,L)\n",
    "        return W, Z, V_hat, np.eye(D), sigma2\n",
    "    \n",
    "    #Changement de variable\n",
    "    X_tilde = Xc @ np.transpose(V_hat)\n",
    "    \n",
    "    #Le reste c'est la fonction du dessus\n",
    "    W_hat,Z,Lambda_hat,sigma2 = EM_RCA_LRPSI(Yc,X_tilde,L,Lambda,la,sigma2,nb_steps,err,tempo)\n",
    "    return W_hat,Z,V_hat,Lambda_hat,sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function sum in module numpy:\n",
      "\n",
      "sum(a, axis=None, dtype=None, out=None, keepdims=<no value>, initial=<no value>, where=<no value>)\n",
      "    Sum of array elements over a given axis.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    a : array_like\n",
      "        Elements to sum.\n",
      "    axis : None or int or tuple of ints, optional\n",
      "        Axis or axes along which a sum is performed.  The default,\n",
      "        axis=None, will sum all of the elements of the input array.  If\n",
      "        axis is negative it counts from the last to the first axis.\n",
      "    \n",
      "        .. versionadded:: 1.7.0\n",
      "    \n",
      "        If axis is a tuple of ints, a sum is performed on all of the axes\n",
      "        specified in the tuple instead of a single axis or all the axes as\n",
      "        before.\n",
      "    dtype : dtype, optional\n",
      "        The type of the returned array and of the accumulator in which the\n",
      "        elements are summed.  The dtype of `a` is used by default unless `a`\n",
      "        has an integer dtype of less precision than the default platform\n",
      "        integer.  In that case, if `a` is signed then the platform integer\n",
      "        is used while if `a` is unsigned then an unsigned integer of the\n",
      "        same precision as the platform integer is used.\n",
      "    out : ndarray, optional\n",
      "        Alternative output array in which to place the result. It must have\n",
      "        the same shape as the expected output, but the type of the output\n",
      "        values will be cast if necessary.\n",
      "    keepdims : bool, optional\n",
      "        If this is set to True, the axes which are reduced are left\n",
      "        in the result as dimensions with size one. With this option,\n",
      "        the result will broadcast correctly against the input array.\n",
      "    \n",
      "        If the default value is passed, then `keepdims` will not be\n",
      "        passed through to the `sum` method of sub-classes of\n",
      "        `ndarray`, however any non-default value will be.  If the\n",
      "        sub-class' method does not implement `keepdims` any\n",
      "        exceptions will be raised.\n",
      "    initial : scalar, optional\n",
      "        Starting value for the sum. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.15.0\n",
      "    \n",
      "    where : array_like of bool, optional\n",
      "        Elements to include in the sum. See `~numpy.ufunc.reduce` for details.\n",
      "    \n",
      "        .. versionadded:: 1.17.0\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    sum_along_axis : ndarray\n",
      "        An array with the same shape as `a`, with the specified\n",
      "        axis removed.   If `a` is a 0-d array, or if `axis` is None, a scalar\n",
      "        is returned.  If an output array is specified, a reference to\n",
      "        `out` is returned.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    ndarray.sum : Equivalent method.\n",
      "    \n",
      "    add.reduce : Equivalent functionality of `add`.\n",
      "    \n",
      "    cumsum : Cumulative sum of array elements.\n",
      "    \n",
      "    trapz : Integration of array values using the composite trapezoidal rule.\n",
      "    \n",
      "    mean, average\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    Arithmetic is modular when using integer types, and no error is\n",
      "    raised on overflow.\n",
      "    \n",
      "    The sum of an empty array is the neutral element 0:\n",
      "    \n",
      "    >>> np.sum([])\n",
      "    0.0\n",
      "    \n",
      "    For floating point numbers the numerical precision of sum (and\n",
      "    ``np.add.reduce``) is in general limited by directly adding each number\n",
      "    individually to the result causing rounding errors in every step.\n",
      "    However, often numpy will use a  numerically better approach (partial\n",
      "    pairwise summation) leading to improved precision in many use-cases.\n",
      "    This improved precision is always provided when no ``axis`` is given.\n",
      "    When ``axis`` is given, it will depend on which axis is summed.\n",
      "    Technically, to provide the best speed possible, the improved precision\n",
      "    is only used when the summation is along the fast axis in memory.\n",
      "    Note that the exact precision may vary depending on other parameters.\n",
      "    In contrast to NumPy, Python's ``math.fsum`` function uses a slower but\n",
      "    more precise approach to summation.\n",
      "    Especially when summing a large number of lower precision floating point\n",
      "    numbers, such as ``float32``, numerical errors can become significant.\n",
      "    In such cases it can be advisable to use `dtype=\"float64\"` to use a higher\n",
      "    precision for the output.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> np.sum([0.5, 1.5])\n",
      "    2.0\n",
      "    >>> np.sum([0.5, 0.7, 0.2, 1.5], dtype=np.int32)\n",
      "    1\n",
      "    >>> np.sum([[0, 1], [0, 5]])\n",
      "    6\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=0)\n",
      "    array([0, 6])\n",
      "    >>> np.sum([[0, 1], [0, 5]], axis=1)\n",
      "    array([1, 5])\n",
      "    >>> np.sum([[0, 1], [np.nan, 5]], where=[False, True], axis=1)\n",
      "    array([1., 5.])\n",
      "    \n",
      "    If the accumulator is too small, overflow occurs:\n",
      "    \n",
      "    >>> np.ones(128, dtype=np.int8).sum(dtype=np.int8)\n",
      "    -128\n",
      "    \n",
      "    You can also start the sum with a value other than zero:\n",
      "    \n",
      "    >>> np.sum([10], initial=5)\n",
      "    15\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function ML_RCA in module __main__:\n",
      "\n",
      "ML_RCA(Y, X, L, V=None, nb_steps=100, err=0.0, tempo=True)\n",
      "    Analyse en Composante Résiduelle, méthode itérative.\n",
      "    (Adapté pour le modèle (M.2))\n",
      "    \n",
      "    Paramètres\n",
      "    ----------\n",
      "    Y : 2-D ndarray,\n",
      "        Matrice de taille (N,D) dont les lignes sont les vecteurs observés.\n",
      "    \n",
      "    X : 2-D ndarray,\n",
      "        Matrice de taille (N,C) dont les lignes sont des vecteurs de covariables.\n",
      "        L'algorithme s'assure que les vecteurs de covariables sont centrés en les centrant de force.\n",
      "    \n",
      "    L : int,\n",
      "        Nombre de dimensions latentes souhaité.\n",
      "        \n",
      "    V : 2-D ndarray, optional,\n",
      "        Matrice de taille (D,C) d'effets fixes donnée en argument initial de l'algorithme itératif.\n",
      "    \n",
      "    nb_steps : int, optional,\n",
      "        Nombre maximal d'itérations de l'algorithme.\n",
      "        Mis sur 1000 par défaut.\n",
      "        \n",
      "    err : float, optional,\n",
      "        Erreur en distance L2 entre deux solutions consécutives en-dessous de laquelle l'algorithme s'arrête.\n",
      "        Mis sur 0.0 par défaut.\n",
      "        \n",
      "    tempo : bool, optional,\n",
      "        Si mis sur False, ne sert à rien.\n",
      "        Si mis sur True, affiche le nombre d'itérations effectuées par l'algorithme.\n",
      "        Mis sur True par défaut.\n",
      "        \n",
      "    Renvois\n",
      "    -------\n",
      "    W : 2-D ndarray,\n",
      "        Matrice de taille (D,L) dont les colonnes sont les axes principaux obtenus par la RCA.\n",
      "        \n",
      "    Z : 2-D ndarray,\n",
      "        Matrice de taille (N,L) dont les lignes sont les vecteurs latents obtenus par la RCA.\n",
      "        \n",
      "    V_hat : 2-D ndarray,\n",
      "        Matrice de taille (D,C) d'effets fixes estimée par la RCA.\n",
      "    \n",
      "    sigma2 : float,\n",
      "        Estimation de la variance du bruit.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ML_RCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on package numpy.random in numpy:\n",
      "\n",
      "NAME\n",
      "    numpy.random\n",
      "\n",
      "DESCRIPTION\n",
      "    ========================\n",
      "    Random Number Generation\n",
      "    ========================\n",
      "    \n",
      "    Use ``default_rng()`` to create a `Generator` and call its methods.\n",
      "    \n",
      "    =============== =========================================================\n",
      "    Generator\n",
      "    --------------- ---------------------------------------------------------\n",
      "    Generator       Class implementing all of the random number distributions\n",
      "    default_rng     Default constructor for ``Generator``\n",
      "    =============== =========================================================\n",
      "    \n",
      "    ============================================= ===\n",
      "    BitGenerator Streams that work with Generator\n",
      "    --------------------------------------------- ---\n",
      "    MT19937\n",
      "    PCG64\n",
      "    Philox\n",
      "    SFC64\n",
      "    ============================================= ===\n",
      "    \n",
      "    ============================================= ===\n",
      "    Getting entropy to initialize a BitGenerator\n",
      "    --------------------------------------------- ---\n",
      "    SeedSequence\n",
      "    ============================================= ===\n",
      "    \n",
      "    \n",
      "    Legacy\n",
      "    ------\n",
      "    \n",
      "    For backwards compatibility with previous versions of numpy before 1.17, the\n",
      "    various aliases to the global `RandomState` methods are left alone and do not\n",
      "    use the new `Generator` API.\n",
      "    \n",
      "    ==================== =========================================================\n",
      "    Utility functions\n",
      "    -------------------- ---------------------------------------------------------\n",
      "    random               Uniformly distributed floats over ``[0, 1)``\n",
      "    bytes                Uniformly distributed random bytes.\n",
      "    permutation          Randomly permute a sequence / generate a random sequence.\n",
      "    shuffle              Randomly permute a sequence in place.\n",
      "    choice               Random sample from 1-D array.\n",
      "    ==================== =========================================================\n",
      "    \n",
      "    ==================== =========================================================\n",
      "    Compatibility\n",
      "    functions - removed\n",
      "    in the new API\n",
      "    -------------------- ---------------------------------------------------------\n",
      "    rand                 Uniformly distributed values.\n",
      "    randn                Normally distributed values.\n",
      "    ranf                 Uniformly distributed floating point numbers.\n",
      "    random_integers      Uniformly distributed integers in a given range.\n",
      "                         (deprecated, use ``integers(..., closed=True)`` instead)\n",
      "    random_sample        Alias for `random_sample`\n",
      "    randint              Uniformly distributed integers in a given range\n",
      "    seed                 Seed the legacy random number generator.\n",
      "    ==================== =========================================================\n",
      "    \n",
      "    ==================== =========================================================\n",
      "    Univariate\n",
      "    distributions\n",
      "    -------------------- ---------------------------------------------------------\n",
      "    beta                 Beta distribution over ``[0, 1]``.\n",
      "    binomial             Binomial distribution.\n",
      "    chisquare            :math:`\\chi^2` distribution.\n",
      "    exponential          Exponential distribution.\n",
      "    f                    F (Fisher-Snedecor) distribution.\n",
      "    gamma                Gamma distribution.\n",
      "    geometric            Geometric distribution.\n",
      "    gumbel               Gumbel distribution.\n",
      "    hypergeometric       Hypergeometric distribution.\n",
      "    laplace              Laplace distribution.\n",
      "    logistic             Logistic distribution.\n",
      "    lognormal            Log-normal distribution.\n",
      "    logseries            Logarithmic series distribution.\n",
      "    negative_binomial    Negative binomial distribution.\n",
      "    noncentral_chisquare Non-central chi-square distribution.\n",
      "    noncentral_f         Non-central F distribution.\n",
      "    normal               Normal / Gaussian distribution.\n",
      "    pareto               Pareto distribution.\n",
      "    poisson              Poisson distribution.\n",
      "    power                Power distribution.\n",
      "    rayleigh             Rayleigh distribution.\n",
      "    triangular           Triangular distribution.\n",
      "    uniform              Uniform distribution.\n",
      "    vonmises             Von Mises circular distribution.\n",
      "    wald                 Wald (inverse Gaussian) distribution.\n",
      "    weibull              Weibull distribution.\n",
      "    zipf                 Zipf's distribution over ranked data.\n",
      "    ==================== =========================================================\n",
      "    \n",
      "    ==================== ==========================================================\n",
      "    Multivariate\n",
      "    distributions\n",
      "    -------------------- ----------------------------------------------------------\n",
      "    dirichlet            Multivariate generalization of Beta distribution.\n",
      "    multinomial          Multivariate generalization of the binomial distribution.\n",
      "    multivariate_normal  Multivariate generalization of the normal distribution.\n",
      "    ==================== ==========================================================\n",
      "    \n",
      "    ==================== =========================================================\n",
      "    Standard\n",
      "    distributions\n",
      "    -------------------- ---------------------------------------------------------\n",
      "    standard_cauchy      Standard Cauchy-Lorentz distribution.\n",
      "    standard_exponential Standard exponential distribution.\n",
      "    standard_gamma       Standard Gamma distribution.\n",
      "    standard_normal      Standard normal distribution.\n",
      "    standard_t           Standard Student's t-distribution.\n",
      "    ==================== =========================================================\n",
      "    \n",
      "    ==================== =========================================================\n",
      "    Internal functions\n",
      "    -------------------- ---------------------------------------------------------\n",
      "    get_state            Get tuple representing internal state of generator.\n",
      "    set_state            Set state of generator.\n",
      "    ==================== =========================================================\n",
      "\n",
      "PACKAGE CONTENTS\n",
      "    _bit_generator\n",
      "    _bounded_integers\n",
      "    _common\n",
      "    _generator\n",
      "    _mt19937\n",
      "    _pcg64\n",
      "    _philox\n",
      "    _pickle\n",
      "    _sfc64\n",
      "    mtrand\n",
      "    setup\n",
      "    tests (package)\n",
      "\n",
      "CLASSES\n",
      "    builtins.object\n",
      "        numpy.random._bit_generator.BitGenerator\n",
      "            numpy.random._mt19937.MT19937\n",
      "            numpy.random._pcg64.PCG64\n",
      "            numpy.random._philox.Philox\n",
      "            numpy.random._sfc64.SFC64\n",
      "        numpy.random._bit_generator.SeedSequence\n",
      "        numpy.random._generator.Generator\n",
      "        numpy.random.mtrand.RandomState\n",
      "    \n",
      "    class BitGenerator(builtins.object)\n",
      "     |  BitGenerator(seed=None)\n",
      "     |  \n",
      "     |  Base Class for generic BitGenerators, which provide a stream\n",
      "     |  of random bits based on different algorithms. Must be overridden.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like[ints], SeedSequence}, optional\n",
      "     |      A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "     |      unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "     |      ``array_like[ints]`` is passed, then it will be passed to\n",
      "     |      ~`numpy.random.SeedSequence` to derive the initial `BitGenerator` state.\n",
      "     |      One may also pass in a `SeedSequence` instance.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  lock : threading.Lock\n",
      "     |      Lock instance that is shared so that the same BitGenerator can\n",
      "     |      be used in multiple Generators without corrupting the state. Code that\n",
      "     |      generates values from a bit generator should hold the bit generator's\n",
      "     |      lock.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  -------\n",
      "     |  SeedSequence\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  random_raw(...)\n",
      "     |      random_raw(self, size=None)\n",
      "     |      \n",
      "     |      Return randoms as generated by the underlying BitGenerator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      output : bool, optional\n",
      "     |          Output values.  Used for performance testing since the generated\n",
      "     |          values are not returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : uint or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method directly exposes the the raw underlying pseudo-random\n",
      "     |      number generator. All values are returned as unsigned 64-bit\n",
      "     |      values irrespective of the number of bits produced by the PRNG.\n",
      "     |      \n",
      "     |      See the class docstring for the number of bits returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  capsule\n",
      "     |  \n",
      "     |  cffi\n",
      "     |      CFFI interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing CFFI wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      ctypes interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing ctypes wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  lock\n",
      "     |  \n",
      "     |  state\n",
      "     |      Get or set the PRNG state\n",
      "     |      \n",
      "     |      The base BitGenerator.state must be overridden by a subclass\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict\n",
      "     |          Dictionary containing the information required to describe the\n",
      "     |          state of the PRNG\n",
      "    \n",
      "    class Generator(builtins.object)\n",
      "     |  Generator(bit_generator)\n",
      "     |  \n",
      "     |  Container for the BitGenerators.\n",
      "     |  \n",
      "     |  ``Generator`` exposes a number of methods for generating random\n",
      "     |  numbers drawn from a variety of probability distributions. In addition to\n",
      "     |  the distribution-specific arguments, each method takes a keyword argument\n",
      "     |  `size` that defaults to ``None``. If `size` is ``None``, then a single\n",
      "     |  value is generated and returned. If `size` is an integer, then a 1-D\n",
      "     |  array filled with generated values is returned. If `size` is a tuple,\n",
      "     |  then an array with that shape is filled and returned.\n",
      "     |  \n",
      "     |  The function :func:`numpy.random.default_rng` will instantiate\n",
      "     |  a `Generator` with numpy's default `BitGenerator`.\n",
      "     |  \n",
      "     |  **No Compatibility Guarantee**\n",
      "     |  \n",
      "     |  ``Generator`` does not provide a version compatibility guarantee. In\n",
      "     |  particular, as better algorithms evolve the bit stream may change.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  bit_generator : BitGenerator\n",
      "     |      BitGenerator to use as the core generator.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The Python stdlib module `random` contains pseudo-random number generator\n",
      "     |  with a number of methods that are similar to the ones available in\n",
      "     |  ``Generator``. It uses Mersenne Twister, and this bit generator can\n",
      "     |  be accessed using ``MT19937``. ``Generator``, besides being\n",
      "     |  NumPy-aware, has the advantage that it provides a much larger number\n",
      "     |  of probability distributions to choose from.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from numpy.random import Generator, PCG64\n",
      "     |  >>> rg = Generator(PCG64())\n",
      "     |  >>> rg.standard_normal()\n",
      "     |  -0.203  # random\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  default_rng : Recommended constructor for `Generator`.\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  beta(...)\n",
      "     |      beta(a, b, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Beta distribution.\n",
      "     |      \n",
      "     |      The Beta distribution is a special case of the Dirichlet distribution,\n",
      "     |      and is related to the Gamma distribution.  It has the probability\n",
      "     |      distribution function\n",
      "     |      \n",
      "     |      .. math:: f(x; a,b) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}\n",
      "     |                                                       (1 - x)^{\\beta - 1},\n",
      "     |      \n",
      "     |      where the normalization, B, is the beta function,\n",
      "     |      \n",
      "     |      .. math:: B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}\n",
      "     |                                   (1 - t)^{\\beta - 1} dt.\n",
      "     |      \n",
      "     |      It is often seen in Bayesian inference and order statistics.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Alpha, positive (>0).\n",
      "     |      b : float or array_like of floats\n",
      "     |          Beta, positive (>0).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` and ``b`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(a, b).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized beta distribution.\n",
      "     |  \n",
      "     |  binomial(...)\n",
      "     |      binomial(n, p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a binomial distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a binomial distribution with specified\n",
      "     |      parameters, n trials and p probability of success where\n",
      "     |      n an integer >= 0 and p is in the interval [0,1]. (n may be\n",
      "     |      input as a float, but it is truncated to an integer in use)\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or array_like of ints\n",
      "     |          Parameter of the distribution, >= 0. Floats are also accepted,\n",
      "     |          but they will be truncated to integers.\n",
      "     |      p : float or array_like of floats\n",
      "     |          Parameter of the distribution, >= 0 and <=1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized binomial distribution, where\n",
      "     |          each sample is equal to the number of successes over the n trials.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.binom : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the binomial distribution is\n",
      "     |      \n",
      "     |      .. math:: P(N) = \\binom{n}{N}p^N(1-p)^{n-N},\n",
      "     |      \n",
      "     |      where :math:`n` is the number of trials, :math:`p` is the probability\n",
      "     |      of success, and :math:`N` is the number of successes.\n",
      "     |      \n",
      "     |      When estimating the standard error of a proportion in a population by\n",
      "     |      using a random sample, the normal distribution works well unless the\n",
      "     |      product p*n <=5, where p = population proportion estimate, and n =\n",
      "     |      number of samples, in which case the binomial distribution is used\n",
      "     |      instead. For example, a sample of 15 people shows 4 who are left\n",
      "     |      handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4,\n",
      "     |      so the binomial distribution should be used in this case.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Dalgaard, Peter, \"Introductory Statistics with R\",\n",
      "     |             Springer-Verlag, 2002.\n",
      "     |      .. [2] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "     |             Fifth Edition, 2002.\n",
      "     |      .. [3] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "     |             and Quigley, 1972.\n",
      "     |      .. [4] Weisstein, Eric W. \"Binomial Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/BinomialDistribution.html\n",
      "     |      .. [5] Wikipedia, \"Binomial distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Binomial_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> n, p = 10, .5  # number of trials, probability of each trial\n",
      "     |      >>> s = rng.binomial(n, p, 1000)\n",
      "     |      # result of flipping a coin 10 times, tested 1000 times.\n",
      "     |      \n",
      "     |      A real world example. A company drills 9 wild-cat oil exploration\n",
      "     |      wells, each with an estimated probability of success of 0.1. All nine\n",
      "     |      wells fail. What is the probability of that happening?\n",
      "     |      \n",
      "     |      Let's do 20,000 trials of the model, and count the number that\n",
      "     |      generate zero positive results.\n",
      "     |      \n",
      "     |      >>> sum(rng.binomial(9, 0.1, 20000) == 0)/20000.\n",
      "     |      # answer = 0.38885, or 38%.\n",
      "     |  \n",
      "     |  bytes(...)\n",
      "     |      bytes(length)\n",
      "     |      \n",
      "     |      Return random bytes.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      length : int\n",
      "     |          Number of random bytes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : str\n",
      "     |          String of length `length`.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.default_rng().bytes(10)\n",
      "     |      ' eh\\x85\\x022SZ\\xbf\\xa4' #random\n",
      "     |  \n",
      "     |  chisquare(...)\n",
      "     |      chisquare(df, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a chi-square distribution.\n",
      "     |      \n",
      "     |      When `df` independent random variables, each with standard normal\n",
      "     |      distributions (mean 0, variance 1), are squared and summed, the\n",
      "     |      resulting distribution is chi-square (see Notes).  This distribution\n",
      "     |      is often used in hypothesis testing.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |           Number of degrees of freedom, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(df).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized chi-square distribution.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          When `df` <= 0 or when an inappropriate `size` (e.g. ``size=-1``)\n",
      "     |          is given.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The variable obtained by summing the squares of `df` independent,\n",
      "     |      standard normally distributed random variables:\n",
      "     |      \n",
      "     |      .. math:: Q = \\sum_{i=0}^{\\mathtt{df}} X^2_i\n",
      "     |      \n",
      "     |      is chi-square distributed, denoted\n",
      "     |      \n",
      "     |      .. math:: Q \\sim \\chi^2_k.\n",
      "     |      \n",
      "     |      The probability density function of the chi-squared distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{(1/2)^{k/2}}{\\Gamma(k/2)}\n",
      "     |                       x^{k/2 - 1} e^{-x/2},\n",
      "     |      \n",
      "     |      where :math:`\\Gamma` is the gamma function,\n",
      "     |      \n",
      "     |      .. math:: \\Gamma(x) = \\int_0^{-\\infty} t^{x - 1} e^{-t} dt.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] NIST \"Engineering Statistics Handbook\"\n",
      "     |             https://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.default_rng().chisquare(2,4)\n",
      "     |      array([ 1.89920014,  9.00867716,  3.13710533,  5.62318272]) # random\n",
      "     |  \n",
      "     |  choice(...)\n",
      "     |      choice(a, size=None, replace=True, p=None, axis=0):\n",
      "     |      \n",
      "     |      Generates a random sample from a given 1-D array\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : 1-D array-like or int\n",
      "     |          If an ndarray, a random sample is generated from its elements.\n",
      "     |          If an int, the random sample is generated as if a were np.arange(a)\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn from the 1-d `a`. If `a` has more\n",
      "     |          than one dimension, the `size` shape will be inserted into the\n",
      "     |          `axis` dimension, so the output ``ndim`` will be ``a.ndim - 1 +\n",
      "     |          len(size)``. Default is None, in which case a single value is\n",
      "     |          returned.\n",
      "     |      replace : boolean, optional\n",
      "     |          Whether the sample is with or without replacement\n",
      "     |      p : 1-D array-like, optional\n",
      "     |          The probabilities associated with each entry in a.\n",
      "     |          If not given the sample assumes a uniform distribution over all\n",
      "     |          entries in a.\n",
      "     |      axis : int, optional\n",
      "     |          The axis along which the selection is performed. The default, 0,\n",
      "     |          selects by row.\n",
      "     |      shuffle : boolean, optional\n",
      "     |          Whether the sample is shuffled when sampling without replacement.\n",
      "     |          Default is True, False provides a speedup.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : single item or ndarray\n",
      "     |          The generated random samples\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If a is an int and less than zero, if p is not 1-dimensional, if\n",
      "     |          a is array-like with a size 0, if p is not a vector of\n",
      "     |          probabilities, if a and p have different lengths, or if\n",
      "     |          replace=False and the sample size is greater than the population\n",
      "     |          size.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      integers, shuffle, permutation\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Generate a uniform random sample from np.arange(5) of size 3:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.choice(5, 3)\n",
      "     |      array([0, 3, 4]) # random\n",
      "     |      >>> #This is equivalent to rng.integers(0,5,3)\n",
      "     |      \n",
      "     |      Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "     |      \n",
      "     |      >>> rng.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "     |      array([3, 3, 0]) # random\n",
      "     |      \n",
      "     |      Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "     |      replacement:\n",
      "     |      \n",
      "     |      >>> rng.choice(5, 3, replace=False)\n",
      "     |      array([3,1,0]) # random\n",
      "     |      >>> #This is equivalent to rng.permutation(np.arange(5))[:3]\n",
      "     |      \n",
      "     |      Generate a non-uniform random sample from np.arange(5) of size\n",
      "     |      3 without replacement:\n",
      "     |      \n",
      "     |      >>> rng.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "     |      array([2, 3, 0]) # random\n",
      "     |      \n",
      "     |      Any of the above can be repeated with an arbitrary array-like\n",
      "     |      instead of just integers. For instance:\n",
      "     |      \n",
      "     |      >>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      "     |      >>> rng.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "     |      array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
      "     |            dtype='<U11')\n",
      "     |  \n",
      "     |  dirichlet(...)\n",
      "     |      dirichlet(alpha, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the Dirichlet distribution.\n",
      "     |      \n",
      "     |      Draw `size` samples of dimension k from a Dirichlet distribution. A\n",
      "     |      Dirichlet-distributed random variable can be seen as a multivariate\n",
      "     |      generalization of a Beta distribution. The Dirichlet distribution\n",
      "     |      is a conjugate prior of a multinomial distribution in Bayesian\n",
      "     |      inference.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : sequence of floats, length k\n",
      "     |          Parameter of the distribution (length ``k`` for sample of\n",
      "     |          length ``k``).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          vector of length ``k`` is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : ndarray,\n",
      "     |          The drawn samples, of shape ``(size, k)``.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      -------\n",
      "     |      ValueError\n",
      "     |          If any value in ``alpha`` is less than or equal to zero\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Dirichlet distribution is a distribution over vectors\n",
      "     |      :math:`x` that fulfil the conditions :math:`x_i>0` and\n",
      "     |      :math:`\\sum_{i=1}^k x_i = 1`.\n",
      "     |      \n",
      "     |      The probability density function :math:`p` of a\n",
      "     |      Dirichlet-distributed random vector :math:`X` is\n",
      "     |      proportional to\n",
      "     |      \n",
      "     |      .. math:: p(x) \\propto \\prod_{i=1}^{k}{x^{\\alpha_i-1}_i},\n",
      "     |      \n",
      "     |      where :math:`\\alpha` is a vector containing the positive\n",
      "     |      concentration parameters.\n",
      "     |      \n",
      "     |      The method uses the following property for computation: let :math:`Y`\n",
      "     |      be a random vector which has components that follow a standard gamma\n",
      "     |      distribution, then :math:`X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y`\n",
      "     |      is Dirichlet-distributed\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] David McKay, \"Information Theory, Inference and Learning\n",
      "     |             Algorithms,\" chapter 23,\n",
      "     |             http://www.inference.org.uk/mackay/itila/\n",
      "     |      .. [2] Wikipedia, \"Dirichlet distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Dirichlet_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Taking an example cited in Wikipedia, this distribution can be used if\n",
      "     |      one wanted to cut strings (each of initial length 1.0) into K pieces\n",
      "     |      with different lengths, where each piece had, on average, a designated\n",
      "     |      average length, but allowing some variation in the relative sizes of\n",
      "     |      the pieces.\n",
      "     |      \n",
      "     |      >>> s = np.random.default_rng().dirichlet((10, 5, 3), 20).transpose()\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> plt.barh(range(20), s[0])\n",
      "     |      >>> plt.barh(range(20), s[1], left=s[0], color='g')\n",
      "     |      >>> plt.barh(range(20), s[2], left=s[0]+s[1], color='r')\n",
      "     |      >>> plt.title(\"Lengths of Strings\")\n",
      "     |  \n",
      "     |  exponential(...)\n",
      "     |      exponential(scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from an exponential distribution.\n",
      "     |      \n",
      "     |      Its probability density function is\n",
      "     |      \n",
      "     |      .. math:: f(x; \\frac{1}{\\beta}) = \\frac{1}{\\beta} \\exp(-\\frac{x}{\\beta}),\n",
      "     |      \n",
      "     |      for ``x > 0`` and 0 elsewhere. :math:`\\beta` is the scale parameter,\n",
      "     |      which is the inverse of the rate parameter :math:`\\lambda = 1/\\beta`.\n",
      "     |      The rate parameter is an alternative, widely used parameterization\n",
      "     |      of the exponential distribution [3]_.\n",
      "     |      \n",
      "     |      The exponential distribution is a continuous analogue of the\n",
      "     |      geometric distribution.  It describes many common situations, such as\n",
      "     |      the size of raindrops measured over many rainstorms [1]_, or the time\n",
      "     |      between page requests to Wikipedia [2]_.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scale : float or array_like of floats\n",
      "     |          The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n",
      "     |          non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized exponential distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Peyton Z. Peebles Jr., \"Probability, Random Variables and\n",
      "     |             Random Signal Principles\", 4th ed, 2001, p. 57.\n",
      "     |      .. [2] Wikipedia, \"Poisson process\",\n",
      "     |             https://en.wikipedia.org/wiki/Poisson_process\n",
      "     |      .. [3] Wikipedia, \"Exponential distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Exponential_distribution\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(dfnum, dfden, size=None)\n",
      "     |      \n",
      "     |      Draw samples from an F distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from an F distribution with specified parameters,\n",
      "     |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "     |      freedom in denominator), where both parameters must be greater than\n",
      "     |      zero.\n",
      "     |      \n",
      "     |      The random variate of the F distribution (also known as the\n",
      "     |      Fisher distribution) is a continuous probability distribution\n",
      "     |      that arises in ANOVA tests, and is the ratio of two chi-square\n",
      "     |      variates.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dfnum : float or array_like of floats\n",
      "     |          Degrees of freedom in numerator, must be > 0.\n",
      "     |      dfden : float or array_like of float\n",
      "     |          Degrees of freedom in denominator, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``dfnum`` and ``dfden`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(dfnum, dfden).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Fisher distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.f : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The F statistic is used to compare in-group variances to between-group\n",
      "     |      variances. Calculating the distribution depends on the sampling, and\n",
      "     |      so it is a function of the respective degrees of freedom in the\n",
      "     |      problem.  The variable `dfnum` is the number of samples minus one, the\n",
      "     |      between-groups degrees of freedom, while `dfden` is the within-groups\n",
      "     |      degrees of freedom, the sum of the number of samples in each group\n",
      "     |      minus the number of groups.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "     |             Fifth Edition, 2002.\n",
      "     |      .. [2] Wikipedia, \"F-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/F-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      An example from Glantz[1], pp 47-40:\n",
      "     |      \n",
      "     |      Two groups, children of diabetics (25 people) and children from people\n",
      "     |      without diabetes (25 controls). Fasting blood glucose was measured,\n",
      "     |      case group had a mean value of 86.1, controls had a mean value of\n",
      "     |      82.2. Standard deviations were 2.09 and 2.49 respectively. Are these\n",
      "     |      data consistent with the null hypothesis that the parents diabetic\n",
      "     |      status does not affect their children's blood glucose levels?\n",
      "     |      Calculating the F statistic from the data gives a value of 36.01.\n",
      "     |      \n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> dfnum = 1. # between group degrees of freedom\n",
      "     |      >>> dfden = 48. # within groups degrees of freedom\n",
      "     |      >>> s = np.random.default_rng().f(dfnum, dfden, 1000)\n",
      "     |      \n",
      "     |      The lower bound for the top 1% of the samples is :\n",
      "     |      \n",
      "     |      >>> np.sort(s)[-10]\n",
      "     |      7.61988120985 # random\n",
      "     |      \n",
      "     |      So there is about a 1% chance that the F statistic will exceed 7.62,\n",
      "     |      the measured value is 36, so the null hypothesis is rejected at the 1%\n",
      "     |      level.\n",
      "     |  \n",
      "     |  gamma(...)\n",
      "     |      gamma(shape, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Gamma distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      "     |      `shape` (sometimes designated \"k\") and `scale` (sometimes designated\n",
      "     |      \"theta\"), where both parameters are > 0.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      shape : float or array_like of floats\n",
      "     |          The shape of the gamma distribution. Must be non-negative.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          The scale of the gamma distribution. Must be non-negative.\n",
      "     |          Default is equal to 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``shape`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(shape, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized gamma distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gamma : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gamma distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "     |      \n",
      "     |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "     |      and :math:`\\Gamma` is the Gamma function.\n",
      "     |      \n",
      "     |      The Gamma distribution is often used to model the times to failure of\n",
      "     |      electronic components, and arises naturally in processes for which the\n",
      "     |      waiting times between Poisson distributed events are relevant.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> shape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\n",
      "     |      >>> s = np.random.default_rng().gamma(shape, scale, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> import scipy.special as sps  # doctest: +SKIP\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "     |      >>> y = bins**(shape-1)*(np.exp(-bins/scale) /  # doctest: +SKIP\n",
      "     |      ...                      (sps.gamma(shape)*scale**shape))\n",
      "     |      >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  geometric(...)\n",
      "     |      geometric(p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the geometric distribution.\n",
      "     |      \n",
      "     |      Bernoulli trials are experiments with one of two outcomes:\n",
      "     |      success or failure (an example of such an experiment is flipping\n",
      "     |      a coin).  The geometric distribution models the number of trials\n",
      "     |      that must be run in order to achieve success.  It is therefore\n",
      "     |      supported on the positive integers, ``k = 1, 2, ...``.\n",
      "     |      \n",
      "     |      The probability mass function of the geometric distribution is\n",
      "     |      \n",
      "     |      .. math:: f(k) = (1 - p)^{k - 1} p\n",
      "     |      \n",
      "     |      where `p` is the probability of success of an individual trial.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float or array_like of floats\n",
      "     |          The probability of success of an individual trial.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized geometric distribution.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw ten thousand values from the geometric distribution,\n",
      "     |      with the probability of an individual success equal to 0.35:\n",
      "     |      \n",
      "     |      >>> z = np.random.default_rng().geometric(p=0.35, size=10000)\n",
      "     |      \n",
      "     |      How many trials succeeded after a single run?\n",
      "     |      \n",
      "     |      >>> (z == 1).sum() / 10000.\n",
      "     |      0.34889999999999999 #random\n",
      "     |  \n",
      "     |  gumbel(...)\n",
      "     |      gumbel(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Gumbel distribution.\n",
      "     |      \n",
      "     |      Draw samples from a Gumbel distribution with specified location and\n",
      "     |      scale.  For more information on the Gumbel distribution, see\n",
      "     |      Notes and References below.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          The location of the mode of the distribution. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          The scale parameter of the distribution. Default is 1. Must be non-\n",
      "     |          negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Gumbel distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gumbel_l\n",
      "     |      scipy.stats.gumbel_r\n",
      "     |      scipy.stats.genextreme\n",
      "     |      weibull\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme\n",
      "     |      Value Type I) distribution is one of a class of Generalized Extreme\n",
      "     |      Value (GEV) distributions used in modeling extreme value problems.\n",
      "     |      The Gumbel is a special case of the Extreme Value Type I distribution\n",
      "     |      for maximums from distributions with \"exponential-like\" tails.\n",
      "     |      \n",
      "     |      The probability density for the Gumbel distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{e^{-(x - \\mu)/ \\beta}}{\\beta} e^{ -e^{-(x - \\mu)/\n",
      "     |                \\beta}},\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mode, a location parameter, and\n",
      "     |      :math:`\\beta` is the scale parameter.\n",
      "     |      \n",
      "     |      The Gumbel (named for German mathematician Emil Julius Gumbel) was used\n",
      "     |      very early in the hydrology literature, for modeling the occurrence of\n",
      "     |      flood events. It is also used for modeling maximum wind speed and\n",
      "     |      rainfall rates.  It is a \"fat-tailed\" distribution - the probability of\n",
      "     |      an event in the tail of the distribution is larger than if one used a\n",
      "     |      Gaussian, hence the surprisingly frequent occurrence of 100-year\n",
      "     |      floods. Floods were initially modeled as a Gaussian process, which\n",
      "     |      underestimated the frequency of extreme events.\n",
      "     |      \n",
      "     |      It is one of a class of extreme value distributions, the Generalized\n",
      "     |      Extreme Value (GEV) distributions, which also includes the Weibull and\n",
      "     |      Frechet.\n",
      "     |      \n",
      "     |      The function has a mean of :math:`\\mu + 0.57721\\beta` and a variance\n",
      "     |      of :math:`\\frac{\\pi^2}{6}\\beta^2`.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Gumbel, E. J., \"Statistics of Extremes,\"\n",
      "     |             New York: Columbia University Press, 1958.\n",
      "     |      .. [2] Reiss, R.-D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "     |             Values from Insurance, Finance, Hydrology and Other Fields,\"\n",
      "     |             Basel: Birkhauser Verlag, 2001.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> mu, beta = 0, 0.1 # location and scale\n",
      "     |      >>> s = rng.gumbel(mu, beta, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "     |      ...          * np.exp( -np.exp( -(bins - mu) /beta) ),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Show how an extreme value distribution can arise from a Gaussian process\n",
      "     |      and compare to a Gaussian:\n",
      "     |      \n",
      "     |      >>> means = []\n",
      "     |      >>> maxima = []\n",
      "     |      >>> for i in range(0,1000) :\n",
      "     |      ...    a = rng.normal(mu, beta, 1000)\n",
      "     |      ...    means.append(a.mean())\n",
      "     |      ...    maxima.append(a.max())\n",
      "     |      >>> count, bins, ignored = plt.hist(maxima, 30, density=True)\n",
      "     |      >>> beta = np.std(maxima) * np.sqrt(6) / np.pi\n",
      "     |      >>> mu = np.mean(maxima) - 0.57721*beta\n",
      "     |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "     |      ...          * np.exp(-np.exp(-(bins - mu)/beta)),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi))\n",
      "     |      ...          * np.exp(-(bins - mu)**2 / (2 * beta**2)),\n",
      "     |      ...          linewidth=2, color='g')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  hypergeometric(...)\n",
      "     |      hypergeometric(ngood, nbad, nsample, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Hypergeometric distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a hypergeometric distribution with specified\n",
      "     |      parameters, `ngood` (ways to make a good selection), `nbad` (ways to make\n",
      "     |      a bad selection), and `nsample` (number of items sampled, which is less\n",
      "     |      than or equal to the sum ``ngood + nbad``).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ngood : int or array_like of ints\n",
      "     |          Number of ways to make a good selection.  Must be nonnegative and\n",
      "     |          less than 10**9.\n",
      "     |      nbad : int or array_like of ints\n",
      "     |          Number of ways to make a bad selection.  Must be nonnegative and\n",
      "     |          less than 10**9.\n",
      "     |      nsample : int or array_like of ints\n",
      "     |          Number of items sampled.  Must be nonnegative and less than\n",
      "     |          ``ngood + nbad``.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if `ngood`, `nbad`, and `nsample`\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(ngood, nbad, nsample).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized hypergeometric distribution. Each\n",
      "     |          sample is the number of good items within a randomly selected subset of\n",
      "     |          size `nsample` taken from a set of `ngood` good items and `nbad` bad items.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      multivariate_hypergeometric : Draw samples from the multivariate\n",
      "     |          hypergeometric distribution.\n",
      "     |      scipy.stats.hypergeom : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Hypergeometric distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x) = \\frac{\\binom{g}{x}\\binom{b}{n-x}}{\\binom{g+b}{n}},\n",
      "     |      \n",
      "     |      where :math:`0 \\le x \\le n` and :math:`n-b \\le x \\le g`\n",
      "     |      \n",
      "     |      for P(x) the probability of ``x`` good results in the drawn sample,\n",
      "     |      g = `ngood`, b = `nbad`, and n = `nsample`.\n",
      "     |      \n",
      "     |      Consider an urn with black and white marbles in it, `ngood` of them\n",
      "     |      are black and `nbad` are white. If you draw `nsample` balls without\n",
      "     |      replacement, then the hypergeometric distribution describes the\n",
      "     |      distribution of black balls in the drawn sample.\n",
      "     |      \n",
      "     |      Note that this distribution is very similar to the binomial\n",
      "     |      distribution, except that in this case, samples are drawn without\n",
      "     |      replacement, whereas in the Binomial case samples are drawn with\n",
      "     |      replacement (or the sample space is infinite). As the sample space\n",
      "     |      becomes large, this distribution approaches the binomial.\n",
      "     |      \n",
      "     |      The arguments `ngood` and `nbad` each must be less than `10**9`. For\n",
      "     |      extremely large arguments, the algorithm that is used to compute the\n",
      "     |      samples [4]_ breaks down because of loss of precision in floating point\n",
      "     |      calculations.  For such large values, if `nsample` is not also large,\n",
      "     |      the distribution can be approximated with the binomial distribution,\n",
      "     |      `binomial(n=nsample, p=ngood/(ngood + nbad))`.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "     |             and Quigley, 1972.\n",
      "     |      .. [2] Weisstein, Eric W. \"Hypergeometric Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/HypergeometricDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Hypergeometric distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Hypergeometric_distribution\n",
      "     |      .. [4] Stadlober, Ernst, \"The ratio of uniforms approach for generating\n",
      "     |             discrete random variates\", Journal of Computational and Applied\n",
      "     |             Mathematics, 31, pp. 181-189 (1990).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> ngood, nbad, nsamp = 100, 2, 10\n",
      "     |      # number of good, number of bad, and number of samples\n",
      "     |      >>> s = rng.hypergeometric(ngood, nbad, nsamp, 1000)\n",
      "     |      >>> from matplotlib.pyplot import hist\n",
      "     |      >>> hist(s)\n",
      "     |      #   note that it is very unlikely to grab both bad items\n",
      "     |      \n",
      "     |      Suppose you have an urn with 15 white and 15 black marbles.\n",
      "     |      If you pull 15 marbles at random, how likely is it that\n",
      "     |      12 or more of them are one color?\n",
      "     |      \n",
      "     |      >>> s = rng.hypergeometric(15, 15, 15, 100000)\n",
      "     |      >>> sum(s>=12)/100000. + sum(s<=3)/100000.\n",
      "     |      #   answer = 0.003 ... pretty unlikely!\n",
      "     |  \n",
      "     |  integers(...)\n",
      "     |      integers(low, high=None, size=None, dtype=np.int64, endpoint=False)\n",
      "     |      \n",
      "     |      Return random integers from `low` (inclusive) to `high` (exclusive), or\n",
      "     |      if endpoint=True, `low` (inclusive) to `high` (inclusive). Replaces\n",
      "     |      `RandomState.randint` (with endpoint=False) and\n",
      "     |      `RandomState.random_integers` (with endpoint=True)\n",
      "     |      \n",
      "     |      Return random integers from the \"discrete uniform\" distribution of\n",
      "     |      the specified dtype. If `high` is None (the default), then results are\n",
      "     |      from 0 to `low`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : int or array-like of ints\n",
      "     |          Lowest (signed) integers to be drawn from the distribution (unless\n",
      "     |          ``high=None``, in which case this parameter is 0 and this value is\n",
      "     |          used for `high`).\n",
      "     |      high : int or array-like of ints, optional\n",
      "     |          If provided, one above the largest (signed) integer to be drawn\n",
      "     |          from the distribution (see above for behavior if ``high=None``).\n",
      "     |          If array-like, must contain integer values\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result. Byteorder must be native.\n",
      "     |          The default value is np.int64.\n",
      "     |      endpoint : bool, optional\n",
      "     |          If true, sample from the interval [low, high] instead of the\n",
      "     |          default [low, high)\n",
      "     |          Defaults to False\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : int or ndarray of ints\n",
      "     |          `size`-shaped array of random integers from the appropriate\n",
      "     |          distribution, or a single such random int if `size` not provided.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When using broadcasting with uint64 dtypes, the maximum value (2**64)\n",
      "     |      cannot be represented as a standard integer type. The high array (or\n",
      "     |      low if high is None) must have object dtype, e.g., array([2**64]).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.integers(2, size=10)\n",
      "     |      array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0])  # random\n",
      "     |      >>> rng.integers(1, size=10)\n",
      "     |      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "     |      \n",
      "     |      Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      "     |      \n",
      "     |      >>> rng.integers(5, size=(2, 4))\n",
      "     |      array([[4, 0, 2, 1],\n",
      "     |             [3, 2, 2, 0]])  # random\n",
      "     |      \n",
      "     |      Generate a 1 x 3 array with 3 different upper bounds\n",
      "     |      \n",
      "     |      >>> rng.integers(1, [3, 5, 10])\n",
      "     |      array([2, 2, 9])  # random\n",
      "     |      \n",
      "     |      Generate a 1 by 3 array with 3 different lower bounds\n",
      "     |      \n",
      "     |      >>> rng.integers([1, 5, 7], 10)\n",
      "     |      array([9, 8, 7])  # random\n",
      "     |      \n",
      "     |      Generate a 2 by 4 array using broadcasting with dtype of uint8\n",
      "     |      \n",
      "     |      >>> rng.integers([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\n",
      "     |      array([[ 8,  6,  9,  7],\n",
      "     |             [ 1, 16,  9, 12]], dtype=uint8)  # random\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Daniel Lemire., \"Fast Random Integer Generation in an Interval\",\n",
      "     |             ACM Transactions on Modeling and Computer Simulation 29 (1), 2019,\n",
      "     |             http://arxiv.org/abs/1805.10941.\n",
      "     |  \n",
      "     |  laplace(...)\n",
      "     |      laplace(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the Laplace or double exponential distribution with\n",
      "     |      specified location (or mean) and scale (decay).\n",
      "     |      \n",
      "     |      The Laplace distribution is similar to the Gaussian/normal distribution,\n",
      "     |      but is sharper at the peak and has fatter tails. It represents the\n",
      "     |      difference between two independent, identically distributed exponential\n",
      "     |      random variables.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          The position, :math:`\\mu`, of the distribution peak. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          :math:`\\lambda`, the exponential decay. Default is 1. Must be non-\n",
      "     |          negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Laplace distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      It has the probability density function\n",
      "     |      \n",
      "     |      .. math:: f(x; \\mu, \\lambda) = \\frac{1}{2\\lambda}\n",
      "     |                                     \\exp\\left(-\\frac{|x - \\mu|}{\\lambda}\\right).\n",
      "     |      \n",
      "     |      The first law of Laplace, from 1774, states that the frequency\n",
      "     |      of an error can be expressed as an exponential function of the\n",
      "     |      absolute magnitude of the error, which leads to the Laplace\n",
      "     |      distribution. For many problems in economics and health\n",
      "     |      sciences, this distribution seems to model the data better\n",
      "     |      than the standard Gaussian distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "     |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "     |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      "     |      .. [2] Kotz, Samuel, et. al. \"The Laplace Distribution and\n",
      "     |             Generalizations, \" Birkhauser, 2001.\n",
      "     |      .. [3] Weisstein, Eric W. \"Laplace Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/LaplaceDistribution.html\n",
      "     |      .. [4] Wikipedia, \"Laplace distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Laplace_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution\n",
      "     |      \n",
      "     |      >>> loc, scale = 0., 1.\n",
      "     |      >>> s = np.random.default_rng().laplace(loc, scale, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> x = np.arange(-8., 8., .01)\n",
      "     |      >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
      "     |      >>> plt.plot(x, pdf)\n",
      "     |      \n",
      "     |      Plot Gaussian for comparison:\n",
      "     |      \n",
      "     |      >>> g = (1/(scale * np.sqrt(2 * np.pi)) *\n",
      "     |      ...      np.exp(-(x - loc)**2 / (2 * scale**2)))\n",
      "     |      >>> plt.plot(x,g)\n",
      "     |  \n",
      "     |  logistic(...)\n",
      "     |      logistic(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a logistic distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a logistic distribution with specified\n",
      "     |      parameters, loc (location or mean, also median), and scale (>0).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          Parameter of the distribution. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          Parameter of the distribution. Must be non-negative.\n",
      "     |          Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized logistic distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.logistic : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Logistic distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x) = P(x) = \\frac{e^{-(x-\\mu)/s}}{s(1+e^{-(x-\\mu)/s})^2},\n",
      "     |      \n",
      "     |      where :math:`\\mu` = location and :math:`s` = scale.\n",
      "     |      \n",
      "     |      The Logistic distribution is used in Extreme Value problems where it\n",
      "     |      can act as a mixture of Gumbel distributions, in Epidemiology, and by\n",
      "     |      the World Chess Federation (FIDE) where it is used in the Elo ranking\n",
      "     |      system, assuming the performance of each player is a logistically\n",
      "     |      distributed random variable.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Reiss, R.-D. and Thomas M. (2001), \"Statistical Analysis of\n",
      "     |             Extreme Values, from Insurance, Finance, Hydrology and Other\n",
      "     |             Fields,\" Birkhauser Verlag, Basel, pp 132-133.\n",
      "     |      .. [2] Weisstein, Eric W. \"Logistic Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/LogisticDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Logistic-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Logistic_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> loc, scale = 10, 1\n",
      "     |      >>> s = np.random.default_rng().logistic(loc, scale, 10000)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, bins=50)\n",
      "     |      \n",
      "     |      #   plot against distribution\n",
      "     |      \n",
      "     |      >>> def logist(x, loc, scale):\n",
      "     |      ...     return np.exp((loc-x)/scale)/(scale*(1+np.exp((loc-x)/scale))**2)\n",
      "     |      >>> lgst_val = logist(bins, loc, scale)\n",
      "     |      >>> plt.plot(bins, lgst_val * count.max() / lgst_val.max())\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  lognormal(...)\n",
      "     |      lognormal(mean=0.0, sigma=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a log-normal distribution.\n",
      "     |      \n",
      "     |      Draw samples from a log-normal distribution with specified mean,\n",
      "     |      standard deviation, and array shape.  Note that the mean and standard\n",
      "     |      deviation are not the values for the distribution itself, but of the\n",
      "     |      underlying normal distribution it is derived from.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : float or array_like of floats, optional\n",
      "     |          Mean value of the underlying normal distribution. Default is 0.\n",
      "     |      sigma : float or array_like of floats, optional\n",
      "     |          Standard deviation of the underlying normal distribution. Must be\n",
      "     |          non-negative. Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mean`` and ``sigma`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mean, sigma).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized log-normal distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.lognorm : probability density function, distribution,\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      A variable `x` has a log-normal distribution if `log(x)` is normally\n",
      "     |      distributed.  The probability density function for the log-normal\n",
      "     |      distribution is:\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{\\sigma x \\sqrt{2\\pi}}\n",
      "     |                       e^{(-\\frac{(ln(x)-\\mu)^2}{2\\sigma^2})}\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mean and :math:`\\sigma` is the standard\n",
      "     |      deviation of the normally distributed logarithm of the variable.\n",
      "     |      A log-normal distribution results if a random variable is the *product*\n",
      "     |      of a large number of independent, identically-distributed variables in\n",
      "     |      the same way that a normal distribution results if the variable is the\n",
      "     |      *sum* of a large number of independent, identically-distributed\n",
      "     |      variables.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Limpert, E., Stahel, W. A., and Abbt, M., \"Log-normal\n",
      "     |             Distributions across the Sciences: Keys and Clues,\"\n",
      "     |             BioScience, Vol. 51, No. 5, May, 2001.\n",
      "     |             https://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n",
      "     |      .. [2] Reiss, R.D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "     |             Values,\" Basel: Birkhauser Verlag, 2001, pp. 31-32.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> mu, sigma = 3., 1. # mean and standard deviation\n",
      "     |      >>> s = rng.lognormal(mu, sigma, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 100, density=True, align='mid')\n",
      "     |      \n",
      "     |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "     |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "     |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "     |      \n",
      "     |      >>> plt.plot(x, pdf, linewidth=2, color='r')\n",
      "     |      >>> plt.axis('tight')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Demonstrate that taking the products of random samples from a uniform\n",
      "     |      distribution can be fit well by a log-normal probability density\n",
      "     |      function.\n",
      "     |      \n",
      "     |      >>> # Generate a thousand samples: each is the product of 100 random\n",
      "     |      >>> # values, drawn from a normal distribution.\n",
      "     |      >>> rng = rng\n",
      "     |      >>> b = []\n",
      "     |      >>> for i in range(1000):\n",
      "     |      ...    a = 10. + rng.standard_normal(100)\n",
      "     |      ...    b.append(np.product(a))\n",
      "     |      \n",
      "     |      >>> b = np.array(b) / np.min(b) # scale values to be positive\n",
      "     |      >>> count, bins, ignored = plt.hist(b, 100, density=True, align='mid')\n",
      "     |      >>> sigma = np.std(np.log(b))\n",
      "     |      >>> mu = np.mean(np.log(b))\n",
      "     |      \n",
      "     |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "     |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "     |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "     |      \n",
      "     |      >>> plt.plot(x, pdf, color='r', linewidth=2)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  logseries(...)\n",
      "     |      logseries(p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a logarithmic series distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a log series distribution with specified\n",
      "     |      shape parameter, 0 < ``p`` < 1.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float or array_like of floats\n",
      "     |          Shape parameter for the distribution.  Must be in the range (0, 1).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized logarithmic series distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.logser : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability mass function for the Log Series distribution is\n",
      "     |      \n",
      "     |      .. math:: P(k) = \\frac{-p^k}{k \\ln(1-p)},\n",
      "     |      \n",
      "     |      where p = probability.\n",
      "     |      \n",
      "     |      The log series distribution is frequently used to represent species\n",
      "     |      richness and occurrence, first proposed by Fisher, Corbet, and\n",
      "     |      Williams in 1943 [2].  It may also be used to model the numbers of\n",
      "     |      occupants seen in cars [3].\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Buzas, Martin A.; Culver, Stephen J.,  Understanding regional\n",
      "     |             species diversity through the log series distribution of\n",
      "     |             occurrences: BIODIVERSITY RESEARCH Diversity & Distributions,\n",
      "     |             Volume 5, Number 5, September 1999 , pp. 187-195(9).\n",
      "     |      .. [2] Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The\n",
      "     |             relation between the number of species and the number of\n",
      "     |             individuals in a random sample of an animal population.\n",
      "     |             Journal of Animal Ecology, 12:42-58.\n",
      "     |      .. [3] D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small\n",
      "     |             Data Sets, CRC Press, 1994.\n",
      "     |      .. [4] Wikipedia, \"Logarithmic distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Logarithmic_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = .6\n",
      "     |      >>> s = np.random.default_rng().logseries(a, 10000)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s)\n",
      "     |      \n",
      "     |      #   plot against distribution\n",
      "     |      \n",
      "     |      >>> def logseries(k, p):\n",
      "     |      ...     return -p**k/(k*np.log(1-p))\n",
      "     |      >>> plt.plot(bins, logseries(bins, a) * count.max()/\n",
      "     |      ...          logseries(bins, a).max(), 'r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(n, pvals, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a multinomial distribution.\n",
      "     |      \n",
      "     |      The multinomial distribution is a multivariate generalization of the\n",
      "     |      binomial distribution.  Take an experiment with one of ``p``\n",
      "     |      possible outcomes.  An example of such an experiment is throwing a dice,\n",
      "     |      where the outcome can be 1 through 6.  Each sample drawn from the\n",
      "     |      distribution represents `n` such experiments.  Its values,\n",
      "     |      ``X_i = [X_0, X_1, ..., X_p]``, represent the number of times the\n",
      "     |      outcome was ``i``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or array-like of ints\n",
      "     |          Number of experiments.\n",
      "     |      pvals : sequence of floats, length p\n",
      "     |          Probabilities of each of the ``p`` different outcomes.  These\n",
      "     |          must sum to 1 (however, the last element is always assumed to\n",
      "     |          account for the remaining probability, as long as\n",
      "     |          ``sum(pvals[:-1]) <= 1)``.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "     |          the shape is ``(N,)``.\n",
      "     |      \n",
      "     |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "     |          value drawn from the distribution.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Throw a dice 20 times:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.multinomial(20, [1/6.]*6, size=1)\n",
      "     |      array([[4, 1, 7, 5, 2, 1]])  # random\n",
      "     |      \n",
      "     |      It landed 4 times on 1, once on 2, etc.\n",
      "     |      \n",
      "     |      Now, throw the dice 20 times, and 20 times again:\n",
      "     |      \n",
      "     |      >>> rng.multinomial(20, [1/6.]*6, size=2)\n",
      "     |      array([[3, 4, 3, 3, 4, 3],\n",
      "     |             [2, 4, 3, 4, 0, 7]])  # random\n",
      "     |      \n",
      "     |      For the first run, we threw 3 times 1, 4 times 2, etc.  For the second,\n",
      "     |      we threw 2 times 1, 4 times 2, etc.\n",
      "     |      \n",
      "     |      Now, do one experiment throwing the dice 10 time, and 10 times again,\n",
      "     |      and another throwing the dice 20 times, and 20 times again:\n",
      "     |      \n",
      "     |      >>> rng.multinomial([[10], [20]], [1/6.]*6, size=2)\n",
      "     |      array([[[2, 4, 0, 1, 2, 1],\n",
      "     |              [1, 3, 0, 3, 1, 2]],\n",
      "     |             [[1, 4, 4, 4, 4, 3],\n",
      "     |              [3, 3, 2, 5, 5, 2]]])  # random\n",
      "     |      \n",
      "     |      The first array shows the outcomes of throwing the dice 10 times, and\n",
      "     |      the second shows the outcomes from throwing the dice 20 times.\n",
      "     |      \n",
      "     |      A loaded die is more likely to land on number 6:\n",
      "     |      \n",
      "     |      >>> rng.multinomial(100, [1/7.]*5 + [2/7.])\n",
      "     |      array([11, 16, 14, 17, 16, 26])  # random\n",
      "     |      \n",
      "     |      The probability inputs should be normalized. As an implementation\n",
      "     |      detail, the value of the last entry is ignored and assumed to take\n",
      "     |      up any leftover probability mass, but this should not be relied on.\n",
      "     |      A biased coin which has twice as much weight on one side as on the\n",
      "     |      other should be sampled like so:\n",
      "     |      \n",
      "     |      >>> rng.multinomial(100, [1.0 / 3, 2.0 / 3])  # RIGHT\n",
      "     |      array([38, 62])  # random\n",
      "     |      \n",
      "     |      not like:\n",
      "     |      \n",
      "     |      >>> rng.multinomial(100, [1.0, 2.0])  # WRONG\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ValueError: pvals < 0, pvals > 1 or pvals contains NaNs\n",
      "     |  \n",
      "     |  multivariate_hypergeometric(...)\n",
      "     |      multivariate_hypergeometric(colors, nsample, size=None,\n",
      "     |                                  method='marginals')\n",
      "     |      \n",
      "     |      Generate variates from a multivariate hypergeometric distribution.\n",
      "     |      \n",
      "     |      The multivariate hypergeometric distribution is a generalization\n",
      "     |      of the hypergeometric distribution.\n",
      "     |      \n",
      "     |      Choose ``nsample`` items at random without replacement from a\n",
      "     |      collection with ``N`` distinct types.  ``N`` is the length of\n",
      "     |      ``colors``, and the values in ``colors`` are the number of occurrences\n",
      "     |      of that type in the collection.  The total number of items in the\n",
      "     |      collection is ``sum(colors)``.  Each random variate generated by this\n",
      "     |      function is a vector of length ``N`` holding the counts of the\n",
      "     |      different types that occurred in the ``nsample`` items.\n",
      "     |      \n",
      "     |      The name ``colors`` comes from a common description of the\n",
      "     |      distribution: it is the probability distribution of the number of\n",
      "     |      marbles of each color selected without replacement from an urn\n",
      "     |      containing marbles of different colors; ``colors[i]`` is the number\n",
      "     |      of marbles in the urn with color ``i``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      colors : sequence of integers\n",
      "     |          The number of each type of item in the collection from which\n",
      "     |          a sample is drawn.  The values in ``colors`` must be nonnegative.\n",
      "     |          To avoid loss of precision in the algorithm, ``sum(colors)``\n",
      "     |          must be less than ``10**9`` when `method` is \"marginals\".\n",
      "     |      nsample : int\n",
      "     |          The number of items selected.  ``nsample`` must not be greater\n",
      "     |          than ``sum(colors)``.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          The number of variates to generate, either an integer or a tuple\n",
      "     |          holding the shape of the array of variates.  If the given size is,\n",
      "     |          e.g., ``(k, m)``, then ``k * m`` variates are drawn, where one\n",
      "     |          variate is a vector of length ``len(colors)``, and the return value\n",
      "     |          has shape ``(k, m, len(colors))``.  If `size` is an integer, the\n",
      "     |          output has shape ``(size, len(colors))``.  Default is None, in\n",
      "     |          which case a single variate is returned as an array with shape\n",
      "     |          ``(len(colors),)``.\n",
      "     |      method : string, optional\n",
      "     |          Specify the algorithm that is used to generate the variates.\n",
      "     |          Must be 'count' or 'marginals' (the default).  See the Notes\n",
      "     |          for a description of the methods.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      variates : ndarray\n",
      "     |          Array of variates drawn from the multivariate hypergeometric\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      hypergeometric : Draw samples from the (univariate) hypergeometric\n",
      "     |          distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The two methods do not return the same sequence of variates.\n",
      "     |      \n",
      "     |      The \"count\" algorithm is roughly equivalent to the following numpy\n",
      "     |      code::\n",
      "     |      \n",
      "     |          choices = np.repeat(np.arange(len(colors)), colors)\n",
      "     |          selection = np.random.choice(choices, nsample, replace=False)\n",
      "     |          variate = np.bincount(selection, minlength=len(colors))\n",
      "     |      \n",
      "     |      The \"count\" algorithm uses a temporary array of integers with length\n",
      "     |      ``sum(colors)``.\n",
      "     |      \n",
      "     |      The \"marginals\" algorithm generates a variate by using repeated\n",
      "     |      calls to the univariate hypergeometric sampler.  It is roughly\n",
      "     |      equivalent to::\n",
      "     |      \n",
      "     |          variate = np.zeros(len(colors), dtype=np.int64)\n",
      "     |          # `remaining` is the cumulative sum of `colors` from the last\n",
      "     |          # element to the first; e.g. if `colors` is [3, 1, 5], then\n",
      "     |          # `remaining` is [9, 6, 5].\n",
      "     |          remaining = np.cumsum(colors[::-1])[::-1]\n",
      "     |          for i in range(len(colors)-1):\n",
      "     |              if nsample < 1:\n",
      "     |                  break\n",
      "     |              variate[i] = hypergeometric(colors[i], remaining[i+1],\n",
      "     |                                         nsample)\n",
      "     |              nsample -= variate[i]\n",
      "     |          variate[-1] = nsample\n",
      "     |      \n",
      "     |      The default method is \"marginals\".  For some cases (e.g. when\n",
      "     |      `colors` contains relatively small integers), the \"count\" method\n",
      "     |      can be significantly faster than the \"marginals\" method.  If\n",
      "     |      performance of the algorithm is important, test the two methods\n",
      "     |      with typical inputs to decide which works best.\n",
      "     |      \n",
      "     |      .. versionadded:: 1.18.0\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> colors = [16, 8, 4]\n",
      "     |      >>> seed = 4861946401452\n",
      "     |      >>> gen = np.random.Generator(np.random.PCG64(seed))\n",
      "     |      >>> gen.multivariate_hypergeometric(colors, 6)\n",
      "     |      array([5, 0, 1])\n",
      "     |      >>> gen.multivariate_hypergeometric(colors, 6, size=3)\n",
      "     |      array([[5, 0, 1],\n",
      "     |             [2, 2, 2],\n",
      "     |             [3, 3, 0]])\n",
      "     |      >>> gen.multivariate_hypergeometric(colors, 6, size=(2, 2))\n",
      "     |      array([[[3, 2, 1],\n",
      "     |              [3, 2, 1]],\n",
      "     |             [[4, 1, 1],\n",
      "     |              [3, 2, 1]]])\n",
      "     |  \n",
      "     |  multivariate_normal(...)\n",
      "     |      multivariate_normal(mean, cov, size=None, check_valid='warn', tol=1e-8)\n",
      "     |      \n",
      "     |      Draw random samples from a multivariate normal distribution.\n",
      "     |      \n",
      "     |      The multivariate normal, multinormal or Gaussian distribution is a\n",
      "     |      generalization of the one-dimensional normal distribution to higher\n",
      "     |      dimensions.  Such a distribution is specified by its mean and\n",
      "     |      covariance matrix.  These parameters are analogous to the mean\n",
      "     |      (average or \"center\") and variance (standard deviation, or \"width,\"\n",
      "     |      squared) of the one-dimensional normal distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : 1-D array_like, of length N\n",
      "     |          Mean of the N-dimensional distribution.\n",
      "     |      cov : 2-D array_like, of shape (N, N)\n",
      "     |          Covariance matrix of the distribution. It must be symmetric and\n",
      "     |          positive-semidefinite for proper sampling.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Given a shape of, for example, ``(m,n,k)``, ``m*n*k`` samples are\n",
      "     |          generated, and packed in an `m`-by-`n`-by-`k` arrangement.  Because\n",
      "     |          each sample is `N`-dimensional, the output shape is ``(m,n,k,N)``.\n",
      "     |          If no shape is specified, a single (`N`-D) sample is returned.\n",
      "     |      check_valid : { 'warn', 'raise', 'ignore' }, optional\n",
      "     |          Behavior when the covariance matrix is not positive semidefinite.\n",
      "     |      tol : float, optional\n",
      "     |          Tolerance when checking the singular values in covariance matrix.\n",
      "     |          cov is cast to double before the check.\n",
      "     |      method : { 'svd', 'eigh', 'cholesky'}, optional\n",
      "     |          The cov input is used to compute a factor matrix A such that\n",
      "     |          ``A @ A.T = cov``. This argument is used to select the method\n",
      "     |          used to compute the factor matrix A. The default method 'svd' is\n",
      "     |          the slowest, while 'cholesky' is the fastest but less robust than\n",
      "     |          the slowest method. The method `eigh` uses eigen decomposition to\n",
      "     |          compute A and is faster than svd but slower than cholesky.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.18.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "     |          the shape is ``(N,)``.\n",
      "     |      \n",
      "     |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "     |          value drawn from the distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mean is a coordinate in N-dimensional space, which represents the\n",
      "     |      location where samples are most likely to be generated.  This is\n",
      "     |      analogous to the peak of the bell curve for the one-dimensional or\n",
      "     |      univariate normal distribution.\n",
      "     |      \n",
      "     |      Covariance indicates the level to which two variables vary together.\n",
      "     |      From the multivariate normal distribution, we draw N-dimensional\n",
      "     |      samples, :math:`X = [x_1, x_2, ... x_N]`.  The covariance matrix\n",
      "     |      element :math:`C_{ij}` is the covariance of :math:`x_i` and :math:`x_j`.\n",
      "     |      The element :math:`C_{ii}` is the variance of :math:`x_i` (i.e. its\n",
      "     |      \"spread\").\n",
      "     |      \n",
      "     |      Instead of specifying the full covariance matrix, popular\n",
      "     |      approximations include:\n",
      "     |      \n",
      "     |        - Spherical covariance (`cov` is a multiple of the identity matrix)\n",
      "     |        - Diagonal covariance (`cov` has non-negative elements, and only on\n",
      "     |          the diagonal)\n",
      "     |      \n",
      "     |      This geometrical property can be seen in two dimensions by plotting\n",
      "     |      generated data-points:\n",
      "     |      \n",
      "     |      >>> mean = [0, 0]\n",
      "     |      >>> cov = [[1, 0], [0, 100]]  # diagonal covariance\n",
      "     |      \n",
      "     |      Diagonal covariance means that points are oriented along x or y-axis:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> x, y = np.random.default_rng().multivariate_normal(mean, cov, 5000).T\n",
      "     |      >>> plt.plot(x, y, 'x')\n",
      "     |      >>> plt.axis('equal')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Note that the covariance matrix must be positive semidefinite (a.k.a.\n",
      "     |      nonnegative-definite). Otherwise, the behavior of this method is\n",
      "     |      undefined and backwards compatibility is not guaranteed.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Papoulis, A., \"Probability, Random Variables, and Stochastic\n",
      "     |             Processes,\" 3rd ed., New York: McGraw-Hill, 1991.\n",
      "     |      .. [2] Duda, R. O., Hart, P. E., and Stork, D. G., \"Pattern\n",
      "     |             Classification,\" 2nd ed., New York: Wiley, 2001.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mean = (1, 2)\n",
      "     |      >>> cov = [[1, 0], [0, 1]]\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> x = rng.multivariate_normal(mean, cov, (3, 3))\n",
      "     |      >>> x.shape\n",
      "     |      (3, 3, 2)\n",
      "     |      \n",
      "     |      We can use a different method other than the default to factorize cov:\n",
      "     |      >>> y = rng.multivariate_normal(mean, cov, (3, 3), method='cholesky')\n",
      "     |      >>> y.shape\n",
      "     |      (3, 3, 2)\n",
      "     |      \n",
      "     |      The following is probably true, given that 0.6 is roughly twice the\n",
      "     |      standard deviation:\n",
      "     |      \n",
      "     |      >>> list((x[0,0,:] - mean) < 0.6)\n",
      "     |      [True, True] # random\n",
      "     |  \n",
      "     |  negative_binomial(...)\n",
      "     |      negative_binomial(n, p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a negative binomial distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a negative binomial distribution with specified\n",
      "     |      parameters, `n` successes and `p` probability of success where `n`\n",
      "     |      is > 0 and `p` is in the interval [0, 1].\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : float or array_like of floats\n",
      "     |          Parameter of the distribution, > 0.\n",
      "     |      p : float or array_like of floats\n",
      "     |          Parameter of the distribution, >= 0 and <=1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized negative binomial distribution,\n",
      "     |          where each sample is equal to N, the number of failures that\n",
      "     |          occurred before a total of n successes was reached.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability mass function of the negative binomial distribution is\n",
      "     |      \n",
      "     |      .. math:: P(N;n,p) = \\frac{\\Gamma(N+n)}{N!\\Gamma(n)}p^{n}(1-p)^{N},\n",
      "     |      \n",
      "     |      where :math:`n` is the number of successes, :math:`p` is the\n",
      "     |      probability of success, :math:`N+n` is the number of trials, and\n",
      "     |      :math:`\\Gamma` is the gamma function. When :math:`n` is an integer,\n",
      "     |      :math:`\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} = \\binom{N+n-1}{N}`, which is\n",
      "     |      the more common form of this term in the the pmf. The negative\n",
      "     |      binomial distribution gives the probability of N failures given n\n",
      "     |      successes, with a success on the last trial.\n",
      "     |      \n",
      "     |      If one throws a die repeatedly until the third time a \"1\" appears,\n",
      "     |      then the probability distribution of the number of non-\"1\"s that\n",
      "     |      appear before the third \"1\" is a negative binomial distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Negative Binomial Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Negative binomial distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      A real world example. A company drills wild-cat oil\n",
      "     |      exploration wells, each with an estimated probability of\n",
      "     |      success of 0.1.  What is the probability of having one success\n",
      "     |      for each successive well, that is what is the probability of a\n",
      "     |      single success after drilling 5 wells, after 6 wells, etc.?\n",
      "     |      \n",
      "     |      >>> s = np.random.default_rng().negative_binomial(1, 0.1, 100000)\n",
      "     |      >>> for i in range(1, 11): # doctest: +SKIP\n",
      "     |      ...    probability = sum(s<i) / 100000.\n",
      "     |      ...    print(i, \"wells drilled, probability of one success =\", probability)\n",
      "     |  \n",
      "     |  noncentral_chisquare(...)\n",
      "     |      noncentral_chisquare(df, nonc, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a noncentral chi-square distribution.\n",
      "     |      \n",
      "     |      The noncentral :math:`\\chi^2` distribution is a generalization of\n",
      "     |      the :math:`\\chi^2` distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |          Degrees of freedom, must be > 0.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.10.0\n",
      "     |             Earlier NumPy versions required dfnum > 1.\n",
      "     |      nonc : float or array_like of floats\n",
      "     |          Non-centrality, must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` and ``nonc`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(df, nonc).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized noncentral chi-square distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the noncentral Chi-square\n",
      "     |      distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;df,nonc) = \\sum^{\\infty}_{i=0}\n",
      "     |                             \\frac{e^{-nonc/2}(nonc/2)^{i}}{i!}\n",
      "     |                             P_{Y_{df+2i}}(x),\n",
      "     |      \n",
      "     |      where :math:`Y_{q}` is the Chi-square with q degrees of freedom.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Noncentral chi-squared distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> values = plt.hist(rng.noncentral_chisquare(3, 20, 100000),\n",
      "     |      ...                   bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Draw values from a noncentral chisquare with very small noncentrality,\n",
      "     |      and compare to a chisquare.\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> values = plt.hist(rng.noncentral_chisquare(3, .0000001, 100000),\n",
      "     |      ...                   bins=np.arange(0., 25, .1), density=True)\n",
      "     |      >>> values2 = plt.hist(rng.chisquare(3, 100000),\n",
      "     |      ...                    bins=np.arange(0., 25, .1), density=True)\n",
      "     |      >>> plt.plot(values[1][0:-1], values[0]-values2[0], 'ob')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Demonstrate how large values of non-centrality lead to a more symmetric\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> values = plt.hist(rng.noncentral_chisquare(3, 20, 100000),\n",
      "     |      ...                   bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  noncentral_f(...)\n",
      "     |      noncentral_f(dfnum, dfden, nonc, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the noncentral F distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from an F distribution with specified parameters,\n",
      "     |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "     |      freedom in denominator), where both parameters > 1.\n",
      "     |      `nonc` is the non-centrality parameter.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dfnum : float or array_like of floats\n",
      "     |          Numerator degrees of freedom, must be > 0.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.14.0\n",
      "     |             Earlier NumPy versions required dfnum > 1.\n",
      "     |      dfden : float or array_like of floats\n",
      "     |          Denominator degrees of freedom, must be > 0.\n",
      "     |      nonc : float or array_like of floats\n",
      "     |          Non-centrality parameter, the sum of the squares of the numerator\n",
      "     |          means, must be >= 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``dfnum``, ``dfden``, and ``nonc``\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(dfnum, dfden, nonc).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized noncentral Fisher distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When calculating the power of an experiment (power = probability of\n",
      "     |      rejecting the null hypothesis when a specific alternative is true) the\n",
      "     |      non-central F statistic becomes important.  When the null hypothesis is\n",
      "     |      true, the F statistic follows a central F distribution. When the null\n",
      "     |      hypothesis is not true, then it follows a non-central F statistic.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Noncentral F-Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/NoncentralF-Distribution.html\n",
      "     |      .. [2] Wikipedia, \"Noncentral F-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Noncentral_F-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      In a study, testing for a specific alternative to the null hypothesis\n",
      "     |      requires use of the Noncentral F distribution. We need to calculate the\n",
      "     |      area in the tail of the distribution that exceeds the value of the F\n",
      "     |      distribution for the null hypothesis.  We'll plot the two probability\n",
      "     |      distributions for comparison.\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> dfnum = 3 # between group deg of freedom\n",
      "     |      >>> dfden = 20 # within groups degrees of freedom\n",
      "     |      >>> nonc = 3.0\n",
      "     |      >>> nc_vals = rng.noncentral_f(dfnum, dfden, nonc, 1000000)\n",
      "     |      >>> NF = np.histogram(nc_vals, bins=50, density=True)\n",
      "     |      >>> c_vals = rng.f(dfnum, dfden, 1000000)\n",
      "     |      >>> F = np.histogram(c_vals, bins=50, density=True)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> plt.plot(F[1][1:], F[0])\n",
      "     |      >>> plt.plot(NF[1][1:], NF[0])\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  normal(...)\n",
      "     |      normal(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw random samples from a normal (Gaussian) distribution.\n",
      "     |      \n",
      "     |      The probability density function of the normal distribution, first\n",
      "     |      derived by De Moivre and 200 years later by both Gauss and Laplace\n",
      "     |      independently [2]_, is often called the bell curve because of\n",
      "     |      its characteristic shape (see the example below).\n",
      "     |      \n",
      "     |      The normal distributions occurs often in nature.  For example, it\n",
      "     |      describes the commonly occurring distribution of samples influenced\n",
      "     |      by a large number of tiny, random disturbances, each with its own\n",
      "     |      unique distribution [2]_.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats\n",
      "     |          Mean (\"centre\") of the distribution.\n",
      "     |      scale : float or array_like of floats\n",
      "     |          Standard deviation (spread or \"width\") of the distribution. Must be\n",
      "     |          non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized normal distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.norm : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gaussian distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
      "     |                       e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
      "     |      deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
      "     |      is called the variance.\n",
      "     |      \n",
      "     |      The function has its peak at the mean, and its \"spread\" increases with\n",
      "     |      the standard deviation (the function reaches 0.607 times its maximum at\n",
      "     |      :math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
      "     |      :meth:`normal` is more likely to return samples lying close to the\n",
      "     |      mean, rather than those far away.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Normal distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Normal_distribution\n",
      "     |      .. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
      "     |             Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
      "     |             pp. 51, 51, 125.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
      "     |      >>> s = np.random.default_rng().normal(mu, sigma, 1000)\n",
      "     |      \n",
      "     |      Verify the mean and the variance:\n",
      "     |      \n",
      "     |      >>> abs(mu - np.mean(s))\n",
      "     |      0.0  # may vary\n",
      "     |      \n",
      "     |      >>> abs(sigma - np.std(s, ddof=1))\n",
      "     |      0.1  # may vary\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
      "     |      ...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Two-by-four array of samples from N(3, 6.25):\n",
      "     |      \n",
      "     |      >>> np.random.default_rng().normal(3, 2.5, size=(2, 4))\n",
      "     |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "     |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "     |  \n",
      "     |  pareto(...)\n",
      "     |      pareto(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Pareto II or Lomax distribution with\n",
      "     |      specified shape.\n",
      "     |      \n",
      "     |      The Lomax or Pareto II distribution is a shifted Pareto\n",
      "     |      distribution. The classical Pareto distribution can be\n",
      "     |      obtained from the Lomax distribution by adding 1 and\n",
      "     |      multiplying by the scale parameter ``m`` (see Notes).  The\n",
      "     |      smallest value of the Lomax distribution is zero while for the\n",
      "     |      classical Pareto distribution it is ``mu``, where the standard\n",
      "     |      Pareto distribution has location ``mu = 1``.  Lomax can also\n",
      "     |      be considered as a simplified version of the Generalized\n",
      "     |      Pareto distribution (available in SciPy), with the scale set\n",
      "     |      to one and the location set to zero.\n",
      "     |      \n",
      "     |      The Pareto distribution must be greater than zero, and is\n",
      "     |      unbounded above.  It is also known as the \"80-20 rule\".  In\n",
      "     |      this distribution, 80 percent of the weights are in the lowest\n",
      "     |      20 percent of the range, while the other 20 percent fill the\n",
      "     |      remaining 80 percent of the range.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Shape of the distribution. Must be positive.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Pareto distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.lomax : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      scipy.stats.genpareto : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Pareto distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{am^a}{x^{a+1}}\n",
      "     |      \n",
      "     |      where :math:`a` is the shape and :math:`m` the scale.\n",
      "     |      \n",
      "     |      The Pareto distribution, named after the Italian economist\n",
      "     |      Vilfredo Pareto, is a power law probability distribution\n",
      "     |      useful in many real world problems.  Outside the field of\n",
      "     |      economics it is generally referred to as the Bradford\n",
      "     |      distribution. Pareto developed the distribution to describe\n",
      "     |      the distribution of wealth in an economy.  It has also found\n",
      "     |      use in insurance, web page access statistics, oil field sizes,\n",
      "     |      and many other problems, including the download frequency for\n",
      "     |      projects in Sourceforge [1]_.  It is one of the so-called\n",
      "     |      \"fat-tailed\" distributions.\n",
      "     |      \n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of\n",
      "     |             Sourceforge projects.\n",
      "     |      .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.\n",
      "     |      .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme\n",
      "     |             Values, Birkhauser Verlag, Basel, pp 23-30.\n",
      "     |      .. [4] Wikipedia, \"Pareto distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Pareto_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a, m = 3., 2.  # shape and mode\n",
      "     |      >>> s = (np.random.default_rng().pareto(a, 1000) + 1) * m\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with the probability\n",
      "     |      density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, _ = plt.hist(s, 100, density=True)\n",
      "     |      >>> fit = a*m**a / bins**(a+1)\n",
      "     |      >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  permutation(...)\n",
      "     |      permutation(x, axis=0)\n",
      "     |      \n",
      "     |      Randomly permute a sequence, or return a permuted range.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : int or array_like\n",
      "     |          If `x` is an integer, randomly permute ``np.arange(x)``.\n",
      "     |          If `x` is an array, make a copy and shuffle the elements\n",
      "     |          randomly.\n",
      "     |      axis : int, optional\n",
      "     |          The axis which `x` is shuffled along. Default is 0.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          Permuted sequence or array range.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.permutation(10)\n",
      "     |      array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random\n",
      "     |      \n",
      "     |      >>> rng.permutation([1, 4, 9, 12, 15])\n",
      "     |      array([15,  1,  9,  4, 12]) # random\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> rng.permutation(arr)\n",
      "     |      array([[6, 7, 8], # random\n",
      "     |             [0, 1, 2],\n",
      "     |             [3, 4, 5]])\n",
      "     |      \n",
      "     |      >>> rng.permutation(\"abc\")\n",
      "     |      Traceback (most recent call last):\n",
      "     |          ...\n",
      "     |      numpy.AxisError: x must be an integer or at least 1-dimensional\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> rng.permutation(arr, axis=1)\n",
      "     |      array([[0, 2, 1], # random\n",
      "     |             [3, 5, 4],\n",
      "     |             [6, 8, 7]])\n",
      "     |  \n",
      "     |  poisson(...)\n",
      "     |      poisson(lam=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Poisson distribution.\n",
      "     |      \n",
      "     |      The Poisson distribution is the limit of the binomial distribution\n",
      "     |      for large N.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lam : float or array_like of floats\n",
      "     |          Expectation of interval, must be >= 0. A sequence of expectation\n",
      "     |          intervals must be broadcastable over the requested size.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``lam`` is a scalar. Otherwise,\n",
      "     |          ``np.array(lam).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Poisson distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Poisson distribution\n",
      "     |      \n",
      "     |      .. math:: f(k; \\lambda)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
      "     |      \n",
      "     |      For events with an expected separation :math:`\\lambda` the Poisson\n",
      "     |      distribution :math:`f(k; \\lambda)` describes the probability of\n",
      "     |      :math:`k` events occurring within the observed\n",
      "     |      interval :math:`\\lambda`.\n",
      "     |      \n",
      "     |      Because the output is limited to the range of the C int64 type, a\n",
      "     |      ValueError is raised when `lam` is within 10 sigma of the maximum\n",
      "     |      representable value.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Poisson Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/PoissonDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Poisson distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Poisson_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> s = rng.poisson(5, 10000)\n",
      "     |      \n",
      "     |      Display histogram of the sample:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 14, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Draw each 100 values for lambda 100 and 500:\n",
      "     |      \n",
      "     |      >>> s = rng.poisson(lam=(100., 500.), size=(100, 2))\n",
      "     |  \n",
      "     |  power(...)\n",
      "     |      power(a, size=None)\n",
      "     |      \n",
      "     |      Draws samples in [0, 1] from a power distribution with positive\n",
      "     |      exponent a - 1.\n",
      "     |      \n",
      "     |      Also known as the power function distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Parameter of the distribution. Must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized power distribution.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If a < 1.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function is\n",
      "     |      \n",
      "     |      .. math:: P(x; a) = ax^{a-1}, 0 \\le x \\le 1, a>0.\n",
      "     |      \n",
      "     |      The power function distribution is just the inverse of the Pareto\n",
      "     |      distribution. It may also be seen as a special case of the Beta\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      It is used, for example, in modeling the over-reporting of insurance\n",
      "     |      claims.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Christian Kleiber, Samuel Kotz, \"Statistical size distributions\n",
      "     |             in economics and actuarial sciences\", Wiley, 2003.\n",
      "     |      .. [2] Heckert, N. A. and Filliben, James J. \"NIST Handbook 148:\n",
      "     |             Dataplot Reference Manual, Volume 2: Let Subcommands and Library\n",
      "     |             Functions\", National Institute of Standards and Technology\n",
      "     |             Handbook Series, June 2003.\n",
      "     |             https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> a = 5. # shape\n",
      "     |      >>> samples = 1000\n",
      "     |      >>> s = rng.power(a, samples)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, bins=30)\n",
      "     |      >>> x = np.linspace(0, 1, 100)\n",
      "     |      >>> y = a*x**(a-1.)\n",
      "     |      >>> normed_y = samples*np.diff(bins)[0]*y\n",
      "     |      >>> plt.plot(x, normed_y)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Compare the power function distribution to the inverse of the Pareto.\n",
      "     |      \n",
      "     |      >>> from scipy import stats  # doctest: +SKIP\n",
      "     |      >>> rvs = rng.power(5, 1000000)\n",
      "     |      >>> rvsp = rng.pareto(5, 1000000)\n",
      "     |      >>> xx = np.linspace(0,1,100)\n",
      "     |      >>> powpdf = stats.powerlaw.pdf(xx,5)  # doctest: +SKIP\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(rvs, bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('power(5)')\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('inverse of 1 + Generator.pareto(5)')\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('inverse of stats.pareto(5)')\n",
      "     |  \n",
      "     |  random(...)\n",
      "     |      random(size=None, dtype=np.float64, out=None)\n",
      "     |      \n",
      "     |      Return random floats in the half-open interval [0.0, 1.0).\n",
      "     |      \n",
      "     |      Results are from the \"continuous uniform\" distribution over the\n",
      "     |      stated interval.  To sample :math:`Unif[a, b), b > a` multiply\n",
      "     |      the output of `random` by `(b-a)` and add `a`::\n",
      "     |      \n",
      "     |        (b - a) * random() + a\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result, only `float64` and `float32` are supported.\n",
      "     |          Byteorder must be native. The default value is np.float64.\n",
      "     |      out : ndarray, optional\n",
      "     |          Alternative output array in which to place the result. If size is not None,\n",
      "     |          it must have the same shape as the provided size and must match the type of\n",
      "     |          the output values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray of floats\n",
      "     |          Array of random floats of shape `size` (unless ``size=None``, in which\n",
      "     |          case a single float is returned).\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.random()\n",
      "     |      0.47108547995356098 # random\n",
      "     |      >>> type(rng.random())\n",
      "     |      <class 'float'>\n",
      "     |      >>> rng.random((5,))\n",
      "     |      array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428]) # random\n",
      "     |      \n",
      "     |      Three-by-two array of random numbers from [-5, 0):\n",
      "     |      \n",
      "     |      >>> 5 * rng.random((3, 2)) - 5\n",
      "     |      array([[-3.99149989, -0.52338984], # random\n",
      "     |             [-2.99091858, -0.79479508],\n",
      "     |             [-1.23204345, -1.75224494]])\n",
      "     |  \n",
      "     |  rayleigh(...)\n",
      "     |      rayleigh(scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Rayleigh distribution.\n",
      "     |      \n",
      "     |      The :math:`\\chi` and Weibull distributions are generalizations of the\n",
      "     |      Rayleigh.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          Scale, also equals the mode. Must be non-negative. Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Rayleigh distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the Rayleigh distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;scale) = \\frac{x}{scale^2}e^{\\frac{-x^2}{2 \\cdotp scale^2}}\n",
      "     |      \n",
      "     |      The Rayleigh distribution would arise, for example, if the East\n",
      "     |      and North components of the wind velocity had identical zero-mean\n",
      "     |      Gaussian distributions.  Then the wind speed would have a Rayleigh\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Brighton Webs Ltd., \"Rayleigh Distribution,\"\n",
      "     |             https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp\n",
      "     |      .. [2] Wikipedia, \"Rayleigh distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Rayleigh_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram\n",
      "     |      \n",
      "     |      >>> from matplotlib.pyplot import hist\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> values = hist(rng.rayleigh(3, 100000), bins=200, density=True)\n",
      "     |      \n",
      "     |      Wave heights tend to follow a Rayleigh distribution. If the mean wave\n",
      "     |      height is 1 meter, what fraction of waves are likely to be larger than 3\n",
      "     |      meters?\n",
      "     |      \n",
      "     |      >>> meanvalue = 1\n",
      "     |      >>> modevalue = np.sqrt(2 / np.pi) * meanvalue\n",
      "     |      >>> s = rng.rayleigh(modevalue, 1000000)\n",
      "     |      \n",
      "     |      The percentage of waves larger than 3 meters is:\n",
      "     |      \n",
      "     |      >>> 100.*sum(s>3)/1000000.\n",
      "     |      0.087300000000000003 # random\n",
      "     |  \n",
      "     |  shuffle(...)\n",
      "     |      shuffle(x, axis=0)\n",
      "     |      \n",
      "     |      Modify a sequence in-place by shuffling its contents.\n",
      "     |      \n",
      "     |      The order of sub-arrays is changed but their contents remains the same.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          The array or list to be shuffled.\n",
      "     |      axis : int, optional\n",
      "     |          The axis which `x` is shuffled along. Default is 0.\n",
      "     |          It is only supported on `ndarray` objects.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> arr = np.arange(10)\n",
      "     |      >>> rng.shuffle(arr)\n",
      "     |      >>> arr\n",
      "     |      [1 7 5 2 9 4 3 6 0 8] # random\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> rng.shuffle(arr)\n",
      "     |      >>> arr\n",
      "     |      array([[3, 4, 5], # random\n",
      "     |             [6, 7, 8],\n",
      "     |             [0, 1, 2]])\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> rng.shuffle(arr, axis=1)\n",
      "     |      >>> arr\n",
      "     |      array([[2, 0, 1], # random\n",
      "     |             [5, 3, 4],\n",
      "     |             [8, 6, 7]])\n",
      "     |  \n",
      "     |  standard_cauchy(...)\n",
      "     |      standard_cauchy(size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Cauchy distribution with mode = 0.\n",
      "     |      \n",
      "     |      Also known as the Lorentz distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : ndarray or scalar\n",
      "     |          The drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the full Cauchy distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\bigl[ 1+\n",
      "     |                (\\frac{x-x_0}{\\gamma})^2 \\bigr] }\n",
      "     |      \n",
      "     |      and the Standard Cauchy distribution just sets :math:`x_0=0` and\n",
      "     |      :math:`\\gamma=1`\n",
      "     |      \n",
      "     |      The Cauchy distribution arises in the solution to the driven harmonic\n",
      "     |      oscillator problem, and also describes spectral line broadening. It\n",
      "     |      also describes the distribution of values at which a line tilted at\n",
      "     |      a random angle will cut the x axis.\n",
      "     |      \n",
      "     |      When studying hypothesis tests that assume normality, seeing how the\n",
      "     |      tests perform on data from a Cauchy distribution is a good indicator of\n",
      "     |      their sensitivity to a heavy-tailed distribution, since the Cauchy looks\n",
      "     |      very much like a Gaussian distribution, but with heavier tails.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, \"Cauchy\n",
      "     |            Distribution\",\n",
      "     |            https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n",
      "     |      .. [2] Weisstein, Eric W. \"Cauchy Distribution.\" From MathWorld--A\n",
      "     |            Wolfram Web Resource.\n",
      "     |            http://mathworld.wolfram.com/CauchyDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Cauchy distribution\"\n",
      "     |            https://en.wikipedia.org/wiki/Cauchy_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples and plot the distribution:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> s = np.random.default_rng().standard_cauchy(1000000)\n",
      "     |      >>> s = s[(s>-25) & (s<25)]  # truncate distribution so it plots well\n",
      "     |      >>> plt.hist(s, bins=100)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  standard_exponential(...)\n",
      "     |      standard_exponential(size=None, dtype=np.float64, method='zig', out=None)\n",
      "     |      \n",
      "     |      Draw samples from the standard exponential distribution.\n",
      "     |      \n",
      "     |      `standard_exponential` is identical to the exponential distribution\n",
      "     |      with a scale parameter of 1.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result, only `float64` and `float32` are supported.\n",
      "     |          Byteorder must be native. The default value is np.float64.\n",
      "     |      method : str, optional\n",
      "     |          Either 'inv' or 'zig'. 'inv' uses the default inverse CDF method.\n",
      "     |          'zig' uses the much faster Ziggurat method of Marsaglia and Tsang.\n",
      "     |      out : ndarray, optional\n",
      "     |          Alternative output array in which to place the result. If size is not None,\n",
      "     |          it must have the same shape as the provided size and must match the type of\n",
      "     |          the output values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Output a 3x8000 array:\n",
      "     |      \n",
      "     |      >>> n = np.random.default_rng().standard_exponential((3, 8000))\n",
      "     |  \n",
      "     |  standard_gamma(...)\n",
      "     |      standard_gamma(shape, size=None, dtype=np.float64, out=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Gamma distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      "     |      shape (sometimes designated \"k\") and scale=1.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      shape : float or array_like of floats\n",
      "     |          Parameter, must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``shape`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(shape).size`` samples are drawn.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result, only `float64` and `float32` are supported.\n",
      "     |          Byteorder must be native. The default value is np.float64.\n",
      "     |      out : ndarray, optional\n",
      "     |          Alternative output array in which to place the result. If size is\n",
      "     |          not None, it must have the same shape as the provided size and\n",
      "     |          must match the type of the output values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized standard gamma distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gamma : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gamma distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "     |      \n",
      "     |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "     |      and :math:`\\Gamma` is the Gamma function.\n",
      "     |      \n",
      "     |      The Gamma distribution is often used to model the times to failure of\n",
      "     |      electronic components, and arises naturally in processes for which the\n",
      "     |      waiting times between Poisson distributed events are relevant.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> shape, scale = 2., 1. # mean and width\n",
      "     |      >>> s = np.random.default_rng().standard_gamma(shape, 1000000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> import scipy.special as sps  # doctest: +SKIP\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "     |      >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/  # doctest: +SKIP\n",
      "     |      ...                       (sps.gamma(shape) * scale**shape))\n",
      "     |      >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  standard_normal(...)\n",
      "     |      standard_normal(size=None, dtype=np.float64, out=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Normal distribution (mean=0, stdev=1).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result, only `float64` and `float32` are supported.\n",
      "     |          Byteorder must be native. The default value is np.float64.\n",
      "     |      out : ndarray, optional\n",
      "     |          Alternative output array in which to place the result. If size is not None,\n",
      "     |          it must have the same shape as the provided size and must match the type of\n",
      "     |          the output values.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray\n",
      "     |          A floating-point array of shape ``size`` of drawn samples, or a\n",
      "     |          single sample if ``size`` was not specified.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      normal :\n",
      "     |          Equivalent function with additional ``loc`` and ``scale`` arguments\n",
      "     |          for setting the mean and standard deviation.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For random samples from :math:`N(\\mu, \\sigma^2)`, use one of::\n",
      "     |      \n",
      "     |          mu + sigma * gen.standard_normal(size=...)\n",
      "     |          gen.normal(mu, sigma, size=...)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> rng.standard_normal()\n",
      "     |      2.1923875335537315 #random\n",
      "     |      \n",
      "     |      >>> s = rng.standard_normal(8000)\n",
      "     |      >>> s\n",
      "     |      array([ 0.6888893 ,  0.78096262, -0.89086505, ...,  0.49876311,  # random\n",
      "     |             -0.38672696, -0.4685006 ])                                # random\n",
      "     |      >>> s.shape\n",
      "     |      (8000,)\n",
      "     |      >>> s = rng.standard_normal(size=(3, 4, 2))\n",
      "     |      >>> s.shape\n",
      "     |      (3, 4, 2)\n",
      "     |      \n",
      "     |      Two-by-four array of samples from :math:`N(3, 6.25)`:\n",
      "     |      \n",
      "     |      >>> 3 + 2.5 * rng.standard_normal(size=(2, 4))\n",
      "     |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "     |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "     |  \n",
      "     |  standard_t(...)\n",
      "     |      standard_t(df, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Student's t distribution with `df` degrees\n",
      "     |      of freedom.\n",
      "     |      \n",
      "     |      A special case of the hyperbolic distribution.  As `df` gets\n",
      "     |      large, the result resembles that of the standard normal\n",
      "     |      distribution (`standard_normal`).\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |          Degrees of freedom, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(df).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized standard Student's t distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the t distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x, df) = \\frac{\\Gamma(\\frac{df+1}{2})}{\\sqrt{\\pi df}\n",
      "     |                \\Gamma(\\frac{df}{2})}\\Bigl( 1+\\frac{x^2}{df} \\Bigr)^{-(df+1)/2}\n",
      "     |      \n",
      "     |      The t test is based on an assumption that the data come from a\n",
      "     |      Normal distribution. The t test provides a way to test whether\n",
      "     |      the sample mean (that is the mean calculated from the data) is\n",
      "     |      a good estimate of the true mean.\n",
      "     |      \n",
      "     |      The derivation of the t-distribution was first published in\n",
      "     |      1908 by William Gosset while working for the Guinness Brewery\n",
      "     |      in Dublin. Due to proprietary issues, he had to publish under\n",
      "     |      a pseudonym, and so he used the name Student.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Dalgaard, Peter, \"Introductory Statistics With R\",\n",
      "     |             Springer, 2002.\n",
      "     |      .. [2] Wikipedia, \"Student's t-distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Student's_t-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      From Dalgaard page 83 [1]_, suppose the daily energy intake for 11\n",
      "     |      women in kilojoules (kJ) is:\n",
      "     |      \n",
      "     |      >>> intake = np.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, \\\n",
      "     |      ...                    7515, 8230, 8770])\n",
      "     |      \n",
      "     |      Does their energy intake deviate systematically from the recommended\n",
      "     |      value of 7725 kJ?\n",
      "     |      \n",
      "     |      We have 10 degrees of freedom, so is the sample mean within 95% of the\n",
      "     |      recommended value?\n",
      "     |      \n",
      "     |      >>> s = np.random.default_rng().standard_t(10, size=100000)\n",
      "     |      >>> np.mean(intake)\n",
      "     |      6753.636363636364\n",
      "     |      >>> intake.std(ddof=1)\n",
      "     |      1142.1232221373727\n",
      "     |      \n",
      "     |      Calculate the t statistic, setting the ddof parameter to the unbiased\n",
      "     |      value so the divisor in the standard deviation will be degrees of\n",
      "     |      freedom, N-1.\n",
      "     |      \n",
      "     |      >>> t = (np.mean(intake)-7725)/(intake.std(ddof=1)/np.sqrt(len(intake)))\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(s, bins=100, density=True)\n",
      "     |      \n",
      "     |      For a one-sided t-test, how far out in the distribution does the t\n",
      "     |      statistic appear?\n",
      "     |      \n",
      "     |      >>> np.sum(s<t) / float(len(s))\n",
      "     |      0.0090699999999999999  #random\n",
      "     |      \n",
      "     |      So the p-value is about 0.009, which says the null hypothesis has a\n",
      "     |      probability of about 99% of being true.\n",
      "     |  \n",
      "     |  triangular(...)\n",
      "     |      triangular(left, mode, right, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the triangular distribution over the\n",
      "     |      interval ``[left, right]``.\n",
      "     |      \n",
      "     |      The triangular distribution is a continuous probability\n",
      "     |      distribution with lower limit left, peak at mode, and upper\n",
      "     |      limit right. Unlike the other distributions, these parameters\n",
      "     |      directly define the shape of the pdf.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      left : float or array_like of floats\n",
      "     |          Lower limit.\n",
      "     |      mode : float or array_like of floats\n",
      "     |          The value where the peak of the distribution occurs.\n",
      "     |          The value must fulfill the condition ``left <= mode <= right``.\n",
      "     |      right : float or array_like of floats\n",
      "     |          Upper limit, must be larger than `left`.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``left``, ``mode``, and ``right``\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(left, mode, right).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized triangular distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the triangular distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;l, m, r) = \\begin{cases}\n",
      "     |                \\frac{2(x-l)}{(r-l)(m-l)}& \\text{for $l \\leq x \\leq m$},\\\\\n",
      "     |                \\frac{2(r-x)}{(r-l)(r-m)}& \\text{for $m \\leq x \\leq r$},\\\\\n",
      "     |                0& \\text{otherwise}.\n",
      "     |                \\end{cases}\n",
      "     |      \n",
      "     |      The triangular distribution is often used in ill-defined\n",
      "     |      problems where the underlying distribution is not known, but\n",
      "     |      some knowledge of the limits and mode exists. Often it is used\n",
      "     |      in simulations.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Triangular distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Triangular_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(np.random.default_rng().triangular(-3, 0, 8, 100000), bins=200,\n",
      "     |      ...              density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  uniform(...)\n",
      "     |      uniform(low=0.0, high=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a uniform distribution.\n",
      "     |      \n",
      "     |      Samples are uniformly distributed over the half-open interval\n",
      "     |      ``[low, high)`` (includes low, but excludes high).  In other words,\n",
      "     |      any value within the given interval is equally likely to be drawn\n",
      "     |      by `uniform`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : float or array_like of floats, optional\n",
      "     |          Lower boundary of the output interval.  All values generated will be\n",
      "     |          greater than or equal to low.  The default value is 0.\n",
      "     |      high : float or array_like of floats\n",
      "     |          Upper boundary of the output interval.  All values generated will be\n",
      "     |          less than high.  The default value is 1.0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``low`` and ``high`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(low, high).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized uniform distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      integers : Discrete uniform distribution, yielding integers.\n",
      "     |      random : Floats uniformly distributed over ``[0, 1)``.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function of the uniform distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{b - a}\n",
      "     |      \n",
      "     |      anywhere within the interval ``[a, b)``, and zero elsewhere.\n",
      "     |      \n",
      "     |      When ``high`` == ``low``, values of ``low`` will be returned.\n",
      "     |      If ``high`` < ``low``, the results are officially undefined\n",
      "     |      and may eventually raise an error, i.e. do not rely on this\n",
      "     |      function to behave when passed arguments satisfying that\n",
      "     |      inequality condition.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> s = np.random.default_rng().uniform(-1,0,1000)\n",
      "     |      \n",
      "     |      All values are within the given interval:\n",
      "     |      \n",
      "     |      >>> np.all(s >= -1)\n",
      "     |      True\n",
      "     |      >>> np.all(s < 0)\n",
      "     |      True\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with the\n",
      "     |      probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 15, density=True)\n",
      "     |      >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  vonmises(...)\n",
      "     |      vonmises(mu, kappa, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a von Mises distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a von Mises distribution with specified mode\n",
      "     |      (mu) and dispersion (kappa), on the interval [-pi, pi].\n",
      "     |      \n",
      "     |      The von Mises distribution (also known as the circular normal\n",
      "     |      distribution) is a continuous probability distribution on the unit\n",
      "     |      circle.  It may be thought of as the circular analogue of the normal\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : float or array_like of floats\n",
      "     |          Mode (\"center\") of the distribution.\n",
      "     |      kappa : float or array_like of floats\n",
      "     |          Dispersion of the distribution, has to be >=0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mu`` and ``kappa`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mu, kappa).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized von Mises distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.vonmises : probability density function, distribution, or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the von Mises distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{e^{\\kappa cos(x-\\mu)}}{2\\pi I_0(\\kappa)},\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mode and :math:`\\kappa` the dispersion,\n",
      "     |      and :math:`I_0(\\kappa)` is the modified Bessel function of order 0.\n",
      "     |      \n",
      "     |      The von Mises is named for Richard Edler von Mises, who was born in\n",
      "     |      Austria-Hungary, in what is now the Ukraine.  He fled to the United\n",
      "     |      States in 1939 and became a professor at Harvard.  He worked in\n",
      "     |      probability theory, aerodynamics, fluid mechanics, and philosophy of\n",
      "     |      science.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "     |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "     |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      "     |      .. [2] von Mises, R., \"Mathematical Theory of Probability\n",
      "     |             and Statistics\", New York: Academic Press, 1964.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, kappa = 0.0, 4.0 # mean and dispersion\n",
      "     |      >>> s = np.random.default_rng().vonmises(mu, kappa, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from scipy.special import i0  # doctest: +SKIP\n",
      "     |      >>> plt.hist(s, 50, density=True)\n",
      "     |      >>> x = np.linspace(-np.pi, np.pi, num=51)\n",
      "     |      >>> y = np.exp(kappa*np.cos(x-mu))/(2*np.pi*i0(kappa))  # doctest: +SKIP\n",
      "     |      >>> plt.plot(x, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  wald(...)\n",
      "     |      wald(mean, scale, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Wald, or inverse Gaussian, distribution.\n",
      "     |      \n",
      "     |      As the scale approaches infinity, the distribution becomes more like a\n",
      "     |      Gaussian. Some references claim that the Wald is an inverse Gaussian\n",
      "     |      with mean equal to 1, but this is by no means universal.\n",
      "     |      \n",
      "     |      The inverse Gaussian distribution was first studied in relationship to\n",
      "     |      Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n",
      "     |      because there is an inverse relationship between the time to cover a\n",
      "     |      unit distance and distance covered in unit time.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : float or array_like of floats\n",
      "     |          Distribution mean, must be > 0.\n",
      "     |      scale : float or array_like of floats\n",
      "     |          Scale parameter, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mean`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Wald distribution.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the Wald distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n",
      "     |                                  \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n",
      "     |      \n",
      "     |      As noted above the inverse Gaussian distribution first arise\n",
      "     |      from attempts to model Brownian motion. It is also a\n",
      "     |      competitor to the Weibull for use in reliability modeling and\n",
      "     |      modeling stock returns and interest rate processes.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Brighton Webs Ltd., Wald Distribution,\n",
      "     |             https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp\n",
      "     |      .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n",
      "     |             Distribution: Theory : Methodology, and Applications\", CRC Press,\n",
      "     |             1988.\n",
      "     |      .. [3] Wikipedia, \"Inverse Gaussian distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(np.random.default_rng().wald(3, 2, 100000), bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  weibull(...)\n",
      "     |      weibull(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Weibull distribution.\n",
      "     |      \n",
      "     |      Draw samples from a 1-parameter Weibull distribution with the given\n",
      "     |      shape parameter `a`.\n",
      "     |      \n",
      "     |      .. math:: X = (-ln(U))^{1/a}\n",
      "     |      \n",
      "     |      Here, U is drawn from the uniform distribution over (0,1].\n",
      "     |      \n",
      "     |      The more common 2-parameter Weibull, including a scale parameter\n",
      "     |      :math:`\\lambda` is just :math:`X = \\lambda(-ln(U))^{1/a}`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Shape parameter of the distribution.  Must be nonnegative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Weibull distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.weibull_max\n",
      "     |      scipy.stats.weibull_min\n",
      "     |      scipy.stats.genextreme\n",
      "     |      gumbel\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Weibull (or Type III asymptotic extreme value distribution\n",
      "     |      for smallest values, SEV Type III, or Rosin-Rammler\n",
      "     |      distribution) is one of a class of Generalized Extreme Value\n",
      "     |      (GEV) distributions used in modeling extreme value problems.\n",
      "     |      This class includes the Gumbel and Frechet distributions.\n",
      "     |      \n",
      "     |      The probability density for the Weibull distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{a}\n",
      "     |                       {\\lambda}(\\frac{x}{\\lambda})^{a-1}e^{-(x/\\lambda)^a},\n",
      "     |      \n",
      "     |      where :math:`a` is the shape and :math:`\\lambda` the scale.\n",
      "     |      \n",
      "     |      The function has its peak (the mode) at\n",
      "     |      :math:`\\lambda(\\frac{a-1}{a})^{1/a}`.\n",
      "     |      \n",
      "     |      When ``a = 1``, the Weibull distribution reduces to the exponential\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Waloddi Weibull, Royal Technical University, Stockholm,\n",
      "     |             1939 \"A Statistical Theory Of The Strength Of Materials\",\n",
      "     |             Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939,\n",
      "     |             Generalstabens Litografiska Anstalts Forlag, Stockholm.\n",
      "     |      .. [2] Waloddi Weibull, \"A Statistical Distribution Function of\n",
      "     |             Wide Applicability\", Journal Of Applied Mechanics ASME Paper\n",
      "     |             1951.\n",
      "     |      .. [3] Wikipedia, \"Weibull distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Weibull_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> rng = np.random.default_rng()\n",
      "     |      >>> a = 5. # shape\n",
      "     |      >>> s = rng.weibull(a, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> x = np.arange(1,100.)/50.\n",
      "     |      >>> def weib(x,n,a):\n",
      "     |      ...     return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)\n",
      "     |      \n",
      "     |      >>> count, bins, ignored = plt.hist(rng.weibull(5.,1000))\n",
      "     |      >>> x = np.arange(1,100.)/50.\n",
      "     |      >>> scale = count.max()/weib(x, 1., 5.).max()\n",
      "     |      >>> plt.plot(x, weib(x, 1., 5.)*scale)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  zipf(...)\n",
      "     |      zipf(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Zipf distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Zipf distribution with specified parameter\n",
      "     |      `a` > 1.\n",
      "     |      \n",
      "     |      The Zipf distribution (also known as the zeta distribution) is a\n",
      "     |      continuous probability distribution that satisfies Zipf's law: the\n",
      "     |      frequency of an item is inversely proportional to its rank in a\n",
      "     |      frequency table.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Distribution parameter. Must be greater than 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar. Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Zipf distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.zipf : probability density function, distribution, or\n",
      "     |          cumulative density function, etc.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Zipf distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{x^{-a}}{\\zeta(a)},\n",
      "     |      \n",
      "     |      where :math:`\\zeta` is the Riemann Zeta function.\n",
      "     |      \n",
      "     |      It is named for the American linguist George Kingsley Zipf, who noted\n",
      "     |      that the frequency of any word in a sample of a language is inversely\n",
      "     |      proportional to its rank in the frequency table.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Zipf, G. K., \"Selected Studies of the Principle of Relative\n",
      "     |             Frequency in Language,\" Cambridge, MA: Harvard Univ. Press,\n",
      "     |             1932.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = 2. # parameter\n",
      "     |      >>> s = np.random.default_rng().zipf(a, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from scipy import special  # doctest: +SKIP\n",
      "     |      \n",
      "     |      Truncate s values at 50 so plot is interesting:\n",
      "     |      \n",
      "     |      >>> count, bins, ignored = plt.hist(s[s<50],\n",
      "     |      ...         50, density=True)\n",
      "     |      >>> x = np.arange(1., 50.)\n",
      "     |      >>> y = x**(-a) / special.zetac(a)  # doctest: +SKIP\n",
      "     |      >>> plt.plot(x, y/max(y), linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  bit_generator\n",
      "     |      Gets the bit generator instance used by the generator\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bit_generator : BitGenerator\n",
      "     |          The bit generator instance used by the generator\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class MT19937(numpy.random._bit_generator.BitGenerator)\n",
      "     |  MT19937(seed=None)\n",
      "     |  \n",
      "     |  Container for the Mersenne Twister pseudo-random number generator.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like[ints], SeedSequence}, optional\n",
      "     |      A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "     |      unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "     |      ``array_like[ints]`` is passed, then it will be passed to\n",
      "     |      `SeedSequence` to derive the initial `BitGenerator` state. One may also\n",
      "     |      pass in a `SeedSequence` instance.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  lock: threading.Lock\n",
      "     |      Lock instance that is shared so that the same bit git generator can\n",
      "     |      be used in multiple Generators without corrupting the state. Code that\n",
      "     |      generates values from a bit generator should hold the bit generator's\n",
      "     |      lock.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  ``MT19937`` provides a capsule containing function pointers that produce\n",
      "     |  doubles, and unsigned 32 and 64- bit integers [1]_. These are not\n",
      "     |  directly consumable in Python and must be consumed by a ``Generator``\n",
      "     |  or similar object that supports low-level access.\n",
      "     |  \n",
      "     |  The Python stdlib module \"random\" also contains a Mersenne Twister\n",
      "     |  pseudo-random number generator.\n",
      "     |  \n",
      "     |  **State and Seeding**\n",
      "     |  \n",
      "     |  The ``MT19937`` state vector consists of a 624-element array of\n",
      "     |  32-bit unsigned integers plus a single integer value between 0 and 624\n",
      "     |  that indexes the current position within the main array.\n",
      "     |  \n",
      "     |  The input seed is processed by `SeedSequence` to fill the whole state. The\n",
      "     |  first element is reset such that only its most significant bit is set.\n",
      "     |  \n",
      "     |  **Parallel Features**\n",
      "     |  \n",
      "     |  The preferred way to use a BitGenerator in parallel applications is to use\n",
      "     |  the `SeedSequence.spawn` method to obtain entropy values, and to use these\n",
      "     |  to generate new BitGenerators:\n",
      "     |  \n",
      "     |  >>> from numpy.random import Generator, MT19937, SeedSequence\n",
      "     |  >>> sg = SeedSequence(1234)\n",
      "     |  >>> rg = [Generator(MT19937(s)) for s in sg.spawn(10)]\n",
      "     |  \n",
      "     |  Another method is to use `MT19937.jumped` which advances the state as-if\n",
      "     |  :math:`2^{128}` random numbers have been generated ([1]_, [2]_). This\n",
      "     |  allows the original sequence to be split so that distinct segments can be\n",
      "     |  used in each worker process. All generators should be chained to ensure\n",
      "     |  that the segments come from the same sequence.\n",
      "     |  \n",
      "     |  >>> from numpy.random import Generator, MT19937, SeedSequence\n",
      "     |  >>> sg = SeedSequence(1234)\n",
      "     |  >>> bit_generator = MT19937(sg)\n",
      "     |  >>> rg = []\n",
      "     |  >>> for _ in range(10):\n",
      "     |  ...    rg.append(Generator(bit_generator))\n",
      "     |  ...    # Chain the BitGenerators\n",
      "     |  ...    bit_generator = bit_generator.jumped()\n",
      "     |  \n",
      "     |  **Compatibility Guarantee**\n",
      "     |  \n",
      "     |  ``MT19937`` makes a guarantee that a fixed seed and will always produce\n",
      "     |  the same random integer stream.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] Hiroshi Haramoto, Makoto Matsumoto, and Pierre L'Ecuyer, \"A Fast\n",
      "     |      Jump Ahead Algorithm for Linear Recurrences in a Polynomial Space\",\n",
      "     |      Sequences and Their Applications - SETA, 290--298, 2008.\n",
      "     |  .. [2] Hiroshi Haramoto, Makoto Matsumoto, Takuji Nishimura, François\n",
      "     |      Panneton, Pierre L'Ecuyer, \"Efficient Jump Ahead for F2-Linear\n",
      "     |      Random Number Generators\", INFORMS JOURNAL ON COMPUTING, Vol. 20,\n",
      "     |      No. 3, Summer 2008, pp. 385-390.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      MT19937\n",
      "     |      numpy.random._bit_generator.BitGenerator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate_cython__(...)\n",
      "     |  \n",
      "     |  jumped(...)\n",
      "     |      jumped(jumps=1)\n",
      "     |      \n",
      "     |      Returns a new bit generator with the state jumped\n",
      "     |      \n",
      "     |      The state of the returned big generator is jumped as-if\n",
      "     |      2**(128 * jumps) random numbers have been generated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      jumps : integer, positive\n",
      "     |          Number of times to jump the state of the bit generator returned\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bit_generator : MT19937\n",
      "     |          New instance of generator jumped iter times\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  state\n",
      "     |      Get or set the PRNG state\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict\n",
      "     |          Dictionary containing the information required to describe the\n",
      "     |          state of the PRNG\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  random_raw(...)\n",
      "     |      random_raw(self, size=None)\n",
      "     |      \n",
      "     |      Return randoms as generated by the underlying BitGenerator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      output : bool, optional\n",
      "     |          Output values.  Used for performance testing since the generated\n",
      "     |          values are not returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : uint or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method directly exposes the the raw underlying pseudo-random\n",
      "     |      number generator. All values are returned as unsigned 64-bit\n",
      "     |      values irrespective of the number of bits produced by the PRNG.\n",
      "     |      \n",
      "     |      See the class docstring for the number of bits returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  capsule\n",
      "     |  \n",
      "     |  cffi\n",
      "     |      CFFI interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing CFFI wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      ctypes interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing ctypes wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  lock\n",
      "    \n",
      "    class PCG64(numpy.random._bit_generator.BitGenerator)\n",
      "     |  PCG64(seed_seq=None)\n",
      "     |  \n",
      "     |  BitGenerator for the PCG-64 pseudo-random number generator.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like[ints], SeedSequence}, optional\n",
      "     |      A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "     |      unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "     |      ``array_like[ints]`` is passed, then it will be passed to\n",
      "     |      `SeedSequence` to derive the initial `BitGenerator` state. One may also\n",
      "     |      pass in a `SeedSequence` instance.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  PCG-64 is a 128-bit implementation of O'Neill's permutation congruential\n",
      "     |  generator ([1]_, [2]_). PCG-64 has a period of :math:`2^{128}` and supports\n",
      "     |  advancing an arbitrary number of steps as well as :math:`2^{127}` streams.\n",
      "     |  The specific member of the PCG family that we use is PCG XSL RR 128/64\n",
      "     |  as described in the paper ([2]_).\n",
      "     |  \n",
      "     |  ``PCG64`` provides a capsule containing function pointers that produce\n",
      "     |  doubles, and unsigned 32 and 64- bit integers. These are not\n",
      "     |  directly consumable in Python and must be consumed by a ``Generator``\n",
      "     |  or similar object that supports low-level access.\n",
      "     |  \n",
      "     |  Supports the method :meth:`advance` to advance the RNG an arbitrary number of\n",
      "     |  steps. The state of the PCG-64 RNG is represented by 2 128-bit unsigned\n",
      "     |  integers.\n",
      "     |  \n",
      "     |  **State and Seeding**\n",
      "     |  \n",
      "     |  The ``PCG64`` state vector consists of 2 unsigned 128-bit values,\n",
      "     |  which are represented externally as Python ints. One is the state of the\n",
      "     |  PRNG, which is advanced by a linear congruential generator (LCG). The\n",
      "     |  second is a fixed odd increment used in the LCG.\n",
      "     |  \n",
      "     |  The input seed is processed by `SeedSequence` to generate both values. The\n",
      "     |  increment is not independently settable.\n",
      "     |  \n",
      "     |  **Parallel Features**\n",
      "     |  \n",
      "     |  The preferred way to use a BitGenerator in parallel applications is to use\n",
      "     |  the `SeedSequence.spawn` method to obtain entropy values, and to use these\n",
      "     |  to generate new BitGenerators:\n",
      "     |  \n",
      "     |  >>> from numpy.random import Generator, PCG64, SeedSequence\n",
      "     |  >>> sg = SeedSequence(1234)\n",
      "     |  >>> rg = [Generator(PCG64(s)) for s in sg.spawn(10)]\n",
      "     |  \n",
      "     |  **Compatibility Guarantee**\n",
      "     |  \n",
      "     |  ``PCG64`` makes a guarantee that a fixed seed and will always produce\n",
      "     |  the same random integer stream.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] `\"PCG, A Family of Better Random Number Generators\"\n",
      "     |         <http://www.pcg-random.org/>`_\n",
      "     |  .. [2] O'Neill, Melissa E. `\"PCG: A Family of Simple Fast Space-Efficient\n",
      "     |         Statistically Good Algorithms for Random Number Generation\"\n",
      "     |         <https://www.cs.hmc.edu/tr/hmc-cs-2014-0905.pdf>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      PCG64\n",
      "     |      numpy.random._bit_generator.BitGenerator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate_cython__(...)\n",
      "     |  \n",
      "     |  advance(...)\n",
      "     |      advance(delta)\n",
      "     |      \n",
      "     |      Advance the underlying RNG as-if delta draws have occurred.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      delta : integer, positive\n",
      "     |          Number of draws to advance the RNG. Must be less than the\n",
      "     |          size state variable in the underlying RNG.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : PCG64\n",
      "     |          RNG advanced delta steps\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Advancing a RNG updates the underlying RNG state as-if a given\n",
      "     |      number of calls to the underlying RNG have been made. In general\n",
      "     |      there is not a one-to-one relationship between the number output\n",
      "     |      random values from a particular distribution and the number of\n",
      "     |      draws from the core RNG.  This occurs for two reasons:\n",
      "     |      \n",
      "     |      * The random values are simulated using a rejection-based method\n",
      "     |        and so, on average, more than one value from the underlying\n",
      "     |        RNG is required to generate an single draw.\n",
      "     |      * The number of bits required to generate a simulated value\n",
      "     |        differs from the number of bits generated by the underlying\n",
      "     |        RNG.  For example, two 16-bit integer values can be simulated\n",
      "     |        from a single draw of a 32-bit RNG.\n",
      "     |      \n",
      "     |      Advancing the RNG state resets any pre-computed random numbers.\n",
      "     |      This is required to ensure exact reproducibility.\n",
      "     |  \n",
      "     |  jumped(...)\n",
      "     |      jumped(jumps=1)\n",
      "     |      \n",
      "     |      Returns a new bit generator with the state jumped.\n",
      "     |      \n",
      "     |      Jumps the state as-if jumps * 210306068529402873165736369884012333109\n",
      "     |      random numbers have been generated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      jumps : integer, positive\n",
      "     |          Number of times to jump the state of the bit generator returned\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bit_generator : PCG64\n",
      "     |          New instance of generator jumped iter times\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The step size is phi-1 when multiplied by 2**128 where phi is the\n",
      "     |      golden ratio.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  state\n",
      "     |      Get or set the PRNG state\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict\n",
      "     |          Dictionary containing the information required to describe the\n",
      "     |          state of the PRNG\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  random_raw(...)\n",
      "     |      random_raw(self, size=None)\n",
      "     |      \n",
      "     |      Return randoms as generated by the underlying BitGenerator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      output : bool, optional\n",
      "     |          Output values.  Used for performance testing since the generated\n",
      "     |          values are not returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : uint or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method directly exposes the the raw underlying pseudo-random\n",
      "     |      number generator. All values are returned as unsigned 64-bit\n",
      "     |      values irrespective of the number of bits produced by the PRNG.\n",
      "     |      \n",
      "     |      See the class docstring for the number of bits returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  capsule\n",
      "     |  \n",
      "     |  cffi\n",
      "     |      CFFI interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing CFFI wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      ctypes interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing ctypes wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  lock\n",
      "    \n",
      "    class Philox(numpy.random._bit_generator.BitGenerator)\n",
      "     |  Philox(seed=None, counter=None, key=None)\n",
      "     |  \n",
      "     |  Container for the Philox (4x64) pseudo-random number generator.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like[ints], SeedSequence}, optional\n",
      "     |      A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "     |      unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "     |      ``array_like[ints]`` is passed, then it will be passed to\n",
      "     |      `SeedSequence` to derive the initial `BitGenerator` state. One may also\n",
      "     |      pass in a `SeedSequence` instance.\n",
      "     |  counter : {None, int, array_like}, optional\n",
      "     |      Counter to use in the Philox state. Can be either\n",
      "     |      a Python int (long in 2.x) in [0, 2**256) or a 4-element uint64 array.\n",
      "     |      If not provided, the RNG is initialized at 0.\n",
      "     |  key : {None, int, array_like}, optional\n",
      "     |      Key to use in the Philox state.  Unlike ``seed``, the value in key is\n",
      "     |      directly set. Can be either a Python int in [0, 2**128) or a 2-element\n",
      "     |      uint64 array. `key` and ``seed`` cannot both be used.\n",
      "     |  \n",
      "     |  Attributes\n",
      "     |  ----------\n",
      "     |  lock: threading.Lock\n",
      "     |      Lock instance that is shared so that the same bit git generator can\n",
      "     |      be used in multiple Generators without corrupting the state. Code that\n",
      "     |      generates values from a bit generator should hold the bit generator's\n",
      "     |      lock.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  Philox is a 64-bit PRNG that uses a counter-based design based on weaker\n",
      "     |  (and faster) versions of cryptographic functions [1]_. Instances using\n",
      "     |  different values of the key produce independent sequences.  Philox has a\n",
      "     |  period of :math:`2^{256} - 1` and supports arbitrary advancing and jumping\n",
      "     |  the sequence in increments of :math:`2^{128}`. These features allow\n",
      "     |  multiple non-overlapping sequences to be generated.\n",
      "     |  \n",
      "     |  ``Philox`` provides a capsule containing function pointers that produce\n",
      "     |  doubles, and unsigned 32 and 64- bit integers. These are not\n",
      "     |  directly consumable in Python and must be consumed by a ``Generator``\n",
      "     |  or similar object that supports low-level access.\n",
      "     |  \n",
      "     |  **State and Seeding**\n",
      "     |  \n",
      "     |  The ``Philox`` state vector consists of a 256-bit value encoded as\n",
      "     |  a 4-element uint64 array and a 128-bit value encoded as a 2-element uint64\n",
      "     |  array. The former is a counter which is incremented by 1 for every 4 64-bit\n",
      "     |  randoms produced. The second is a key which determined the sequence\n",
      "     |  produced. Using different keys produces independent sequences.\n",
      "     |  \n",
      "     |  The input ``seed`` is processed by `SeedSequence` to generate the key. The\n",
      "     |  counter is set to 0.\n",
      "     |  \n",
      "     |  Alternately, one can omit the ``seed`` parameter and set the ``key`` and\n",
      "     |  ``counter`` directly.\n",
      "     |  \n",
      "     |  **Parallel Features**\n",
      "     |  \n",
      "     |  The preferred way to use a BitGenerator in parallel applications is to use\n",
      "     |  the `SeedSequence.spawn` method to obtain entropy values, and to use these\n",
      "     |  to generate new BitGenerators:\n",
      "     |  \n",
      "     |  >>> from numpy.random import Generator, Philox, SeedSequence\n",
      "     |  >>> sg = SeedSequence(1234)\n",
      "     |  >>> rg = [Generator(Philox(s)) for s in sg.spawn(10)]\n",
      "     |  \n",
      "     |  ``Philox`` can be used in parallel applications by calling the ``jumped``\n",
      "     |  method  to advances the state as-if :math:`2^{128}` random numbers have\n",
      "     |  been generated. Alternatively, ``advance`` can be used to advance the\n",
      "     |  counter for any positive step in [0, 2**256). When using ``jumped``, all\n",
      "     |  generators should be chained to ensure that the segments come from the same\n",
      "     |  sequence.\n",
      "     |  \n",
      "     |  >>> from numpy.random import Generator, Philox\n",
      "     |  >>> bit_generator = Philox(1234)\n",
      "     |  >>> rg = []\n",
      "     |  >>> for _ in range(10):\n",
      "     |  ...    rg.append(Generator(bit_generator))\n",
      "     |  ...    bit_generator = bit_generator.jumped()\n",
      "     |  \n",
      "     |  Alternatively, ``Philox`` can be used in parallel applications by using\n",
      "     |  a sequence of distinct keys where each instance uses different key.\n",
      "     |  \n",
      "     |  >>> key = 2**96 + 2**33 + 2**17 + 2**9\n",
      "     |  >>> rg = [Generator(Philox(key=key+i)) for i in range(10)]\n",
      "     |  \n",
      "     |  **Compatibility Guarantee**\n",
      "     |  \n",
      "     |  ``Philox`` makes a guarantee that a fixed ``seed`` will always produce\n",
      "     |  the same random integer stream.\n",
      "     |  \n",
      "     |  Examples\n",
      "     |  --------\n",
      "     |  >>> from numpy.random import Generator, Philox\n",
      "     |  >>> rg = Generator(Philox(1234))\n",
      "     |  >>> rg.standard_normal()\n",
      "     |  0.123  # random\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] John K. Salmon, Mark A. Moraes, Ron O. Dror, and David E. Shaw,\n",
      "     |         \"Parallel Random Numbers: As Easy as 1, 2, 3,\" Proceedings of\n",
      "     |         the International Conference for High Performance Computing,\n",
      "     |         Networking, Storage and Analysis (SC11), New York, NY: ACM, 2011.\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      Philox\n",
      "     |      numpy.random._bit_generator.BitGenerator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate_cython__(...)\n",
      "     |  \n",
      "     |  advance(...)\n",
      "     |      advance(delta)\n",
      "     |      \n",
      "     |      Advance the underlying RNG as-if delta draws have occurred.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      delta : integer, positive\n",
      "     |          Number of draws to advance the RNG. Must be less than the\n",
      "     |          size state variable in the underlying RNG.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      self : Philox\n",
      "     |          RNG advanced delta steps\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      Advancing a RNG updates the underlying RNG state as-if a given\n",
      "     |      number of calls to the underlying RNG have been made. In general\n",
      "     |      there is not a one-to-one relationship between the number output\n",
      "     |      random values from a particular distribution and the number of\n",
      "     |      draws from the core RNG.  This occurs for two reasons:\n",
      "     |      \n",
      "     |      * The random values are simulated using a rejection-based method\n",
      "     |        and so, on average, more than one value from the underlying\n",
      "     |        RNG is required to generate an single draw.\n",
      "     |      * The number of bits required to generate a simulated value\n",
      "     |        differs from the number of bits generated by the underlying\n",
      "     |        RNG.  For example, two 16-bit integer values can be simulated\n",
      "     |        from a single draw of a 32-bit RNG.\n",
      "     |      \n",
      "     |      Advancing the RNG state resets any pre-computed random numbers.\n",
      "     |      This is required to ensure exact reproducibility.\n",
      "     |  \n",
      "     |  jumped(...)\n",
      "     |      jumped(jumps=1)\n",
      "     |      \n",
      "     |      Returns a new bit generator with the state jumped\n",
      "     |      \n",
      "     |      The state of the returned big generator is jumped as-if\n",
      "     |      2**(128 * jumps) random numbers have been generated.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      jumps : integer, positive\n",
      "     |          Number of times to jump the state of the bit generator returned\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      bit_generator : Philox\n",
      "     |          New instance of generator jumped iter times\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  state\n",
      "     |      Get or set the PRNG state\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict\n",
      "     |          Dictionary containing the information required to describe the\n",
      "     |          state of the PRNG\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  random_raw(...)\n",
      "     |      random_raw(self, size=None)\n",
      "     |      \n",
      "     |      Return randoms as generated by the underlying BitGenerator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      output : bool, optional\n",
      "     |          Output values.  Used for performance testing since the generated\n",
      "     |          values are not returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : uint or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method directly exposes the the raw underlying pseudo-random\n",
      "     |      number generator. All values are returned as unsigned 64-bit\n",
      "     |      values irrespective of the number of bits produced by the PRNG.\n",
      "     |      \n",
      "     |      See the class docstring for the number of bits returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  capsule\n",
      "     |  \n",
      "     |  cffi\n",
      "     |      CFFI interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing CFFI wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      ctypes interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing ctypes wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  lock\n",
      "    \n",
      "    class RandomState(builtins.object)\n",
      "     |  RandomState(seed=None)\n",
      "     |  \n",
      "     |  Container for the slow Mersenne Twister pseudo-random number generator.\n",
      "     |  Consider using a different BitGenerator with the Generator container\n",
      "     |  instead.\n",
      "     |  \n",
      "     |  `RandomState` and `Generator` expose a number of methods for generating\n",
      "     |  random numbers drawn from a variety of probability distributions. In\n",
      "     |  addition to the distribution-specific arguments, each method takes a\n",
      "     |  keyword argument `size` that defaults to ``None``. If `size` is ``None``,\n",
      "     |  then a single value is generated and returned. If `size` is an integer,\n",
      "     |  then a 1-D array filled with generated values is returned. If `size` is a\n",
      "     |  tuple, then an array with that shape is filled and returned.\n",
      "     |  \n",
      "     |  **Compatibility Guarantee**\n",
      "     |  \n",
      "     |  A fixed bit generator using a fixed seed and a fixed series of calls to\n",
      "     |  'RandomState' methods using the same parameters will always produce the\n",
      "     |  same results up to roundoff error except when the values were incorrect.\n",
      "     |  `RandomState` is effectively frozen and will only receive updates that\n",
      "     |  are required by changes in the the internals of Numpy. More substantial\n",
      "     |  changes, including algorithmic improvements, are reserved for\n",
      "     |  `Generator`.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like, BitGenerator}, optional\n",
      "     |      Random seed used to initialize the pseudo-random number generator or\n",
      "     |      an instantized BitGenerator.  If an integer or array, used as a seed for\n",
      "     |      the MT19937 BitGenerator. Values can be any integer between 0 and\n",
      "     |      2**32 - 1 inclusive, an array (or other sequence) of such integers,\n",
      "     |      or ``None`` (the default).  If `seed` is ``None``, then the `MT19937`\n",
      "     |      BitGenerator is initialized by reading data from ``/dev/urandom``\n",
      "     |      (or the Windows analogue) if available or seed from the clock\n",
      "     |      otherwise.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  The Python stdlib module \"random\" also contains a Mersenne Twister\n",
      "     |  pseudo-random number generator with a number of methods that are similar\n",
      "     |  to the ones available in `RandomState`. `RandomState`, besides being\n",
      "     |  NumPy-aware, has the advantage that it provides a much larger number\n",
      "     |  of probability distributions to choose from.\n",
      "     |  \n",
      "     |  See Also\n",
      "     |  --------\n",
      "     |  Generator\n",
      "     |  MT19937\n",
      "     |  numpy.random.BitGenerator\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  __str__(self, /)\n",
      "     |      Return str(self).\n",
      "     |  \n",
      "     |  beta(...)\n",
      "     |      beta(a, b, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Beta distribution.\n",
      "     |      \n",
      "     |      The Beta distribution is a special case of the Dirichlet distribution,\n",
      "     |      and is related to the Gamma distribution.  It has the probability\n",
      "     |      distribution function\n",
      "     |      \n",
      "     |      .. math:: f(x; a,b) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}\n",
      "     |                                                       (1 - x)^{\\beta - 1},\n",
      "     |      \n",
      "     |      where the normalization, B, is the beta function,\n",
      "     |      \n",
      "     |      .. math:: B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}\n",
      "     |                                   (1 - t)^{\\beta - 1} dt.\n",
      "     |      \n",
      "     |      It is often seen in Bayesian inference and order statistics.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``beta`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Alpha, positive (>0).\n",
      "     |      b : float or array_like of floats\n",
      "     |          Beta, positive (>0).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` and ``b`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(a, b).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized beta distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.beta: which should be used for new code.\n",
      "     |  \n",
      "     |  binomial(...)\n",
      "     |      binomial(n, p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a binomial distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a binomial distribution with specified\n",
      "     |      parameters, n trials and p probability of success where\n",
      "     |      n an integer >= 0 and p is in the interval [0,1]. (n may be\n",
      "     |      input as a float, but it is truncated to an integer in use)\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``binomial`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int or array_like of ints\n",
      "     |          Parameter of the distribution, >= 0. Floats are also accepted,\n",
      "     |          but they will be truncated to integers.\n",
      "     |      p : float or array_like of floats\n",
      "     |          Parameter of the distribution, >= 0 and <=1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized binomial distribution, where\n",
      "     |          each sample is equal to the number of successes over the n trials.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.binom : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.binomial: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the binomial distribution is\n",
      "     |      \n",
      "     |      .. math:: P(N) = \\binom{n}{N}p^N(1-p)^{n-N},\n",
      "     |      \n",
      "     |      where :math:`n` is the number of trials, :math:`p` is the probability\n",
      "     |      of success, and :math:`N` is the number of successes.\n",
      "     |      \n",
      "     |      When estimating the standard error of a proportion in a population by\n",
      "     |      using a random sample, the normal distribution works well unless the\n",
      "     |      product p*n <=5, where p = population proportion estimate, and n =\n",
      "     |      number of samples, in which case the binomial distribution is used\n",
      "     |      instead. For example, a sample of 15 people shows 4 who are left\n",
      "     |      handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4,\n",
      "     |      so the binomial distribution should be used in this case.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Dalgaard, Peter, \"Introductory Statistics with R\",\n",
      "     |             Springer-Verlag, 2002.\n",
      "     |      .. [2] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "     |             Fifth Edition, 2002.\n",
      "     |      .. [3] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "     |             and Quigley, 1972.\n",
      "     |      .. [4] Weisstein, Eric W. \"Binomial Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/BinomialDistribution.html\n",
      "     |      .. [5] Wikipedia, \"Binomial distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Binomial_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> n, p = 10, .5  # number of trials, probability of each trial\n",
      "     |      >>> s = np.random.binomial(n, p, 1000)\n",
      "     |      # result of flipping a coin 10 times, tested 1000 times.\n",
      "     |      \n",
      "     |      A real world example. A company drills 9 wild-cat oil exploration\n",
      "     |      wells, each with an estimated probability of success of 0.1. All nine\n",
      "     |      wells fail. What is the probability of that happening?\n",
      "     |      \n",
      "     |      Let's do 20,000 trials of the model, and count the number that\n",
      "     |      generate zero positive results.\n",
      "     |      \n",
      "     |      >>> sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.\n",
      "     |      # answer = 0.38885, or 38%.\n",
      "     |  \n",
      "     |  bytes(...)\n",
      "     |      bytes(length)\n",
      "     |      \n",
      "     |      Return random bytes.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``bytes`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      length : int\n",
      "     |          Number of random bytes.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : str\n",
      "     |          String of length `length`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.bytes: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.bytes(10)\n",
      "     |      ' eh\\x85\\x022SZ\\xbf\\xa4' #random\n",
      "     |  \n",
      "     |  chisquare(...)\n",
      "     |      chisquare(df, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a chi-square distribution.\n",
      "     |      \n",
      "     |      When `df` independent random variables, each with standard normal\n",
      "     |      distributions (mean 0, variance 1), are squared and summed, the\n",
      "     |      resulting distribution is chi-square (see Notes).  This distribution\n",
      "     |      is often used in hypothesis testing.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``chisquare`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |           Number of degrees of freedom, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(df).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized chi-square distribution.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          When `df` <= 0 or when an inappropriate `size` (e.g. ``size=-1``)\n",
      "     |          is given.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.chisquare: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The variable obtained by summing the squares of `df` independent,\n",
      "     |      standard normally distributed random variables:\n",
      "     |      \n",
      "     |      .. math:: Q = \\sum_{i=0}^{\\mathtt{df}} X^2_i\n",
      "     |      \n",
      "     |      is chi-square distributed, denoted\n",
      "     |      \n",
      "     |      .. math:: Q \\sim \\chi^2_k.\n",
      "     |      \n",
      "     |      The probability density function of the chi-squared distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{(1/2)^{k/2}}{\\Gamma(k/2)}\n",
      "     |                       x^{k/2 - 1} e^{-x/2},\n",
      "     |      \n",
      "     |      where :math:`\\Gamma` is the gamma function,\n",
      "     |      \n",
      "     |      .. math:: \\Gamma(x) = \\int_0^{-\\infty} t^{x - 1} e^{-t} dt.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] NIST \"Engineering Statistics Handbook\"\n",
      "     |             https://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.chisquare(2,4)\n",
      "     |      array([ 1.89920014,  9.00867716,  3.13710533,  5.62318272]) # random\n",
      "     |  \n",
      "     |  choice(...)\n",
      "     |      choice(a, size=None, replace=True, p=None)\n",
      "     |      \n",
      "     |      Generates a random sample from a given 1-D array\n",
      "     |      \n",
      "     |              .. versionadded:: 1.7.0\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``choice`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : 1-D array-like or int\n",
      "     |          If an ndarray, a random sample is generated from its elements.\n",
      "     |          If an int, the random sample is generated as if a were np.arange(a)\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      replace : boolean, optional\n",
      "     |          Whether the sample is with or without replacement\n",
      "     |      p : 1-D array-like, optional\n",
      "     |          The probabilities associated with each entry in a.\n",
      "     |          If not given the sample assumes a uniform distribution over all\n",
      "     |          entries in a.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : single item or ndarray\n",
      "     |          The generated random samples\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If a is an int and less than zero, if a or p are not 1-dimensional,\n",
      "     |          if a is an array-like of size 0, if p is not a vector of\n",
      "     |          probabilities, if a and p have different lengths, or if\n",
      "     |          replace=False and the sample size is greater than the population\n",
      "     |          size\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      randint, shuffle, permutation\n",
      "     |      Generator.choice: which should be used in new code\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Generate a uniform random sample from np.arange(5) of size 3:\n",
      "     |      \n",
      "     |      >>> np.random.choice(5, 3)\n",
      "     |      array([0, 3, 4]) # random\n",
      "     |      >>> #This is equivalent to np.random.randint(0,5,3)\n",
      "     |      \n",
      "     |      Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "     |      \n",
      "     |      >>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "     |      array([3, 3, 0]) # random\n",
      "     |      \n",
      "     |      Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "     |      replacement:\n",
      "     |      \n",
      "     |      >>> np.random.choice(5, 3, replace=False)\n",
      "     |      array([3,1,0]) # random\n",
      "     |      >>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
      "     |      \n",
      "     |      Generate a non-uniform random sample from np.arange(5) of size\n",
      "     |      3 without replacement:\n",
      "     |      \n",
      "     |      >>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "     |      array([2, 3, 0]) # random\n",
      "     |      \n",
      "     |      Any of the above can be repeated with an arbitrary array-like\n",
      "     |      instead of just integers. For instance:\n",
      "     |      \n",
      "     |      >>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      "     |      >>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "     |      array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
      "     |            dtype='<U11')\n",
      "     |  \n",
      "     |  dirichlet(...)\n",
      "     |      dirichlet(alpha, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the Dirichlet distribution.\n",
      "     |      \n",
      "     |      Draw `size` samples of dimension k from a Dirichlet distribution. A\n",
      "     |      Dirichlet-distributed random variable can be seen as a multivariate\n",
      "     |      generalization of a Beta distribution. The Dirichlet distribution\n",
      "     |      is a conjugate prior of a multinomial distribution in Bayesian\n",
      "     |      inference.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``dirichlet`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      alpha : sequence of floats, length k\n",
      "     |          Parameter of the distribution (length ``k`` for sample of\n",
      "     |          length ``k``).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          vector of length ``k`` is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : ndarray,\n",
      "     |          The drawn samples, of shape ``(size, k)``.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      -------\n",
      "     |      ValueError\n",
      "     |          If any value in ``alpha`` is less than or equal to zero\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.dirichlet: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Dirichlet distribution is a distribution over vectors\n",
      "     |      :math:`x` that fulfil the conditions :math:`x_i>0` and\n",
      "     |      :math:`\\sum_{i=1}^k x_i = 1`.\n",
      "     |      \n",
      "     |      The probability density function :math:`p` of a\n",
      "     |      Dirichlet-distributed random vector :math:`X` is\n",
      "     |      proportional to\n",
      "     |      \n",
      "     |      .. math:: p(x) \\propto \\prod_{i=1}^{k}{x^{\\alpha_i-1}_i},\n",
      "     |      \n",
      "     |      where :math:`\\alpha` is a vector containing the positive\n",
      "     |      concentration parameters.\n",
      "     |      \n",
      "     |      The method uses the following property for computation: let :math:`Y`\n",
      "     |      be a random vector which has components that follow a standard gamma\n",
      "     |      distribution, then :math:`X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y`\n",
      "     |      is Dirichlet-distributed\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] David McKay, \"Information Theory, Inference and Learning\n",
      "     |             Algorithms,\" chapter 23,\n",
      "     |             http://www.inference.org.uk/mackay/itila/\n",
      "     |      .. [2] Wikipedia, \"Dirichlet distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Dirichlet_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Taking an example cited in Wikipedia, this distribution can be used if\n",
      "     |      one wanted to cut strings (each of initial length 1.0) into K pieces\n",
      "     |      with different lengths, where each piece had, on average, a designated\n",
      "     |      average length, but allowing some variation in the relative sizes of\n",
      "     |      the pieces.\n",
      "     |      \n",
      "     |      >>> s = np.random.dirichlet((10, 5, 3), 20).transpose()\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> plt.barh(range(20), s[0])\n",
      "     |      >>> plt.barh(range(20), s[1], left=s[0], color='g')\n",
      "     |      >>> plt.barh(range(20), s[2], left=s[0]+s[1], color='r')\n",
      "     |      >>> plt.title(\"Lengths of Strings\")\n",
      "     |  \n",
      "     |  exponential(...)\n",
      "     |      exponential(scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from an exponential distribution.\n",
      "     |      \n",
      "     |      Its probability density function is\n",
      "     |      \n",
      "     |      .. math:: f(x; \\frac{1}{\\beta}) = \\frac{1}{\\beta} \\exp(-\\frac{x}{\\beta}),\n",
      "     |      \n",
      "     |      for ``x > 0`` and 0 elsewhere. :math:`\\beta` is the scale parameter,\n",
      "     |      which is the inverse of the rate parameter :math:`\\lambda = 1/\\beta`.\n",
      "     |      The rate parameter is an alternative, widely used parameterization\n",
      "     |      of the exponential distribution [3]_.\n",
      "     |      \n",
      "     |      The exponential distribution is a continuous analogue of the\n",
      "     |      geometric distribution.  It describes many common situations, such as\n",
      "     |      the size of raindrops measured over many rainstorms [1]_, or the time\n",
      "     |      between page requests to Wikipedia [2]_.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``exponential`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scale : float or array_like of floats\n",
      "     |          The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n",
      "     |          non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized exponential distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.exponential: which should be used for new code.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Peyton Z. Peebles Jr., \"Probability, Random Variables and\n",
      "     |             Random Signal Principles\", 4th ed, 2001, p. 57.\n",
      "     |      .. [2] Wikipedia, \"Poisson process\",\n",
      "     |             https://en.wikipedia.org/wiki/Poisson_process\n",
      "     |      .. [3] Wikipedia, \"Exponential distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Exponential_distribution\n",
      "     |  \n",
      "     |  f(...)\n",
      "     |      f(dfnum, dfden, size=None)\n",
      "     |      \n",
      "     |      Draw samples from an F distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from an F distribution with specified parameters,\n",
      "     |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "     |      freedom in denominator), where both parameters must be greater than\n",
      "     |      zero.\n",
      "     |      \n",
      "     |      The random variate of the F distribution (also known as the\n",
      "     |      Fisher distribution) is a continuous probability distribution\n",
      "     |      that arises in ANOVA tests, and is the ratio of two chi-square\n",
      "     |      variates.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``f`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dfnum : float or array_like of floats\n",
      "     |          Degrees of freedom in numerator, must be > 0.\n",
      "     |      dfden : float or array_like of float\n",
      "     |          Degrees of freedom in denominator, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``dfnum`` and ``dfden`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(dfnum, dfden).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Fisher distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.f : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.f: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The F statistic is used to compare in-group variances to between-group\n",
      "     |      variances. Calculating the distribution depends on the sampling, and\n",
      "     |      so it is a function of the respective degrees of freedom in the\n",
      "     |      problem.  The variable `dfnum` is the number of samples minus one, the\n",
      "     |      between-groups degrees of freedom, while `dfden` is the within-groups\n",
      "     |      degrees of freedom, the sum of the number of samples in each group\n",
      "     |      minus the number of groups.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "     |             Fifth Edition, 2002.\n",
      "     |      .. [2] Wikipedia, \"F-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/F-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      An example from Glantz[1], pp 47-40:\n",
      "     |      \n",
      "     |      Two groups, children of diabetics (25 people) and children from people\n",
      "     |      without diabetes (25 controls). Fasting blood glucose was measured,\n",
      "     |      case group had a mean value of 86.1, controls had a mean value of\n",
      "     |      82.2. Standard deviations were 2.09 and 2.49 respectively. Are these\n",
      "     |      data consistent with the null hypothesis that the parents diabetic\n",
      "     |      status does not affect their children's blood glucose levels?\n",
      "     |      Calculating the F statistic from the data gives a value of 36.01.\n",
      "     |      \n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> dfnum = 1. # between group degrees of freedom\n",
      "     |      >>> dfden = 48. # within groups degrees of freedom\n",
      "     |      >>> s = np.random.f(dfnum, dfden, 1000)\n",
      "     |      \n",
      "     |      The lower bound for the top 1% of the samples is :\n",
      "     |      \n",
      "     |      >>> np.sort(s)[-10]\n",
      "     |      7.61988120985 # random\n",
      "     |      \n",
      "     |      So there is about a 1% chance that the F statistic will exceed 7.62,\n",
      "     |      the measured value is 36, so the null hypothesis is rejected at the 1%\n",
      "     |      level.\n",
      "     |  \n",
      "     |  gamma(...)\n",
      "     |      gamma(shape, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Gamma distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      "     |      `shape` (sometimes designated \"k\") and `scale` (sometimes designated\n",
      "     |      \"theta\"), where both parameters are > 0.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``gamma`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      shape : float or array_like of floats\n",
      "     |          The shape of the gamma distribution. Must be non-negative.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          The scale of the gamma distribution. Must be non-negative.\n",
      "     |          Default is equal to 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``shape`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(shape, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized gamma distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gamma : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.gamma: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gamma distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "     |      \n",
      "     |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "     |      and :math:`\\Gamma` is the Gamma function.\n",
      "     |      \n",
      "     |      The Gamma distribution is often used to model the times to failure of\n",
      "     |      electronic components, and arises naturally in processes for which the\n",
      "     |      waiting times between Poisson distributed events are relevant.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> shape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\n",
      "     |      >>> s = np.random.gamma(shape, scale, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> import scipy.special as sps  # doctest: +SKIP\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "     |      >>> y = bins**(shape-1)*(np.exp(-bins/scale) /  # doctest: +SKIP\n",
      "     |      ...                      (sps.gamma(shape)*scale**shape))\n",
      "     |      >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  geometric(...)\n",
      "     |      geometric(p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the geometric distribution.\n",
      "     |      \n",
      "     |      Bernoulli trials are experiments with one of two outcomes:\n",
      "     |      success or failure (an example of such an experiment is flipping\n",
      "     |      a coin).  The geometric distribution models the number of trials\n",
      "     |      that must be run in order to achieve success.  It is therefore\n",
      "     |      supported on the positive integers, ``k = 1, 2, ...``.\n",
      "     |      \n",
      "     |      The probability mass function of the geometric distribution is\n",
      "     |      \n",
      "     |      .. math:: f(k) = (1 - p)^{k - 1} p\n",
      "     |      \n",
      "     |      where `p` is the probability of success of an individual trial.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``geometric`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float or array_like of floats\n",
      "     |          The probability of success of an individual trial.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized geometric distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.geometric: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw ten thousand values from the geometric distribution,\n",
      "     |      with the probability of an individual success equal to 0.35:\n",
      "     |      \n",
      "     |      >>> z = np.random.geometric(p=0.35, size=10000)\n",
      "     |      \n",
      "     |      How many trials succeeded after a single run?\n",
      "     |      \n",
      "     |      >>> (z == 1).sum() / 10000.\n",
      "     |      0.34889999999999999 #random\n",
      "     |  \n",
      "     |  get_state(...)\n",
      "     |      get_state()\n",
      "     |      \n",
      "     |      Return a tuple representing the internal state of the generator.\n",
      "     |      \n",
      "     |      For more details, see `set_state`.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : {tuple(str, ndarray of 624 uints, int, int, float), dict}\n",
      "     |          The returned tuple has the following items:\n",
      "     |      \n",
      "     |          1. the string 'MT19937'.\n",
      "     |          2. a 1-D array of 624 unsigned integer keys.\n",
      "     |          3. an integer ``pos``.\n",
      "     |          4. an integer ``has_gauss``.\n",
      "     |          5. a float ``cached_gaussian``.\n",
      "     |      \n",
      "     |          If `legacy` is False, or the BitGenerator is not NT19937, then\n",
      "     |          state is returned as a dictionary.\n",
      "     |      \n",
      "     |      legacy : bool\n",
      "     |          Flag indicating the return a legacy tuple state when the BitGenerator\n",
      "     |          is MT19937.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      set_state\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `set_state` and `get_state` are not needed to work with any of the\n",
      "     |      random distributions in NumPy. If the internal state is manually altered,\n",
      "     |      the user should know exactly what he/she is doing.\n",
      "     |  \n",
      "     |  gumbel(...)\n",
      "     |      gumbel(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Gumbel distribution.\n",
      "     |      \n",
      "     |      Draw samples from a Gumbel distribution with specified location and\n",
      "     |      scale.  For more information on the Gumbel distribution, see\n",
      "     |      Notes and References below.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``gumbel`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          The location of the mode of the distribution. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          The scale parameter of the distribution. Default is 1. Must be non-\n",
      "     |          negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Gumbel distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gumbel_l\n",
      "     |      scipy.stats.gumbel_r\n",
      "     |      scipy.stats.genextreme\n",
      "     |      weibull\n",
      "     |      Generator.gumbel: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme\n",
      "     |      Value Type I) distribution is one of a class of Generalized Extreme\n",
      "     |      Value (GEV) distributions used in modeling extreme value problems.\n",
      "     |      The Gumbel is a special case of the Extreme Value Type I distribution\n",
      "     |      for maximums from distributions with \"exponential-like\" tails.\n",
      "     |      \n",
      "     |      The probability density for the Gumbel distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{e^{-(x - \\mu)/ \\beta}}{\\beta} e^{ -e^{-(x - \\mu)/\n",
      "     |                \\beta}},\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mode, a location parameter, and\n",
      "     |      :math:`\\beta` is the scale parameter.\n",
      "     |      \n",
      "     |      The Gumbel (named for German mathematician Emil Julius Gumbel) was used\n",
      "     |      very early in the hydrology literature, for modeling the occurrence of\n",
      "     |      flood events. It is also used for modeling maximum wind speed and\n",
      "     |      rainfall rates.  It is a \"fat-tailed\" distribution - the probability of\n",
      "     |      an event in the tail of the distribution is larger than if one used a\n",
      "     |      Gaussian, hence the surprisingly frequent occurrence of 100-year\n",
      "     |      floods. Floods were initially modeled as a Gaussian process, which\n",
      "     |      underestimated the frequency of extreme events.\n",
      "     |      \n",
      "     |      It is one of a class of extreme value distributions, the Generalized\n",
      "     |      Extreme Value (GEV) distributions, which also includes the Weibull and\n",
      "     |      Frechet.\n",
      "     |      \n",
      "     |      The function has a mean of :math:`\\mu + 0.57721\\beta` and a variance\n",
      "     |      of :math:`\\frac{\\pi^2}{6}\\beta^2`.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Gumbel, E. J., \"Statistics of Extremes,\"\n",
      "     |             New York: Columbia University Press, 1958.\n",
      "     |      .. [2] Reiss, R.-D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "     |             Values from Insurance, Finance, Hydrology and Other Fields,\"\n",
      "     |             Basel: Birkhauser Verlag, 2001.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, beta = 0, 0.1 # location and scale\n",
      "     |      >>> s = np.random.gumbel(mu, beta, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "     |      ...          * np.exp( -np.exp( -(bins - mu) /beta) ),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Show how an extreme value distribution can arise from a Gaussian process\n",
      "     |      and compare to a Gaussian:\n",
      "     |      \n",
      "     |      >>> means = []\n",
      "     |      >>> maxima = []\n",
      "     |      >>> for i in range(0,1000) :\n",
      "     |      ...    a = np.random.normal(mu, beta, 1000)\n",
      "     |      ...    means.append(a.mean())\n",
      "     |      ...    maxima.append(a.max())\n",
      "     |      >>> count, bins, ignored = plt.hist(maxima, 30, density=True)\n",
      "     |      >>> beta = np.std(maxima) * np.sqrt(6) / np.pi\n",
      "     |      >>> mu = np.mean(maxima) - 0.57721*beta\n",
      "     |      >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "     |      ...          * np.exp(-np.exp(-(bins - mu)/beta)),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi))\n",
      "     |      ...          * np.exp(-(bins - mu)**2 / (2 * beta**2)),\n",
      "     |      ...          linewidth=2, color='g')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  hypergeometric(...)\n",
      "     |      hypergeometric(ngood, nbad, nsample, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Hypergeometric distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a hypergeometric distribution with specified\n",
      "     |      parameters, `ngood` (ways to make a good selection), `nbad` (ways to make\n",
      "     |      a bad selection), and `nsample` (number of items sampled, which is less\n",
      "     |      than or equal to the sum ``ngood + nbad``).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``hypergeometric`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      ngood : int or array_like of ints\n",
      "     |          Number of ways to make a good selection.  Must be nonnegative.\n",
      "     |      nbad : int or array_like of ints\n",
      "     |          Number of ways to make a bad selection.  Must be nonnegative.\n",
      "     |      nsample : int or array_like of ints\n",
      "     |          Number of items sampled.  Must be at least 1 and at most\n",
      "     |          ``ngood + nbad``.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if `ngood`, `nbad`, and `nsample`\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(ngood, nbad, nsample).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized hypergeometric distribution. Each\n",
      "     |          sample is the number of good items within a randomly selected subset of\n",
      "     |          size `nsample` taken from a set of `ngood` good items and `nbad` bad items.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.hypergeom : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.hypergeometric: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Hypergeometric distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x) = \\frac{\\binom{g}{x}\\binom{b}{n-x}}{\\binom{g+b}{n}},\n",
      "     |      \n",
      "     |      where :math:`0 \\le x \\le n` and :math:`n-b \\le x \\le g`\n",
      "     |      \n",
      "     |      for P(x) the probability of ``x`` good results in the drawn sample,\n",
      "     |      g = `ngood`, b = `nbad`, and n = `nsample`.\n",
      "     |      \n",
      "     |      Consider an urn with black and white marbles in it, `ngood` of them\n",
      "     |      are black and `nbad` are white. If you draw `nsample` balls without\n",
      "     |      replacement, then the hypergeometric distribution describes the\n",
      "     |      distribution of black balls in the drawn sample.\n",
      "     |      \n",
      "     |      Note that this distribution is very similar to the binomial\n",
      "     |      distribution, except that in this case, samples are drawn without\n",
      "     |      replacement, whereas in the Binomial case samples are drawn with\n",
      "     |      replacement (or the sample space is infinite). As the sample space\n",
      "     |      becomes large, this distribution approaches the binomial.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "     |             and Quigley, 1972.\n",
      "     |      .. [2] Weisstein, Eric W. \"Hypergeometric Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/HypergeometricDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Hypergeometric distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Hypergeometric_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> ngood, nbad, nsamp = 100, 2, 10\n",
      "     |      # number of good, number of bad, and number of samples\n",
      "     |      >>> s = np.random.hypergeometric(ngood, nbad, nsamp, 1000)\n",
      "     |      >>> from matplotlib.pyplot import hist\n",
      "     |      >>> hist(s)\n",
      "     |      #   note that it is very unlikely to grab both bad items\n",
      "     |      \n",
      "     |      Suppose you have an urn with 15 white and 15 black marbles.\n",
      "     |      If you pull 15 marbles at random, how likely is it that\n",
      "     |      12 or more of them are one color?\n",
      "     |      \n",
      "     |      >>> s = np.random.hypergeometric(15, 15, 15, 100000)\n",
      "     |      >>> sum(s>=12)/100000. + sum(s<=3)/100000.\n",
      "     |      #   answer = 0.003 ... pretty unlikely!\n",
      "     |  \n",
      "     |  laplace(...)\n",
      "     |      laplace(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the Laplace or double exponential distribution with\n",
      "     |      specified location (or mean) and scale (decay).\n",
      "     |      \n",
      "     |      The Laplace distribution is similar to the Gaussian/normal distribution,\n",
      "     |      but is sharper at the peak and has fatter tails. It represents the\n",
      "     |      difference between two independent, identically distributed exponential\n",
      "     |      random variables.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``laplace`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          The position, :math:`\\mu`, of the distribution peak. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          :math:`\\lambda`, the exponential decay. Default is 1. Must be non-\n",
      "     |          negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Laplace distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.laplace: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      It has the probability density function\n",
      "     |      \n",
      "     |      .. math:: f(x; \\mu, \\lambda) = \\frac{1}{2\\lambda}\n",
      "     |                                     \\exp\\left(-\\frac{|x - \\mu|}{\\lambda}\\right).\n",
      "     |      \n",
      "     |      The first law of Laplace, from 1774, states that the frequency\n",
      "     |      of an error can be expressed as an exponential function of the\n",
      "     |      absolute magnitude of the error, which leads to the Laplace\n",
      "     |      distribution. For many problems in economics and health\n",
      "     |      sciences, this distribution seems to model the data better\n",
      "     |      than the standard Gaussian distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "     |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "     |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      "     |      .. [2] Kotz, Samuel, et. al. \"The Laplace Distribution and\n",
      "     |             Generalizations, \" Birkhauser, 2001.\n",
      "     |      .. [3] Weisstein, Eric W. \"Laplace Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/LaplaceDistribution.html\n",
      "     |      .. [4] Wikipedia, \"Laplace distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Laplace_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution\n",
      "     |      \n",
      "     |      >>> loc, scale = 0., 1.\n",
      "     |      >>> s = np.random.laplace(loc, scale, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> x = np.arange(-8., 8., .01)\n",
      "     |      >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
      "     |      >>> plt.plot(x, pdf)\n",
      "     |      \n",
      "     |      Plot Gaussian for comparison:\n",
      "     |      \n",
      "     |      >>> g = (1/(scale * np.sqrt(2 * np.pi)) *\n",
      "     |      ...      np.exp(-(x - loc)**2 / (2 * scale**2)))\n",
      "     |      >>> plt.plot(x,g)\n",
      "     |  \n",
      "     |  logistic(...)\n",
      "     |      logistic(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a logistic distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a logistic distribution with specified\n",
      "     |      parameters, loc (location or mean, also median), and scale (>0).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``logistic`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats, optional\n",
      "     |          Parameter of the distribution. Default is 0.\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          Parameter of the distribution. Must be non-negative.\n",
      "     |          Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized logistic distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.logistic : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.logistic: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Logistic distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x) = P(x) = \\frac{e^{-(x-\\mu)/s}}{s(1+e^{-(x-\\mu)/s})^2},\n",
      "     |      \n",
      "     |      where :math:`\\mu` = location and :math:`s` = scale.\n",
      "     |      \n",
      "     |      The Logistic distribution is used in Extreme Value problems where it\n",
      "     |      can act as a mixture of Gumbel distributions, in Epidemiology, and by\n",
      "     |      the World Chess Federation (FIDE) where it is used in the Elo ranking\n",
      "     |      system, assuming the performance of each player is a logistically\n",
      "     |      distributed random variable.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Reiss, R.-D. and Thomas M. (2001), \"Statistical Analysis of\n",
      "     |             Extreme Values, from Insurance, Finance, Hydrology and Other\n",
      "     |             Fields,\" Birkhauser Verlag, Basel, pp 132-133.\n",
      "     |      .. [2] Weisstein, Eric W. \"Logistic Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/LogisticDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Logistic-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Logistic_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> loc, scale = 10, 1\n",
      "     |      >>> s = np.random.logistic(loc, scale, 10000)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, bins=50)\n",
      "     |      \n",
      "     |      #   plot against distribution\n",
      "     |      \n",
      "     |      >>> def logist(x, loc, scale):\n",
      "     |      ...     return np.exp((loc-x)/scale)/(scale*(1+np.exp((loc-x)/scale))**2)\n",
      "     |      >>> lgst_val = logist(bins, loc, scale)\n",
      "     |      >>> plt.plot(bins, lgst_val * count.max() / lgst_val.max())\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  lognormal(...)\n",
      "     |      lognormal(mean=0.0, sigma=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a log-normal distribution.\n",
      "     |      \n",
      "     |      Draw samples from a log-normal distribution with specified mean,\n",
      "     |      standard deviation, and array shape.  Note that the mean and standard\n",
      "     |      deviation are not the values for the distribution itself, but of the\n",
      "     |      underlying normal distribution it is derived from.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``lognormal`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : float or array_like of floats, optional\n",
      "     |          Mean value of the underlying normal distribution. Default is 0.\n",
      "     |      sigma : float or array_like of floats, optional\n",
      "     |          Standard deviation of the underlying normal distribution. Must be\n",
      "     |          non-negative. Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mean`` and ``sigma`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mean, sigma).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized log-normal distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.lognorm : probability density function, distribution,\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.lognormal: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      A variable `x` has a log-normal distribution if `log(x)` is normally\n",
      "     |      distributed.  The probability density function for the log-normal\n",
      "     |      distribution is:\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{\\sigma x \\sqrt{2\\pi}}\n",
      "     |                       e^{(-\\frac{(ln(x)-\\mu)^2}{2\\sigma^2})}\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mean and :math:`\\sigma` is the standard\n",
      "     |      deviation of the normally distributed logarithm of the variable.\n",
      "     |      A log-normal distribution results if a random variable is the *product*\n",
      "     |      of a large number of independent, identically-distributed variables in\n",
      "     |      the same way that a normal distribution results if the variable is the\n",
      "     |      *sum* of a large number of independent, identically-distributed\n",
      "     |      variables.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Limpert, E., Stahel, W. A., and Abbt, M., \"Log-normal\n",
      "     |             Distributions across the Sciences: Keys and Clues,\"\n",
      "     |             BioScience, Vol. 51, No. 5, May, 2001.\n",
      "     |             https://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n",
      "     |      .. [2] Reiss, R.D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "     |             Values,\" Basel: Birkhauser Verlag, 2001, pp. 31-32.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, sigma = 3., 1. # mean and standard deviation\n",
      "     |      >>> s = np.random.lognormal(mu, sigma, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 100, density=True, align='mid')\n",
      "     |      \n",
      "     |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "     |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "     |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "     |      \n",
      "     |      >>> plt.plot(x, pdf, linewidth=2, color='r')\n",
      "     |      >>> plt.axis('tight')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Demonstrate that taking the products of random samples from a uniform\n",
      "     |      distribution can be fit well by a log-normal probability density\n",
      "     |      function.\n",
      "     |      \n",
      "     |      >>> # Generate a thousand samples: each is the product of 100 random\n",
      "     |      >>> # values, drawn from a normal distribution.\n",
      "     |      >>> b = []\n",
      "     |      >>> for i in range(1000):\n",
      "     |      ...    a = 10. + np.random.standard_normal(100)\n",
      "     |      ...    b.append(np.product(a))\n",
      "     |      \n",
      "     |      >>> b = np.array(b) / np.min(b) # scale values to be positive\n",
      "     |      >>> count, bins, ignored = plt.hist(b, 100, density=True, align='mid')\n",
      "     |      >>> sigma = np.std(np.log(b))\n",
      "     |      >>> mu = np.mean(np.log(b))\n",
      "     |      \n",
      "     |      >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "     |      >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "     |      ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "     |      \n",
      "     |      >>> plt.plot(x, pdf, color='r', linewidth=2)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  logseries(...)\n",
      "     |      logseries(p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a logarithmic series distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a log series distribution with specified\n",
      "     |      shape parameter, 0 < ``p`` < 1.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``logseries`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      p : float or array_like of floats\n",
      "     |          Shape parameter for the distribution.  Must be in the range (0, 1).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized logarithmic series distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.logser : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.logseries: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Log Series distribution is\n",
      "     |      \n",
      "     |      .. math:: P(k) = \\frac{-p^k}{k \\ln(1-p)},\n",
      "     |      \n",
      "     |      where p = probability.\n",
      "     |      \n",
      "     |      The log series distribution is frequently used to represent species\n",
      "     |      richness and occurrence, first proposed by Fisher, Corbet, and\n",
      "     |      Williams in 1943 [2].  It may also be used to model the numbers of\n",
      "     |      occupants seen in cars [3].\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Buzas, Martin A.; Culver, Stephen J.,  Understanding regional\n",
      "     |             species diversity through the log series distribution of\n",
      "     |             occurrences: BIODIVERSITY RESEARCH Diversity & Distributions,\n",
      "     |             Volume 5, Number 5, September 1999 , pp. 187-195(9).\n",
      "     |      .. [2] Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The\n",
      "     |             relation between the number of species and the number of\n",
      "     |             individuals in a random sample of an animal population.\n",
      "     |             Journal of Animal Ecology, 12:42-58.\n",
      "     |      .. [3] D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small\n",
      "     |             Data Sets, CRC Press, 1994.\n",
      "     |      .. [4] Wikipedia, \"Logarithmic distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Logarithmic_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = .6\n",
      "     |      >>> s = np.random.logseries(a, 10000)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s)\n",
      "     |      \n",
      "     |      #   plot against distribution\n",
      "     |      \n",
      "     |      >>> def logseries(k, p):\n",
      "     |      ...     return -p**k/(k*np.log(1-p))\n",
      "     |      >>> plt.plot(bins, logseries(bins, a)*count.max()/\n",
      "     |      ...          logseries(bins, a).max(), 'r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  multinomial(...)\n",
      "     |      multinomial(n, pvals, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a multinomial distribution.\n",
      "     |      \n",
      "     |      The multinomial distribution is a multivariate generalization of the\n",
      "     |      binomial distribution.  Take an experiment with one of ``p``\n",
      "     |      possible outcomes.  An example of such an experiment is throwing a dice,\n",
      "     |      where the outcome can be 1 through 6.  Each sample drawn from the\n",
      "     |      distribution represents `n` such experiments.  Its values,\n",
      "     |      ``X_i = [X_0, X_1, ..., X_p]``, represent the number of times the\n",
      "     |      outcome was ``i``.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``multinomial`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : int\n",
      "     |          Number of experiments.\n",
      "     |      pvals : sequence of floats, length p\n",
      "     |          Probabilities of each of the ``p`` different outcomes.  These\n",
      "     |          must sum to 1 (however, the last element is always assumed to\n",
      "     |          account for the remaining probability, as long as\n",
      "     |          ``sum(pvals[:-1]) <= 1)``.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "     |          the shape is ``(N,)``.\n",
      "     |      \n",
      "     |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "     |          value drawn from the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.multinomial: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Throw a dice 20 times:\n",
      "     |      \n",
      "     |      >>> np.random.multinomial(20, [1/6.]*6, size=1)\n",
      "     |      array([[4, 1, 7, 5, 2, 1]]) # random\n",
      "     |      \n",
      "     |      It landed 4 times on 1, once on 2, etc.\n",
      "     |      \n",
      "     |      Now, throw the dice 20 times, and 20 times again:\n",
      "     |      \n",
      "     |      >>> np.random.multinomial(20, [1/6.]*6, size=2)\n",
      "     |      array([[3, 4, 3, 3, 4, 3], # random\n",
      "     |             [2, 4, 3, 4, 0, 7]])\n",
      "     |      \n",
      "     |      For the first run, we threw 3 times 1, 4 times 2, etc.  For the second,\n",
      "     |      we threw 2 times 1, 4 times 2, etc.\n",
      "     |      \n",
      "     |      A loaded die is more likely to land on number 6:\n",
      "     |      \n",
      "     |      >>> np.random.multinomial(100, [1/7.]*5 + [2/7.])\n",
      "     |      array([11, 16, 14, 17, 16, 26]) # random\n",
      "     |      \n",
      "     |      The probability inputs should be normalized. As an implementation\n",
      "     |      detail, the value of the last entry is ignored and assumed to take\n",
      "     |      up any leftover probability mass, but this should not be relied on.\n",
      "     |      A biased coin which has twice as much weight on one side as on the\n",
      "     |      other should be sampled like so:\n",
      "     |      \n",
      "     |      >>> np.random.multinomial(100, [1.0 / 3, 2.0 / 3])  # RIGHT\n",
      "     |      array([38, 62]) # random\n",
      "     |      \n",
      "     |      not like:\n",
      "     |      \n",
      "     |      >>> np.random.multinomial(100, [1.0, 2.0])  # WRONG\n",
      "     |      Traceback (most recent call last):\n",
      "     |      ValueError: pvals < 0, pvals > 1 or pvals contains NaNs\n",
      "     |  \n",
      "     |  multivariate_normal(...)\n",
      "     |      multivariate_normal(mean, cov, size=None, check_valid='warn', tol=1e-8)\n",
      "     |      \n",
      "     |      Draw random samples from a multivariate normal distribution.\n",
      "     |      \n",
      "     |      The multivariate normal, multinormal or Gaussian distribution is a\n",
      "     |      generalization of the one-dimensional normal distribution to higher\n",
      "     |      dimensions.  Such a distribution is specified by its mean and\n",
      "     |      covariance matrix.  These parameters are analogous to the mean\n",
      "     |      (average or \"center\") and variance (standard deviation, or \"width,\"\n",
      "     |      squared) of the one-dimensional normal distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``multivariate_normal`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : 1-D array_like, of length N\n",
      "     |          Mean of the N-dimensional distribution.\n",
      "     |      cov : 2-D array_like, of shape (N, N)\n",
      "     |          Covariance matrix of the distribution. It must be symmetric and\n",
      "     |          positive-semidefinite for proper sampling.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Given a shape of, for example, ``(m,n,k)``, ``m*n*k`` samples are\n",
      "     |          generated, and packed in an `m`-by-`n`-by-`k` arrangement.  Because\n",
      "     |          each sample is `N`-dimensional, the output shape is ``(m,n,k,N)``.\n",
      "     |          If no shape is specified, a single (`N`-D) sample is returned.\n",
      "     |      check_valid : { 'warn', 'raise', 'ignore' }, optional\n",
      "     |          Behavior when the covariance matrix is not positive semidefinite.\n",
      "     |      tol : float, optional\n",
      "     |          Tolerance when checking the singular values in covariance matrix.\n",
      "     |          cov is cast to double before the check.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "     |          the shape is ``(N,)``.\n",
      "     |      \n",
      "     |          In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "     |          value drawn from the distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.multivariate_normal: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The mean is a coordinate in N-dimensional space, which represents the\n",
      "     |      location where samples are most likely to be generated.  This is\n",
      "     |      analogous to the peak of the bell curve for the one-dimensional or\n",
      "     |      univariate normal distribution.\n",
      "     |      \n",
      "     |      Covariance indicates the level to which two variables vary together.\n",
      "     |      From the multivariate normal distribution, we draw N-dimensional\n",
      "     |      samples, :math:`X = [x_1, x_2, ... x_N]`.  The covariance matrix\n",
      "     |      element :math:`C_{ij}` is the covariance of :math:`x_i` and :math:`x_j`.\n",
      "     |      The element :math:`C_{ii}` is the variance of :math:`x_i` (i.e. its\n",
      "     |      \"spread\").\n",
      "     |      \n",
      "     |      Instead of specifying the full covariance matrix, popular\n",
      "     |      approximations include:\n",
      "     |      \n",
      "     |        - Spherical covariance (`cov` is a multiple of the identity matrix)\n",
      "     |        - Diagonal covariance (`cov` has non-negative elements, and only on\n",
      "     |          the diagonal)\n",
      "     |      \n",
      "     |      This geometrical property can be seen in two dimensions by plotting\n",
      "     |      generated data-points:\n",
      "     |      \n",
      "     |      >>> mean = [0, 0]\n",
      "     |      >>> cov = [[1, 0], [0, 100]]  # diagonal covariance\n",
      "     |      \n",
      "     |      Diagonal covariance means that points are oriented along x or y-axis:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
      "     |      >>> plt.plot(x, y, 'x')\n",
      "     |      >>> plt.axis('equal')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Note that the covariance matrix must be positive semidefinite (a.k.a.\n",
      "     |      nonnegative-definite). Otherwise, the behavior of this method is\n",
      "     |      undefined and backwards compatibility is not guaranteed.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Papoulis, A., \"Probability, Random Variables, and Stochastic\n",
      "     |             Processes,\" 3rd ed., New York: McGraw-Hill, 1991.\n",
      "     |      .. [2] Duda, R. O., Hart, P. E., and Stork, D. G., \"Pattern\n",
      "     |             Classification,\" 2nd ed., New York: Wiley, 2001.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> mean = (1, 2)\n",
      "     |      >>> cov = [[1, 0], [0, 1]]\n",
      "     |      >>> x = np.random.multivariate_normal(mean, cov, (3, 3))\n",
      "     |      >>> x.shape\n",
      "     |      (3, 3, 2)\n",
      "     |      \n",
      "     |      The following is probably true, given that 0.6 is roughly twice the\n",
      "     |      standard deviation:\n",
      "     |      \n",
      "     |      >>> list((x[0,0,:] - mean) < 0.6)\n",
      "     |      [True, True] # random\n",
      "     |  \n",
      "     |  negative_binomial(...)\n",
      "     |      negative_binomial(n, p, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a negative binomial distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a negative binomial distribution with specified\n",
      "     |      parameters, `n` successes and `p` probability of success where `n`\n",
      "     |      is > 0 and `p` is in the interval [0, 1].\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``negative_binomial`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n : float or array_like of floats\n",
      "     |          Parameter of the distribution, > 0.\n",
      "     |      p : float or array_like of floats\n",
      "     |          Parameter of the distribution, >= 0 and <=1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized negative binomial distribution,\n",
      "     |          where each sample is equal to N, the number of failures that\n",
      "     |          occurred before a total of n successes was reached.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.negative_binomial: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability mass function of the negative binomial distribution is\n",
      "     |      \n",
      "     |      .. math:: P(N;n,p) = \\frac{\\Gamma(N+n)}{N!\\Gamma(n)}p^{n}(1-p)^{N},\n",
      "     |      \n",
      "     |      where :math:`n` is the number of successes, :math:`p` is the\n",
      "     |      probability of success, :math:`N+n` is the number of trials, and\n",
      "     |      :math:`\\Gamma` is the gamma function. When :math:`n` is an integer,\n",
      "     |      :math:`\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} = \\binom{N+n-1}{N}`, which is\n",
      "     |      the more common form of this term in the the pmf. The negative\n",
      "     |      binomial distribution gives the probability of N failures given n\n",
      "     |      successes, with a success on the last trial.\n",
      "     |      \n",
      "     |      If one throws a die repeatedly until the third time a \"1\" appears,\n",
      "     |      then the probability distribution of the number of non-\"1\"s that\n",
      "     |      appear before the third \"1\" is a negative binomial distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Negative Binomial Distribution.\" From\n",
      "     |             MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Negative binomial distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      A real world example. A company drills wild-cat oil\n",
      "     |      exploration wells, each with an estimated probability of\n",
      "     |      success of 0.1.  What is the probability of having one success\n",
      "     |      for each successive well, that is what is the probability of a\n",
      "     |      single success after drilling 5 wells, after 6 wells, etc.?\n",
      "     |      \n",
      "     |      >>> s = np.random.negative_binomial(1, 0.1, 100000)\n",
      "     |      >>> for i in range(1, 11): # doctest: +SKIP\n",
      "     |      ...    probability = sum(s<i) / 100000.\n",
      "     |      ...    print(i, \"wells drilled, probability of one success =\", probability)\n",
      "     |  \n",
      "     |  noncentral_chisquare(...)\n",
      "     |      noncentral_chisquare(df, nonc, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a noncentral chi-square distribution.\n",
      "     |      \n",
      "     |      The noncentral :math:`\\chi^2` distribution is a generalization of\n",
      "     |      the :math:`\\chi^2` distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``noncentral_chisquare`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |          Degrees of freedom, must be > 0.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.10.0\n",
      "     |             Earlier NumPy versions required dfnum > 1.\n",
      "     |      nonc : float or array_like of floats\n",
      "     |          Non-centrality, must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` and ``nonc`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(df, nonc).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized noncentral chi-square distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.noncentral_chisquare: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the noncentral Chi-square\n",
      "     |      distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;df,nonc) = \\sum^{\\infty}_{i=0}\n",
      "     |                             \\frac{e^{-nonc/2}(nonc/2)^{i}}{i!}\n",
      "     |                             P_{Y_{df+2i}}(x),\n",
      "     |      \n",
      "     |      where :math:`Y_{q}` is the Chi-square with q degrees of freedom.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Noncentral chi-squared distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      "     |      ...                   bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Draw values from a noncentral chisquare with very small noncentrality,\n",
      "     |      and compare to a chisquare.\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> values = plt.hist(np.random.noncentral_chisquare(3, .0000001, 100000),\n",
      "     |      ...                   bins=np.arange(0., 25, .1), density=True)\n",
      "     |      >>> values2 = plt.hist(np.random.chisquare(3, 100000),\n",
      "     |      ...                    bins=np.arange(0., 25, .1), density=True)\n",
      "     |      >>> plt.plot(values[1][0:-1], values[0]-values2[0], 'ob')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Demonstrate how large values of non-centrality lead to a more symmetric\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      "     |      ...                   bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  noncentral_f(...)\n",
      "     |      noncentral_f(dfnum, dfden, nonc, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the noncentral F distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from an F distribution with specified parameters,\n",
      "     |      `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "     |      freedom in denominator), where both parameters > 1.\n",
      "     |      `nonc` is the non-centrality parameter.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``noncentral_f`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      dfnum : float or array_like of floats\n",
      "     |          Numerator degrees of freedom, must be > 0.\n",
      "     |      \n",
      "     |          .. versionchanged:: 1.14.0\n",
      "     |             Earlier NumPy versions required dfnum > 1.\n",
      "     |      dfden : float or array_like of floats\n",
      "     |          Denominator degrees of freedom, must be > 0.\n",
      "     |      nonc : float or array_like of floats\n",
      "     |          Non-centrality parameter, the sum of the squares of the numerator\n",
      "     |          means, must be >= 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``dfnum``, ``dfden``, and ``nonc``\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(dfnum, dfden, nonc).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized noncentral Fisher distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.noncentral_f: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      When calculating the power of an experiment (power = probability of\n",
      "     |      rejecting the null hypothesis when a specific alternative is true) the\n",
      "     |      non-central F statistic becomes important.  When the null hypothesis is\n",
      "     |      true, the F statistic follows a central F distribution. When the null\n",
      "     |      hypothesis is not true, then it follows a non-central F statistic.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Noncentral F-Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/NoncentralF-Distribution.html\n",
      "     |      .. [2] Wikipedia, \"Noncentral F-distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Noncentral_F-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      In a study, testing for a specific alternative to the null hypothesis\n",
      "     |      requires use of the Noncentral F distribution. We need to calculate the\n",
      "     |      area in the tail of the distribution that exceeds the value of the F\n",
      "     |      distribution for the null hypothesis.  We'll plot the two probability\n",
      "     |      distributions for comparison.\n",
      "     |      \n",
      "     |      >>> dfnum = 3 # between group deg of freedom\n",
      "     |      >>> dfden = 20 # within groups degrees of freedom\n",
      "     |      >>> nonc = 3.0\n",
      "     |      >>> nc_vals = np.random.noncentral_f(dfnum, dfden, nonc, 1000000)\n",
      "     |      >>> NF = np.histogram(nc_vals, bins=50, density=True)\n",
      "     |      >>> c_vals = np.random.f(dfnum, dfden, 1000000)\n",
      "     |      >>> F = np.histogram(c_vals, bins=50, density=True)\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> plt.plot(F[1][1:], F[0])\n",
      "     |      >>> plt.plot(NF[1][1:], NF[0])\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  normal(...)\n",
      "     |      normal(loc=0.0, scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw random samples from a normal (Gaussian) distribution.\n",
      "     |      \n",
      "     |      The probability density function of the normal distribution, first\n",
      "     |      derived by De Moivre and 200 years later by both Gauss and Laplace\n",
      "     |      independently [2]_, is often called the bell curve because of\n",
      "     |      its characteristic shape (see the example below).\n",
      "     |      \n",
      "     |      The normal distributions occurs often in nature.  For example, it\n",
      "     |      describes the commonly occurring distribution of samples influenced\n",
      "     |      by a large number of tiny, random disturbances, each with its own\n",
      "     |      unique distribution [2]_.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``normal`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      loc : float or array_like of floats\n",
      "     |          Mean (\"centre\") of the distribution.\n",
      "     |      scale : float or array_like of floats\n",
      "     |          Standard deviation (spread or \"width\") of the distribution. Must be\n",
      "     |          non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized normal distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.norm : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.normal: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gaussian distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
      "     |                       e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
      "     |      deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
      "     |      is called the variance.\n",
      "     |      \n",
      "     |      The function has its peak at the mean, and its \"spread\" increases with\n",
      "     |      the standard deviation (the function reaches 0.607 times its maximum at\n",
      "     |      :math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
      "     |      normal is more likely to return samples lying close to the mean, rather\n",
      "     |      than those far away.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Normal distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Normal_distribution\n",
      "     |      .. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
      "     |             Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
      "     |             pp. 51, 51, 125.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
      "     |      >>> s = np.random.normal(mu, sigma, 1000)\n",
      "     |      \n",
      "     |      Verify the mean and the variance:\n",
      "     |      \n",
      "     |      >>> abs(mu - np.mean(s))\n",
      "     |      0.0  # may vary\n",
      "     |      \n",
      "     |      >>> abs(sigma - np.std(s, ddof=1))\n",
      "     |      0.1  # may vary\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "     |      >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
      "     |      ...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
      "     |      ...          linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Two-by-four array of samples from N(3, 6.25):\n",
      "     |      \n",
      "     |      >>> np.random.normal(3, 2.5, size=(2, 4))\n",
      "     |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "     |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "     |  \n",
      "     |  pareto(...)\n",
      "     |      pareto(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Pareto II or Lomax distribution with\n",
      "     |      specified shape.\n",
      "     |      \n",
      "     |      The Lomax or Pareto II distribution is a shifted Pareto\n",
      "     |      distribution. The classical Pareto distribution can be\n",
      "     |      obtained from the Lomax distribution by adding 1 and\n",
      "     |      multiplying by the scale parameter ``m`` (see Notes).  The\n",
      "     |      smallest value of the Lomax distribution is zero while for the\n",
      "     |      classical Pareto distribution it is ``mu``, where the standard\n",
      "     |      Pareto distribution has location ``mu = 1``.  Lomax can also\n",
      "     |      be considered as a simplified version of the Generalized\n",
      "     |      Pareto distribution (available in SciPy), with the scale set\n",
      "     |      to one and the location set to zero.\n",
      "     |      \n",
      "     |      The Pareto distribution must be greater than zero, and is\n",
      "     |      unbounded above.  It is also known as the \"80-20 rule\".  In\n",
      "     |      this distribution, 80 percent of the weights are in the lowest\n",
      "     |      20 percent of the range, while the other 20 percent fill the\n",
      "     |      remaining 80 percent of the range.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``pareto`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Shape of the distribution. Must be positive.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Pareto distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.lomax : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      scipy.stats.genpareto : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.pareto: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Pareto distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{am^a}{x^{a+1}}\n",
      "     |      \n",
      "     |      where :math:`a` is the shape and :math:`m` the scale.\n",
      "     |      \n",
      "     |      The Pareto distribution, named after the Italian economist\n",
      "     |      Vilfredo Pareto, is a power law probability distribution\n",
      "     |      useful in many real world problems.  Outside the field of\n",
      "     |      economics it is generally referred to as the Bradford\n",
      "     |      distribution. Pareto developed the distribution to describe\n",
      "     |      the distribution of wealth in an economy.  It has also found\n",
      "     |      use in insurance, web page access statistics, oil field sizes,\n",
      "     |      and many other problems, including the download frequency for\n",
      "     |      projects in Sourceforge [1]_.  It is one of the so-called\n",
      "     |      \"fat-tailed\" distributions.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of\n",
      "     |             Sourceforge projects.\n",
      "     |      .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.\n",
      "     |      .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme\n",
      "     |             Values, Birkhauser Verlag, Basel, pp 23-30.\n",
      "     |      .. [4] Wikipedia, \"Pareto distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Pareto_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a, m = 3., 2.  # shape and mode\n",
      "     |      >>> s = (np.random.pareto(a, 1000) + 1) * m\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with the probability\n",
      "     |      density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, _ = plt.hist(s, 100, density=True)\n",
      "     |      >>> fit = a*m**a / bins**(a+1)\n",
      "     |      >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  permutation(...)\n",
      "     |      permutation(x)\n",
      "     |      \n",
      "     |      Randomly permute a sequence, or return a permuted range.\n",
      "     |      \n",
      "     |      If `x` is a multi-dimensional array, it is only shuffled along its\n",
      "     |      first index.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``permutation`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : int or array_like\n",
      "     |          If `x` is an integer, randomly permute ``np.arange(x)``.\n",
      "     |          If `x` is an array, make a copy and shuffle the elements\n",
      "     |          randomly.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          Permuted sequence or array range.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.permutation: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.permutation(10)\n",
      "     |      array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random\n",
      "     |      \n",
      "     |      >>> np.random.permutation([1, 4, 9, 12, 15])\n",
      "     |      array([15,  1,  9,  4, 12]) # random\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> np.random.permutation(arr)\n",
      "     |      array([[6, 7, 8], # random\n",
      "     |             [0, 1, 2],\n",
      "     |             [3, 4, 5]])\n",
      "     |  \n",
      "     |  poisson(...)\n",
      "     |      poisson(lam=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Poisson distribution.\n",
      "     |      \n",
      "     |      The Poisson distribution is the limit of the binomial distribution\n",
      "     |      for large N.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``poisson`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      lam : float or array_like of floats\n",
      "     |          Expectation of interval, must be >= 0. A sequence of expectation\n",
      "     |          intervals must be broadcastable over the requested size.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``lam`` is a scalar. Otherwise,\n",
      "     |          ``np.array(lam).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Poisson distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.poisson: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Poisson distribution\n",
      "     |      \n",
      "     |      .. math:: f(k; \\lambda)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
      "     |      \n",
      "     |      For events with an expected separation :math:`\\lambda` the Poisson\n",
      "     |      distribution :math:`f(k; \\lambda)` describes the probability of\n",
      "     |      :math:`k` events occurring within the observed\n",
      "     |      interval :math:`\\lambda`.\n",
      "     |      \n",
      "     |      Because the output is limited to the range of the C int64 type, a\n",
      "     |      ValueError is raised when `lam` is within 10 sigma of the maximum\n",
      "     |      representable value.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Poisson Distribution.\"\n",
      "     |             From MathWorld--A Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/PoissonDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Poisson distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Poisson_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> import numpy as np\n",
      "     |      >>> s = np.random.poisson(5, 10000)\n",
      "     |      \n",
      "     |      Display histogram of the sample:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 14, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Draw each 100 values for lambda 100 and 500:\n",
      "     |      \n",
      "     |      >>> s = np.random.poisson(lam=(100., 500.), size=(100, 2))\n",
      "     |  \n",
      "     |  power(...)\n",
      "     |      power(a, size=None)\n",
      "     |      \n",
      "     |      Draws samples in [0, 1] from a power distribution with positive\n",
      "     |      exponent a - 1.\n",
      "     |      \n",
      "     |      Also known as the power function distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``power`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Parameter of the distribution. Must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized power distribution.\n",
      "     |      \n",
      "     |      Raises\n",
      "     |      ------\n",
      "     |      ValueError\n",
      "     |          If a < 1.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.power: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function is\n",
      "     |      \n",
      "     |      .. math:: P(x; a) = ax^{a-1}, 0 \\le x \\le 1, a>0.\n",
      "     |      \n",
      "     |      The power function distribution is just the inverse of the Pareto\n",
      "     |      distribution. It may also be seen as a special case of the Beta\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      It is used, for example, in modeling the over-reporting of insurance\n",
      "     |      claims.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Christian Kleiber, Samuel Kotz, \"Statistical size distributions\n",
      "     |             in economics and actuarial sciences\", Wiley, 2003.\n",
      "     |      .. [2] Heckert, N. A. and Filliben, James J. \"NIST Handbook 148:\n",
      "     |             Dataplot Reference Manual, Volume 2: Let Subcommands and Library\n",
      "     |             Functions\", National Institute of Standards and Technology\n",
      "     |             Handbook Series, June 2003.\n",
      "     |             https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = 5. # shape\n",
      "     |      >>> samples = 1000\n",
      "     |      >>> s = np.random.power(a, samples)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, bins=30)\n",
      "     |      >>> x = np.linspace(0, 1, 100)\n",
      "     |      >>> y = a*x**(a-1.)\n",
      "     |      >>> normed_y = samples*np.diff(bins)[0]*y\n",
      "     |      >>> plt.plot(x, normed_y)\n",
      "     |      >>> plt.show()\n",
      "     |      \n",
      "     |      Compare the power function distribution to the inverse of the Pareto.\n",
      "     |      \n",
      "     |      >>> from scipy import stats # doctest: +SKIP\n",
      "     |      >>> rvs = np.random.power(5, 1000000)\n",
      "     |      >>> rvsp = np.random.pareto(5, 1000000)\n",
      "     |      >>> xx = np.linspace(0,1,100)\n",
      "     |      >>> powpdf = stats.powerlaw.pdf(xx,5)  # doctest: +SKIP\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(rvs, bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('np.random.power(5)')\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('inverse of 1 + np.random.pareto(5)')\n",
      "     |      \n",
      "     |      >>> plt.figure()\n",
      "     |      >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "     |      >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "     |      >>> plt.title('inverse of stats.pareto(5)')\n",
      "     |  \n",
      "     |  rand(...)\n",
      "     |      rand(d0, d1, ..., dn)\n",
      "     |      \n",
      "     |      Random values in a given shape.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This is a convenience function for users porting code from Matlab,\n",
      "     |          and wraps `random_sample`. That function takes a\n",
      "     |          tuple to specify the size of the output, which is consistent with\n",
      "     |          other NumPy functions like `numpy.zeros` and `numpy.ones`.\n",
      "     |      \n",
      "     |      Create an array of the given shape and populate it with\n",
      "     |      random samples from a uniform distribution\n",
      "     |      over ``[0, 1)``.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      d0, d1, ..., dn : int, optional\n",
      "     |          The dimensions of the returned array, must be non-negative.\n",
      "     |          If no argument is given a single Python float is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray, shape ``(d0, d1, ..., dn)``\n",
      "     |          Random values.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      random\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.rand(3,2)\n",
      "     |      array([[ 0.14022471,  0.96360618],  #random\n",
      "     |             [ 0.37601032,  0.25528411],  #random\n",
      "     |             [ 0.49313049,  0.94909878]]) #random\n",
      "     |  \n",
      "     |  randint(...)\n",
      "     |      randint(low, high=None, size=None, dtype=int)\n",
      "     |      \n",
      "     |      Return random integers from `low` (inclusive) to `high` (exclusive).\n",
      "     |      \n",
      "     |      Return random integers from the \"discrete uniform\" distribution of\n",
      "     |      the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
      "     |      `high` is None (the default), then results are from [0, `low`).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``integers`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : int or array-like of ints\n",
      "     |          Lowest (signed) integers to be drawn from the distribution (unless\n",
      "     |          ``high=None``, in which case this parameter is one above the\n",
      "     |          *highest* such integer).\n",
      "     |      high : int or array-like of ints, optional\n",
      "     |          If provided, one above the largest (signed) integer to be drawn\n",
      "     |          from the distribution (see above for behavior if ``high=None``).\n",
      "     |          If array-like, must contain integer values\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      dtype : dtype, optional\n",
      "     |          Desired dtype of the result. Byteorder must be native.\n",
      "     |          The default value is int.\n",
      "     |      \n",
      "     |          .. versionadded:: 1.11.0\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : int or ndarray of ints\n",
      "     |          `size`-shaped array of random integers from the appropriate\n",
      "     |          distribution, or a single such random int if `size` not provided.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      random_integers : similar to `randint`, only for the closed\n",
      "     |          interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
      "     |          omitted.\n",
      "     |      Generator.integers: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.randint(2, size=10)\n",
      "     |      array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random\n",
      "     |      >>> np.random.randint(1, size=10)\n",
      "     |      array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "     |      \n",
      "     |      Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      "     |      \n",
      "     |      >>> np.random.randint(5, size=(2, 4))\n",
      "     |      array([[4, 0, 2, 1], # random\n",
      "     |             [3, 2, 2, 0]])\n",
      "     |      \n",
      "     |      Generate a 1 x 3 array with 3 different upper bounds\n",
      "     |      \n",
      "     |      >>> np.random.randint(1, [3, 5, 10])\n",
      "     |      array([2, 2, 9]) # random\n",
      "     |      \n",
      "     |      Generate a 1 by 3 array with 3 different lower bounds\n",
      "     |      \n",
      "     |      >>> np.random.randint([1, 5, 7], 10)\n",
      "     |      array([9, 8, 7]) # random\n",
      "     |      \n",
      "     |      Generate a 2 by 4 array using broadcasting with dtype of uint8\n",
      "     |      \n",
      "     |      >>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\n",
      "     |      array([[ 8,  6,  9,  7], # random\n",
      "     |             [ 1, 16,  9, 12]], dtype=uint8)\n",
      "     |  \n",
      "     |  randn(...)\n",
      "     |      randn(d0, d1, ..., dn)\n",
      "     |      \n",
      "     |      Return a sample (or samples) from the \"standard normal\" distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          This is a convenience function for users porting code from Matlab,\n",
      "     |          and wraps `standard_normal`. That function takes a\n",
      "     |          tuple to specify the size of the output, which is consistent with\n",
      "     |          other NumPy functions like `numpy.zeros` and `numpy.ones`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_normal`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      If positive int_like arguments are provided, `randn` generates an array\n",
      "     |      of shape ``(d0, d1, ..., dn)``, filled\n",
      "     |      with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      "     |      distribution of mean 0 and variance 1. A single float randomly sampled\n",
      "     |      from the distribution is returned if no argument is provided.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      d0, d1, ..., dn : int, optional\n",
      "     |          The dimensions of the returned array, must be non-negative.\n",
      "     |          If no argument is given a single Python float is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      Z : ndarray or float\n",
      "     |          A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      "     |          the standard normal distribution, or a single such float if\n",
      "     |          no parameters were supplied.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      standard_normal : Similar, but takes a tuple as its argument.\n",
      "     |      normal : Also accepts mu and sigma arguments.\n",
      "     |      Generator.standard_normal: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      "     |      \n",
      "     |      ``sigma * np.random.randn(...) + mu``\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.randn()\n",
      "     |      2.1923875335537315  # random\n",
      "     |      \n",
      "     |      Two-by-four array of samples from N(3, 6.25):\n",
      "     |      \n",
      "     |      >>> 3 + 2.5 * np.random.randn(2, 4)\n",
      "     |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "     |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "     |  \n",
      "     |  random(...)\n",
      "     |      random(size=None)\n",
      "     |      \n",
      "     |      Return random floats in the half-open interval [0.0, 1.0). Alias for\n",
      "     |      `random_sample` to ease forward-porting to the new random API.\n",
      "     |  \n",
      "     |  random_integers(...)\n",
      "     |      random_integers(low, high=None, size=None)\n",
      "     |      \n",
      "     |      Random integers of type `np.int_` between `low` and `high`, inclusive.\n",
      "     |      \n",
      "     |      Return random integers of type `np.int_` from the \"discrete uniform\"\n",
      "     |      distribution in the closed interval [`low`, `high`].  If `high` is\n",
      "     |      None (the default), then results are from [1, `low`]. The `np.int_`\n",
      "     |      type translates to the C long integer type and its precision\n",
      "     |      is platform dependent.\n",
      "     |      \n",
      "     |      This function has been deprecated. Use randint instead.\n",
      "     |      \n",
      "     |      .. deprecated:: 1.11.0\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : int\n",
      "     |          Lowest (signed) integer to be drawn from the distribution (unless\n",
      "     |          ``high=None``, in which case this parameter is the *highest* such\n",
      "     |          integer).\n",
      "     |      high : int, optional\n",
      "     |          If provided, the largest (signed) integer to be drawn from the\n",
      "     |          distribution (see above for behavior if ``high=None``).\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : int or ndarray of ints\n",
      "     |          `size`-shaped array of random integers from the appropriate\n",
      "     |          distribution, or a single such random int if `size` not provided.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      randint : Similar to `random_integers`, only for the half-open\n",
      "     |          interval [`low`, `high`), and 0 is the lowest value if `high` is\n",
      "     |          omitted.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      To sample from N evenly spaced floating-point numbers between a and b,\n",
      "     |      use::\n",
      "     |      \n",
      "     |        a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.random_integers(5)\n",
      "     |      4 # random\n",
      "     |      >>> type(np.random.random_integers(5))\n",
      "     |      <class 'numpy.int64'>\n",
      "     |      >>> np.random.random_integers(5, size=(3,2))\n",
      "     |      array([[5, 4], # random\n",
      "     |             [3, 3],\n",
      "     |             [4, 5]])\n",
      "     |      \n",
      "     |      Choose five random numbers from the set of five evenly-spaced\n",
      "     |      numbers between 0 and 2.5, inclusive (*i.e.*, from the set\n",
      "     |      :math:`{0, 5/8, 10/8, 15/8, 20/8}`):\n",
      "     |      \n",
      "     |      >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.\n",
      "     |      array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ]) # random\n",
      "     |      \n",
      "     |      Roll two six sided dice 1000 times and sum the results:\n",
      "     |      \n",
      "     |      >>> d1 = np.random.random_integers(1, 6, 1000)\n",
      "     |      >>> d2 = np.random.random_integers(1, 6, 1000)\n",
      "     |      >>> dsums = d1 + d2\n",
      "     |      \n",
      "     |      Display results as a histogram:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(dsums, 11, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  random_sample(...)\n",
      "     |      random_sample(size=None)\n",
      "     |      \n",
      "     |      Return random floats in the half-open interval [0.0, 1.0).\n",
      "     |      \n",
      "     |      Results are from the \"continuous uniform\" distribution over the\n",
      "     |      stated interval.  To sample :math:`Unif[a, b), b > a` multiply\n",
      "     |      the output of `random_sample` by `(b-a)` and add `a`::\n",
      "     |      \n",
      "     |        (b - a) * random_sample() + a\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``random`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray of floats\n",
      "     |          Array of random floats of shape `size` (unless ``size=None``, in which\n",
      "     |          case a single float is returned).\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.random: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.random_sample()\n",
      "     |      0.47108547995356098 # random\n",
      "     |      >>> type(np.random.random_sample())\n",
      "     |      <class 'float'>\n",
      "     |      >>> np.random.random_sample((5,))\n",
      "     |      array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428]) # random\n",
      "     |      \n",
      "     |      Three-by-two array of random numbers from [-5, 0):\n",
      "     |      \n",
      "     |      >>> 5 * np.random.random_sample((3, 2)) - 5\n",
      "     |      array([[-3.99149989, -0.52338984], # random\n",
      "     |             [-2.99091858, -0.79479508],\n",
      "     |             [-1.23204345, -1.75224494]])\n",
      "     |  \n",
      "     |  rayleigh(...)\n",
      "     |      rayleigh(scale=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Rayleigh distribution.\n",
      "     |      \n",
      "     |      The :math:`\\chi` and Weibull distributions are generalizations of the\n",
      "     |      Rayleigh.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``rayleigh`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      scale : float or array_like of floats, optional\n",
      "     |          Scale, also equals the mode. Must be non-negative. Default is 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Rayleigh distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.rayleigh: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the Rayleigh distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;scale) = \\frac{x}{scale^2}e^{\\frac{-x^2}{2 \\cdotp scale^2}}\n",
      "     |      \n",
      "     |      The Rayleigh distribution would arise, for example, if the East\n",
      "     |      and North components of the wind velocity had identical zero-mean\n",
      "     |      Gaussian distributions.  Then the wind speed would have a Rayleigh\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Brighton Webs Ltd., \"Rayleigh Distribution,\"\n",
      "     |             https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp\n",
      "     |      .. [2] Wikipedia, \"Rayleigh distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Rayleigh_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram\n",
      "     |      \n",
      "     |      >>> from matplotlib.pyplot import hist\n",
      "     |      >>> values = hist(np.random.rayleigh(3, 100000), bins=200, density=True)\n",
      "     |      \n",
      "     |      Wave heights tend to follow a Rayleigh distribution. If the mean wave\n",
      "     |      height is 1 meter, what fraction of waves are likely to be larger than 3\n",
      "     |      meters?\n",
      "     |      \n",
      "     |      >>> meanvalue = 1\n",
      "     |      >>> modevalue = np.sqrt(2 / np.pi) * meanvalue\n",
      "     |      >>> s = np.random.rayleigh(modevalue, 1000000)\n",
      "     |      \n",
      "     |      The percentage of waves larger than 3 meters is:\n",
      "     |      \n",
      "     |      >>> 100.*sum(s>3)/1000000.\n",
      "     |      0.087300000000000003 # random\n",
      "     |  \n",
      "     |  seed(...)\n",
      "     |      seed(self, seed=None)\n",
      "     |      \n",
      "     |      Reseed a legacy MT19937 BitGenerator\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This is a convenience, legacy function.\n",
      "     |      \n",
      "     |      The best practice is to **not** reseed a BitGenerator, rather to\n",
      "     |      recreate a new one. This method is here for legacy reasons.\n",
      "     |      This example demonstrates best practice.\n",
      "     |      \n",
      "     |      >>> from numpy.random import MT19937\n",
      "     |      >>> from numpy.random import RandomState, SeedSequence\n",
      "     |      >>> rs = RandomState(MT19937(SeedSequence(123456789)))\n",
      "     |      # Later, you want to restart the stream\n",
      "     |      >>> rs = RandomState(MT19937(SeedSequence(987654321)))\n",
      "     |  \n",
      "     |  set_state(...)\n",
      "     |      set_state(state)\n",
      "     |      \n",
      "     |      Set the internal state of the generator from a tuple.\n",
      "     |      \n",
      "     |      For use if one has reason to manually (re-)set the internal state of\n",
      "     |      the bit generator used by the RandomState instance. By default,\n",
      "     |      RandomState uses the \"Mersenne Twister\"[1]_ pseudo-random number\n",
      "     |      generating algorithm.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      state : {tuple(str, ndarray of 624 uints, int, int, float), dict}\n",
      "     |          The `state` tuple has the following items:\n",
      "     |      \n",
      "     |          1. the string 'MT19937', specifying the Mersenne Twister algorithm.\n",
      "     |          2. a 1-D array of 624 unsigned integers ``keys``.\n",
      "     |          3. an integer ``pos``.\n",
      "     |          4. an integer ``has_gauss``.\n",
      "     |          5. a float ``cached_gaussian``.\n",
      "     |      \n",
      "     |          If state is a dictionary, it is directly set using the BitGenerators\n",
      "     |          `state` property.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : None\n",
      "     |          Returns 'None' on success.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      get_state\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      `set_state` and `get_state` are not needed to work with any of the\n",
      "     |      random distributions in NumPy. If the internal state is manually altered,\n",
      "     |      the user should know exactly what he/she is doing.\n",
      "     |      \n",
      "     |      For backwards compatibility, the form (str, array of 624 uints, int) is\n",
      "     |      also accepted although it is missing some information about the cached\n",
      "     |      Gaussian value: ``state = ('MT19937', keys, pos)``.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] M. Matsumoto and T. Nishimura, \"Mersenne Twister: A\n",
      "     |         623-dimensionally equidistributed uniform pseudorandom number\n",
      "     |         generator,\" *ACM Trans. on Modeling and Computer Simulation*,\n",
      "     |         Vol. 8, No. 1, pp. 3-30, Jan. 1998.\n",
      "     |  \n",
      "     |  shuffle(...)\n",
      "     |      shuffle(x)\n",
      "     |      \n",
      "     |      Modify a sequence in-place by shuffling its contents.\n",
      "     |      \n",
      "     |      This function only shuffles the array along the first axis of a\n",
      "     |      multi-dimensional array. The order of sub-arrays is changed but\n",
      "     |      their contents remains the same.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``shuffle`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      x : array_like\n",
      "     |          The array or list to be shuffled.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      None\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.shuffle: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> arr = np.arange(10)\n",
      "     |      >>> np.random.shuffle(arr)\n",
      "     |      >>> arr\n",
      "     |      [1 7 5 2 9 4 3 6 0 8] # random\n",
      "     |      \n",
      "     |      Multi-dimensional arrays are only shuffled along the first axis:\n",
      "     |      \n",
      "     |      >>> arr = np.arange(9).reshape((3, 3))\n",
      "     |      >>> np.random.shuffle(arr)\n",
      "     |      >>> arr\n",
      "     |      array([[3, 4, 5], # random\n",
      "     |             [6, 7, 8],\n",
      "     |             [0, 1, 2]])\n",
      "     |  \n",
      "     |  standard_cauchy(...)\n",
      "     |      standard_cauchy(size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Cauchy distribution with mode = 0.\n",
      "     |      \n",
      "     |      Also known as the Lorentz distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_cauchy`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      samples : ndarray or scalar\n",
      "     |          The drawn samples.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.standard_cauchy: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the full Cauchy distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\bigl[ 1+\n",
      "     |                (\\frac{x-x_0}{\\gamma})^2 \\bigr] }\n",
      "     |      \n",
      "     |      and the Standard Cauchy distribution just sets :math:`x_0=0` and\n",
      "     |      :math:`\\gamma=1`\n",
      "     |      \n",
      "     |      The Cauchy distribution arises in the solution to the driven harmonic\n",
      "     |      oscillator problem, and also describes spectral line broadening. It\n",
      "     |      also describes the distribution of values at which a line tilted at\n",
      "     |      a random angle will cut the x axis.\n",
      "     |      \n",
      "     |      When studying hypothesis tests that assume normality, seeing how the\n",
      "     |      tests perform on data from a Cauchy distribution is a good indicator of\n",
      "     |      their sensitivity to a heavy-tailed distribution, since the Cauchy looks\n",
      "     |      very much like a Gaussian distribution, but with heavier tails.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, \"Cauchy\n",
      "     |            Distribution\",\n",
      "     |            https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n",
      "     |      .. [2] Weisstein, Eric W. \"Cauchy Distribution.\" From MathWorld--A\n",
      "     |            Wolfram Web Resource.\n",
      "     |            http://mathworld.wolfram.com/CauchyDistribution.html\n",
      "     |      .. [3] Wikipedia, \"Cauchy distribution\"\n",
      "     |            https://en.wikipedia.org/wiki/Cauchy_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples and plot the distribution:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> s = np.random.standard_cauchy(1000000)\n",
      "     |      >>> s = s[(s>-25) & (s<25)]  # truncate distribution so it plots well\n",
      "     |      >>> plt.hist(s, bins=100)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  standard_exponential(...)\n",
      "     |      standard_exponential(size=None)\n",
      "     |      \n",
      "     |      Draw samples from the standard exponential distribution.\n",
      "     |      \n",
      "     |      `standard_exponential` is identical to the exponential distribution\n",
      "     |      with a scale parameter of 1.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_exponential`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.standard_exponential: which should be used for new code.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Output a 3x8000 array:\n",
      "     |      \n",
      "     |      >>> n = np.random.standard_exponential((3, 8000))\n",
      "     |  \n",
      "     |  standard_gamma(...)\n",
      "     |      standard_gamma(shape, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Gamma distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Gamma distribution with specified parameters,\n",
      "     |      shape (sometimes designated \"k\") and scale=1.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_gamma`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      shape : float or array_like of floats\n",
      "     |          Parameter, must be non-negative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``shape`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(shape).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized standard gamma distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.gamma : probability density function, distribution or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.standard_gamma: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Gamma distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "     |      \n",
      "     |      where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "     |      and :math:`\\Gamma` is the Gamma function.\n",
      "     |      \n",
      "     |      The Gamma distribution is often used to model the times to failure of\n",
      "     |      electronic components, and arises naturally in processes for which the\n",
      "     |      waiting times between Poisson distributed events are relevant.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "     |             Wolfram Web Resource.\n",
      "     |             http://mathworld.wolfram.com/GammaDistribution.html\n",
      "     |      .. [2] Wikipedia, \"Gamma distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> shape, scale = 2., 1. # mean and width\n",
      "     |      >>> s = np.random.standard_gamma(shape, 1000000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> import scipy.special as sps  # doctest: +SKIP\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "     |      >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/  # doctest: +SKIP\n",
      "     |      ...                       (sps.gamma(shape) * scale**shape))\n",
      "     |      >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  standard_normal(...)\n",
      "     |      standard_normal(size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Normal distribution (mean=0, stdev=1).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_normal`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : float or ndarray\n",
      "     |          A floating-point array of shape ``size`` of drawn samples, or a\n",
      "     |          single sample if ``size`` was not specified.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      normal :\n",
      "     |          Equivalent function with additional ``loc`` and ``scale`` arguments\n",
      "     |          for setting the mean and standard deviation.\n",
      "     |      Generator.standard_normal: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      For random samples from :math:`N(\\mu, \\sigma^2)`, use one of::\n",
      "     |      \n",
      "     |          mu + sigma * np.random.standard_normal(size=...)\n",
      "     |          np.random.normal(mu, sigma, size=...)\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> np.random.standard_normal()\n",
      "     |      2.1923875335537315 #random\n",
      "     |      \n",
      "     |      >>> s = np.random.standard_normal(8000)\n",
      "     |      >>> s\n",
      "     |      array([ 0.6888893 ,  0.78096262, -0.89086505, ...,  0.49876311,  # random\n",
      "     |             -0.38672696, -0.4685006 ])                                # random\n",
      "     |      >>> s.shape\n",
      "     |      (8000,)\n",
      "     |      >>> s = np.random.standard_normal(size=(3, 4, 2))\n",
      "     |      >>> s.shape\n",
      "     |      (3, 4, 2)\n",
      "     |      \n",
      "     |      Two-by-four array of samples from :math:`N(3, 6.25)`:\n",
      "     |      \n",
      "     |      >>> 3 + 2.5 * np.random.standard_normal(size=(2, 4))\n",
      "     |      array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "     |             [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "     |  \n",
      "     |  standard_t(...)\n",
      "     |      standard_t(df, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a standard Student's t distribution with `df` degrees\n",
      "     |      of freedom.\n",
      "     |      \n",
      "     |      A special case of the hyperbolic distribution.  As `df` gets\n",
      "     |      large, the result resembles that of the standard normal\n",
      "     |      distribution (`standard_normal`).\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``standard_t`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      df : float or array_like of floats\n",
      "     |          Degrees of freedom, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(df).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized standard Student's t distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.standard_t: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the t distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x, df) = \\frac{\\Gamma(\\frac{df+1}{2})}{\\sqrt{\\pi df}\n",
      "     |                \\Gamma(\\frac{df}{2})}\\Bigl( 1+\\frac{x^2}{df} \\Bigr)^{-(df+1)/2}\n",
      "     |      \n",
      "     |      The t test is based on an assumption that the data come from a\n",
      "     |      Normal distribution. The t test provides a way to test whether\n",
      "     |      the sample mean (that is the mean calculated from the data) is\n",
      "     |      a good estimate of the true mean.\n",
      "     |      \n",
      "     |      The derivation of the t-distribution was first published in\n",
      "     |      1908 by William Gosset while working for the Guinness Brewery\n",
      "     |      in Dublin. Due to proprietary issues, he had to publish under\n",
      "     |      a pseudonym, and so he used the name Student.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Dalgaard, Peter, \"Introductory Statistics With R\",\n",
      "     |             Springer, 2002.\n",
      "     |      .. [2] Wikipedia, \"Student's t-distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Student's_t-distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      From Dalgaard page 83 [1]_, suppose the daily energy intake for 11\n",
      "     |      women in kilojoules (kJ) is:\n",
      "     |      \n",
      "     |      >>> intake = np.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, \\\n",
      "     |      ...                    7515, 8230, 8770])\n",
      "     |      \n",
      "     |      Does their energy intake deviate systematically from the recommended\n",
      "     |      value of 7725 kJ?\n",
      "     |      \n",
      "     |      We have 10 degrees of freedom, so is the sample mean within 95% of the\n",
      "     |      recommended value?\n",
      "     |      \n",
      "     |      >>> s = np.random.standard_t(10, size=100000)\n",
      "     |      >>> np.mean(intake)\n",
      "     |      6753.636363636364\n",
      "     |      >>> intake.std(ddof=1)\n",
      "     |      1142.1232221373727\n",
      "     |      \n",
      "     |      Calculate the t statistic, setting the ddof parameter to the unbiased\n",
      "     |      value so the divisor in the standard deviation will be degrees of\n",
      "     |      freedom, N-1.\n",
      "     |      \n",
      "     |      >>> t = (np.mean(intake)-7725)/(intake.std(ddof=1)/np.sqrt(len(intake)))\n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(s, bins=100, density=True)\n",
      "     |      \n",
      "     |      For a one-sided t-test, how far out in the distribution does the t\n",
      "     |      statistic appear?\n",
      "     |      \n",
      "     |      >>> np.sum(s<t) / float(len(s))\n",
      "     |      0.0090699999999999999  #random\n",
      "     |      \n",
      "     |      So the p-value is about 0.009, which says the null hypothesis has a\n",
      "     |      probability of about 99% of being true.\n",
      "     |  \n",
      "     |  tomaxint(...)\n",
      "     |      tomaxint(size=None)\n",
      "     |      \n",
      "     |      Return a sample of uniformly distributed random integers in the interval\n",
      "     |      [0, ``np.iinfo(np.int_).max``]. The `np.int_` type translates to the C long\n",
      "     |      integer type and its precision is platform dependent.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray\n",
      "     |          Drawn samples, with shape `size`.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      randint : Uniform sampling over a given half-open interval of integers.\n",
      "     |      random_integers : Uniform sampling over a given closed interval of\n",
      "     |          integers.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      >>> rs = np.random.RandomState() # need a RandomState object\n",
      "     |      >>> rs.tomaxint((2,2,2))\n",
      "     |      array([[[1170048599, 1600360186], # random\n",
      "     |              [ 739731006, 1947757578]],\n",
      "     |             [[1871712945,  752307660],\n",
      "     |              [1601631370, 1479324245]]])\n",
      "     |      >>> rs.tomaxint((2,2,2)) < np.iinfo(np.int_).max\n",
      "     |      array([[[ True,  True],\n",
      "     |              [ True,  True]],\n",
      "     |             [[ True,  True],\n",
      "     |              [ True,  True]]])\n",
      "     |  \n",
      "     |  triangular(...)\n",
      "     |      triangular(left, mode, right, size=None)\n",
      "     |      \n",
      "     |      Draw samples from the triangular distribution over the\n",
      "     |      interval ``[left, right]``.\n",
      "     |      \n",
      "     |      The triangular distribution is a continuous probability\n",
      "     |      distribution with lower limit left, peak at mode, and upper\n",
      "     |      limit right. Unlike the other distributions, these parameters\n",
      "     |      directly define the shape of the pdf.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``triangular`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      left : float or array_like of floats\n",
      "     |          Lower limit.\n",
      "     |      mode : float or array_like of floats\n",
      "     |          The value where the peak of the distribution occurs.\n",
      "     |          The value must fulfill the condition ``left <= mode <= right``.\n",
      "     |      right : float or array_like of floats\n",
      "     |          Upper limit, must be larger than `left`.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``left``, ``mode``, and ``right``\n",
      "     |          are all scalars.  Otherwise, ``np.broadcast(left, mode, right).size``\n",
      "     |          samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized triangular distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.triangular: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the triangular distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;l, m, r) = \\begin{cases}\n",
      "     |                \\frac{2(x-l)}{(r-l)(m-l)}& \\text{for $l \\leq x \\leq m$},\\\\\n",
      "     |                \\frac{2(r-x)}{(r-l)(r-m)}& \\text{for $m \\leq x \\leq r$},\\\\\n",
      "     |                0& \\text{otherwise}.\n",
      "     |                \\end{cases}\n",
      "     |      \n",
      "     |      The triangular distribution is often used in ill-defined\n",
      "     |      problems where the underlying distribution is not known, but\n",
      "     |      some knowledge of the limits and mode exists. Often it is used\n",
      "     |      in simulations.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Wikipedia, \"Triangular distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Triangular_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(np.random.triangular(-3, 0, 8, 100000), bins=200,\n",
      "     |      ...              density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  uniform(...)\n",
      "     |      uniform(low=0.0, high=1.0, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a uniform distribution.\n",
      "     |      \n",
      "     |      Samples are uniformly distributed over the half-open interval\n",
      "     |      ``[low, high)`` (includes low, but excludes high).  In other words,\n",
      "     |      any value within the given interval is equally likely to be drawn\n",
      "     |      by `uniform`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``uniform`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      low : float or array_like of floats, optional\n",
      "     |          Lower boundary of the output interval.  All values generated will be\n",
      "     |          greater than or equal to low.  The default value is 0.\n",
      "     |      high : float or array_like of floats\n",
      "     |          Upper boundary of the output interval.  All values generated will be\n",
      "     |          less than high.  The default value is 1.0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``low`` and ``high`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(low, high).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized uniform distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      randint : Discrete uniform distribution, yielding integers.\n",
      "     |      random_integers : Discrete uniform distribution over the closed\n",
      "     |                        interval ``[low, high]``.\n",
      "     |      random_sample : Floats uniformly distributed over ``[0, 1)``.\n",
      "     |      random : Alias for `random_sample`.\n",
      "     |      rand : Convenience function that accepts dimensions as input, e.g.,\n",
      "     |             ``rand(2,2)`` would generate a 2-by-2 array of floats,\n",
      "     |             uniformly distributed over ``[0, 1)``.\n",
      "     |      Generator.uniform: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function of the uniform distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{1}{b - a}\n",
      "     |      \n",
      "     |      anywhere within the interval ``[a, b)``, and zero elsewhere.\n",
      "     |      \n",
      "     |      When ``high`` == ``low``, values of ``low`` will be returned.\n",
      "     |      If ``high`` < ``low``, the results are officially undefined\n",
      "     |      and may eventually raise an error, i.e. do not rely on this\n",
      "     |      function to behave when passed arguments satisfying that\n",
      "     |      inequality condition.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> s = np.random.uniform(-1,0,1000)\n",
      "     |      \n",
      "     |      All values are within the given interval:\n",
      "     |      \n",
      "     |      >>> np.all(s >= -1)\n",
      "     |      True\n",
      "     |      >>> np.all(s < 0)\n",
      "     |      True\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with the\n",
      "     |      probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> count, bins, ignored = plt.hist(s, 15, density=True)\n",
      "     |      >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  vonmises(...)\n",
      "     |      vonmises(mu, kappa, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a von Mises distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a von Mises distribution with specified mode\n",
      "     |      (mu) and dispersion (kappa), on the interval [-pi, pi].\n",
      "     |      \n",
      "     |      The von Mises distribution (also known as the circular normal\n",
      "     |      distribution) is a continuous probability distribution on the unit\n",
      "     |      circle.  It may be thought of as the circular analogue of the normal\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``vonmises`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mu : float or array_like of floats\n",
      "     |          Mode (\"center\") of the distribution.\n",
      "     |      kappa : float or array_like of floats\n",
      "     |          Dispersion of the distribution, has to be >=0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mu`` and ``kappa`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mu, kappa).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized von Mises distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.vonmises : probability density function, distribution, or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.vonmises: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the von Mises distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{e^{\\kappa cos(x-\\mu)}}{2\\pi I_0(\\kappa)},\n",
      "     |      \n",
      "     |      where :math:`\\mu` is the mode and :math:`\\kappa` the dispersion,\n",
      "     |      and :math:`I_0(\\kappa)` is the modified Bessel function of order 0.\n",
      "     |      \n",
      "     |      The von Mises is named for Richard Edler von Mises, who was born in\n",
      "     |      Austria-Hungary, in what is now the Ukraine.  He fled to the United\n",
      "     |      States in 1939 and became a professor at Harvard.  He worked in\n",
      "     |      probability theory, aerodynamics, fluid mechanics, and philosophy of\n",
      "     |      science.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "     |             Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "     |             Tables, 9th printing,\" New York: Dover, 1972.\n",
      "     |      .. [2] von Mises, R., \"Mathematical Theory of Probability\n",
      "     |             and Statistics\", New York: Academic Press, 1964.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> mu, kappa = 0.0, 4.0 # mean and dispersion\n",
      "     |      >>> s = np.random.vonmises(mu, kappa, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from scipy.special import i0  # doctest: +SKIP\n",
      "     |      >>> plt.hist(s, 50, density=True)\n",
      "     |      >>> x = np.linspace(-np.pi, np.pi, num=51)\n",
      "     |      >>> y = np.exp(kappa*np.cos(x-mu))/(2*np.pi*i0(kappa))  # doctest: +SKIP\n",
      "     |      >>> plt.plot(x, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  wald(...)\n",
      "     |      wald(mean, scale, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Wald, or inverse Gaussian, distribution.\n",
      "     |      \n",
      "     |      As the scale approaches infinity, the distribution becomes more like a\n",
      "     |      Gaussian. Some references claim that the Wald is an inverse Gaussian\n",
      "     |      with mean equal to 1, but this is by no means universal.\n",
      "     |      \n",
      "     |      The inverse Gaussian distribution was first studied in relationship to\n",
      "     |      Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n",
      "     |      because there is an inverse relationship between the time to cover a\n",
      "     |      unit distance and distance covered in unit time.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``wald`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      mean : float or array_like of floats\n",
      "     |          Distribution mean, must be > 0.\n",
      "     |      scale : float or array_like of floats\n",
      "     |          Scale parameter, must be > 0.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``mean`` and ``scale`` are both scalars.\n",
      "     |          Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Wald distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      Generator.wald: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density function for the Wald distribution is\n",
      "     |      \n",
      "     |      .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n",
      "     |                                  \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n",
      "     |      \n",
      "     |      As noted above the inverse Gaussian distribution first arise\n",
      "     |      from attempts to model Brownian motion. It is also a\n",
      "     |      competitor to the Weibull for use in reliability modeling and\n",
      "     |      modeling stock returns and interest rate processes.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Brighton Webs Ltd., Wald Distribution,\n",
      "     |             https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp\n",
      "     |      .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n",
      "     |             Distribution: Theory : Methodology, and Applications\", CRC Press,\n",
      "     |             1988.\n",
      "     |      .. [3] Wikipedia, \"Inverse Gaussian distribution\"\n",
      "     |             https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw values from the distribution and plot the histogram:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  weibull(...)\n",
      "     |      weibull(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Weibull distribution.\n",
      "     |      \n",
      "     |      Draw samples from a 1-parameter Weibull distribution with the given\n",
      "     |      shape parameter `a`.\n",
      "     |      \n",
      "     |      .. math:: X = (-ln(U))^{1/a}\n",
      "     |      \n",
      "     |      Here, U is drawn from the uniform distribution over (0,1].\n",
      "     |      \n",
      "     |      The more common 2-parameter Weibull, including a scale parameter\n",
      "     |      :math:`\\lambda` is just :math:`X = \\lambda(-ln(U))^{1/a}`.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``weibull`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Shape parameter of the distribution.  Must be nonnegative.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Weibull distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.weibull_max\n",
      "     |      scipy.stats.weibull_min\n",
      "     |      scipy.stats.genextreme\n",
      "     |      gumbel\n",
      "     |      Generator.weibull: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The Weibull (or Type III asymptotic extreme value distribution\n",
      "     |      for smallest values, SEV Type III, or Rosin-Rammler\n",
      "     |      distribution) is one of a class of Generalized Extreme Value\n",
      "     |      (GEV) distributions used in modeling extreme value problems.\n",
      "     |      This class includes the Gumbel and Frechet distributions.\n",
      "     |      \n",
      "     |      The probability density for the Weibull distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{a}\n",
      "     |                       {\\lambda}(\\frac{x}{\\lambda})^{a-1}e^{-(x/\\lambda)^a},\n",
      "     |      \n",
      "     |      where :math:`a` is the shape and :math:`\\lambda` the scale.\n",
      "     |      \n",
      "     |      The function has its peak (the mode) at\n",
      "     |      :math:`\\lambda(\\frac{a-1}{a})^{1/a}`.\n",
      "     |      \n",
      "     |      When ``a = 1``, the Weibull distribution reduces to the exponential\n",
      "     |      distribution.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Waloddi Weibull, Royal Technical University, Stockholm,\n",
      "     |             1939 \"A Statistical Theory Of The Strength Of Materials\",\n",
      "     |             Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939,\n",
      "     |             Generalstabens Litografiska Anstalts Forlag, Stockholm.\n",
      "     |      .. [2] Waloddi Weibull, \"A Statistical Distribution Function of\n",
      "     |             Wide Applicability\", Journal Of Applied Mechanics ASME Paper\n",
      "     |             1951.\n",
      "     |      .. [3] Wikipedia, \"Weibull distribution\",\n",
      "     |             https://en.wikipedia.org/wiki/Weibull_distribution\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = 5. # shape\n",
      "     |      >>> s = np.random.weibull(a, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> x = np.arange(1,100.)/50.\n",
      "     |      >>> def weib(x,n,a):\n",
      "     |      ...     return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)\n",
      "     |      \n",
      "     |      >>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000))\n",
      "     |      >>> x = np.arange(1,100.)/50.\n",
      "     |      >>> scale = count.max()/weib(x, 1., 5.).max()\n",
      "     |      >>> plt.plot(x, weib(x, 1., 5.)*scale)\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  zipf(...)\n",
      "     |      zipf(a, size=None)\n",
      "     |      \n",
      "     |      Draw samples from a Zipf distribution.\n",
      "     |      \n",
      "     |      Samples are drawn from a Zipf distribution with specified parameter\n",
      "     |      `a` > 1.\n",
      "     |      \n",
      "     |      The Zipf distribution (also known as the zeta distribution) is a\n",
      "     |      continuous probability distribution that satisfies Zipf's law: the\n",
      "     |      frequency of an item is inversely proportional to its rank in a\n",
      "     |      frequency table.\n",
      "     |      \n",
      "     |      .. note::\n",
      "     |          New code should use the ``zipf`` method of a ``default_rng()``\n",
      "     |          instance instead; see `random-quick-start`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      a : float or array_like of floats\n",
      "     |          Distribution parameter. Must be greater than 1.\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "     |          a single value is returned if ``a`` is a scalar. Otherwise,\n",
      "     |          ``np.array(a).size`` samples are drawn.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : ndarray or scalar\n",
      "     |          Drawn samples from the parameterized Zipf distribution.\n",
      "     |      \n",
      "     |      See Also\n",
      "     |      --------\n",
      "     |      scipy.stats.zipf : probability density function, distribution, or\n",
      "     |          cumulative density function, etc.\n",
      "     |      Generator.zipf: which should be used for new code.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      The probability density for the Zipf distribution is\n",
      "     |      \n",
      "     |      .. math:: p(x) = \\frac{x^{-a}}{\\zeta(a)},\n",
      "     |      \n",
      "     |      where :math:`\\zeta` is the Riemann Zeta function.\n",
      "     |      \n",
      "     |      It is named for the American linguist George Kingsley Zipf, who noted\n",
      "     |      that the frequency of any word in a sample of a language is inversely\n",
      "     |      proportional to its rank in the frequency table.\n",
      "     |      \n",
      "     |      References\n",
      "     |      ----------\n",
      "     |      .. [1] Zipf, G. K., \"Selected Studies of the Principle of Relative\n",
      "     |             Frequency in Language,\" Cambridge, MA: Harvard Univ. Press,\n",
      "     |             1932.\n",
      "     |      \n",
      "     |      Examples\n",
      "     |      --------\n",
      "     |      Draw samples from the distribution:\n",
      "     |      \n",
      "     |      >>> a = 2. # parameter\n",
      "     |      >>> s = np.random.zipf(a, 1000)\n",
      "     |      \n",
      "     |      Display the histogram of the samples, along with\n",
      "     |      the probability density function:\n",
      "     |      \n",
      "     |      >>> import matplotlib.pyplot as plt\n",
      "     |      >>> from scipy import special  # doctest: +SKIP\n",
      "     |      \n",
      "     |      Truncate s values at 50 so plot is interesting:\n",
      "     |      \n",
      "     |      >>> count, bins, ignored = plt.hist(s[s<50], 50, density=True)\n",
      "     |      >>> x = np.arange(1., 50.)\n",
      "     |      >>> y = x**(-a) / special.zetac(a)  # doctest: +SKIP\n",
      "     |      >>> plt.plot(x, y/max(y), linewidth=2, color='r')  # doctest: +SKIP\n",
      "     |      >>> plt.show()\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "    \n",
      "    class SFC64(numpy.random._bit_generator.BitGenerator)\n",
      "     |  SFC64(seed=None)\n",
      "     |  \n",
      "     |  BitGenerator for Chris Doty-Humphrey's Small Fast Chaotic PRNG.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  seed : {None, int, array_like[ints], SeedSequence}, optional\n",
      "     |      A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "     |      unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "     |      ``array_like[ints]`` is passed, then it will be passed to\n",
      "     |      `SeedSequence` to derive the initial `BitGenerator` state. One may also\n",
      "     |      pass in a `SeedSequence` instance.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  ``SFC64`` is a 256-bit implementation of Chris Doty-Humphrey's Small Fast\n",
      "     |  Chaotic PRNG ([1]_). ``SFC64`` has a few different cycles that one might be\n",
      "     |  on, depending on the seed; the expected period will be about\n",
      "     |  :math:`2^{255}` ([2]_). ``SFC64`` incorporates a 64-bit counter which means\n",
      "     |  that the absolute minimum cycle length is :math:`2^{64}` and that distinct\n",
      "     |  seeds will not run into each other for at least :math:`2^{64}` iterations.\n",
      "     |  \n",
      "     |  ``SFC64`` provides a capsule containing function pointers that produce\n",
      "     |  doubles, and unsigned 32 and 64- bit integers. These are not\n",
      "     |  directly consumable in Python and must be consumed by a ``Generator``\n",
      "     |  or similar object that supports low-level access.\n",
      "     |  \n",
      "     |  **State and Seeding**\n",
      "     |  \n",
      "     |  The ``SFC64`` state vector consists of 4 unsigned 64-bit values. The last\n",
      "     |  is a 64-bit counter that increments by 1 each iteration.\n",
      "     |  \n",
      "     |  The input seed is processed by `SeedSequence` to generate the first\n",
      "     |  3 values, then the ``SFC64`` algorithm is iterated a small number of times\n",
      "     |  to mix.\n",
      "     |  \n",
      "     |  **Compatibility Guarantee**\n",
      "     |  \n",
      "     |  ``SFC64`` makes a guarantee that a fixed seed will always produce the same\n",
      "     |  random integer stream.\n",
      "     |  \n",
      "     |  References\n",
      "     |  ----------\n",
      "     |  .. [1] `\"PractRand\"\n",
      "     |          <http://pracrand.sourceforge.net/RNG_engines.txt>`_\n",
      "     |  .. [2] `\"Random Invertible Mapping Statistics\"\n",
      "     |          <http://www.pcg-random.org/posts/random-invertible-mapping-statistics.html>`_\n",
      "     |  \n",
      "     |  Method resolution order:\n",
      "     |      SFC64\n",
      "     |      numpy.random._bit_generator.BitGenerator\n",
      "     |      builtins.object\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __setstate_cython__(...)\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  state\n",
      "     |      Get or set the PRNG state\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : dict\n",
      "     |          Dictionary containing the information required to describe the\n",
      "     |          state of the PRNG\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Methods inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  __getstate__(...)\n",
      "     |  \n",
      "     |  __reduce__(...)\n",
      "     |      Helper for pickle.\n",
      "     |  \n",
      "     |  __setstate__(...)\n",
      "     |  \n",
      "     |  random_raw(...)\n",
      "     |      random_raw(self, size=None)\n",
      "     |      \n",
      "     |      Return randoms as generated by the underlying BitGenerator\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      size : int or tuple of ints, optional\n",
      "     |          Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "     |          ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "     |          single value is returned.\n",
      "     |      output : bool, optional\n",
      "     |          Output values.  Used for performance testing since the generated\n",
      "     |          values are not returned.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      out : uint or ndarray\n",
      "     |          Drawn samples.\n",
      "     |      \n",
      "     |      Notes\n",
      "     |      -----\n",
      "     |      This method directly exposes the the raw underlying pseudo-random\n",
      "     |      number generator. All values are returned as unsigned 64-bit\n",
      "     |      values irrespective of the number of bits produced by the PRNG.\n",
      "     |      \n",
      "     |      See the class docstring for the number of bits returned.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors inherited from numpy.random._bit_generator.BitGenerator:\n",
      "     |  \n",
      "     |  capsule\n",
      "     |  \n",
      "     |  cffi\n",
      "     |      CFFI interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing CFFI wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  ctypes\n",
      "     |      ctypes interface\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      interface : namedtuple\n",
      "     |          Named tuple containing ctypes wrapper\n",
      "     |      \n",
      "     |          * state_address - Memory address of the state struct\n",
      "     |          * state - pointer to the state struct\n",
      "     |          * next_uint64 - function pointer to produce 64 bit integers\n",
      "     |          * next_uint32 - function pointer to produce 32 bit integers\n",
      "     |          * next_double - function pointer to produce doubles\n",
      "     |          * bitgen - pointer to the bit generator struct\n",
      "     |  \n",
      "     |  lock\n",
      "    \n",
      "    class SeedSequence(builtins.object)\n",
      "     |  SeedSequence(entropy=None, *, spawn_key=(), pool_size=4)\n",
      "     |  \n",
      "     |  SeedSequence mixes sources of entropy in a reproducible way to set the\n",
      "     |  initial state for independent and very probably non-overlapping\n",
      "     |  BitGenerators.\n",
      "     |  \n",
      "     |  Once the SeedSequence is instantiated, you can call the `generate_state`\n",
      "     |  method to get an appropriately sized seed. Calling `spawn(n) <spawn>` will\n",
      "     |  create ``n`` SeedSequences that can be used to seed independent\n",
      "     |  BitGenerators, i.e. for different threads.\n",
      "     |  \n",
      "     |  Parameters\n",
      "     |  ----------\n",
      "     |  entropy : {None, int, sequence[int]}, optional\n",
      "     |      The entropy for creating a `SeedSequence`.\n",
      "     |  spawn_key : {(), sequence[int]}, optional\n",
      "     |      A third source of entropy, used internally when calling\n",
      "     |      `SeedSequence.spawn`\n",
      "     |  pool_size : {int}, optional\n",
      "     |      Size of the pooled entropy to store. Default is 4 to give a 128-bit\n",
      "     |      entropy pool. 8 (for 256 bits) is another reasonable choice if working\n",
      "     |      with larger PRNGs, but there is very little to be gained by selecting\n",
      "     |      another value.\n",
      "     |  n_children_spawned : {int}, optional\n",
      "     |      The number of children already spawned. Only pass this if\n",
      "     |      reconstructing a `SeedSequence` from a serialized form.\n",
      "     |  \n",
      "     |  Notes\n",
      "     |  -----\n",
      "     |  \n",
      "     |  Best practice for achieving reproducible bit streams is to use\n",
      "     |  the default ``None`` for the initial entropy, and then use\n",
      "     |  `SeedSequence.entropy` to log/pickle the `entropy` for reproducibility:\n",
      "     |  \n",
      "     |  >>> sq1 = np.random.SeedSequence()\n",
      "     |  >>> sq1.entropy\n",
      "     |  243799254704924441050048792905230269161  # random\n",
      "     |  >>> sq2 = np.random.SeedSequence(sq1.entropy)\n",
      "     |  >>> np.all(sq1.generate_state(10) == sq2.generate_state(10))\n",
      "     |  True\n",
      "     |  \n",
      "     |  Methods defined here:\n",
      "     |  \n",
      "     |  __init__(self, /, *args, **kwargs)\n",
      "     |      Initialize self.  See help(type(self)) for accurate signature.\n",
      "     |  \n",
      "     |  __reduce__ = __reduce_cython__(...)\n",
      "     |  \n",
      "     |  __repr__(self, /)\n",
      "     |      Return repr(self).\n",
      "     |  \n",
      "     |  __setstate__ = __setstate_cython__(...)\n",
      "     |  \n",
      "     |  generate_state(...)\n",
      "     |      generate_state(n_words, dtype=np.uint32)\n",
      "     |      \n",
      "     |      Return the requested number of words for PRNG seeding.\n",
      "     |      \n",
      "     |      A BitGenerator should call this method in its constructor with\n",
      "     |      an appropriate `n_words` parameter to properly seed itself.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_words : int\n",
      "     |      dtype : np.uint32 or np.uint64, optional\n",
      "     |          The size of each word. This should only be either `uint32` or\n",
      "     |          `uint64`. Strings (`'uint32'`, `'uint64'`) are fine. Note that\n",
      "     |          requesting `uint64` will draw twice as many bits as `uint32` for\n",
      "     |          the same `n_words`. This is a convenience for `BitGenerator`s that\n",
      "     |          express their states as `uint64` arrays.\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      state : uint32 or uint64 array, shape=(n_words,)\n",
      "     |  \n",
      "     |  spawn(...)\n",
      "     |      spawn(n_children)\n",
      "     |      \n",
      "     |      Spawn a number of child `SeedSequence` s by extending the\n",
      "     |      `spawn_key`.\n",
      "     |      \n",
      "     |      Parameters\n",
      "     |      ----------\n",
      "     |      n_children : int\n",
      "     |      \n",
      "     |      Returns\n",
      "     |      -------\n",
      "     |      seqs : list of `SeedSequence` s\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Static methods defined here:\n",
      "     |  \n",
      "     |  __new__(*args, **kwargs) from builtins.type\n",
      "     |      Create and return a new object.  See help(type) for accurate signature.\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data descriptors defined here:\n",
      "     |  \n",
      "     |  entropy\n",
      "     |  \n",
      "     |  n_children_spawned\n",
      "     |  \n",
      "     |  pool\n",
      "     |  \n",
      "     |  pool_size\n",
      "     |  \n",
      "     |  spawn_key\n",
      "     |  \n",
      "     |  state\n",
      "     |  \n",
      "     |  ----------------------------------------------------------------------\n",
      "     |  Data and other attributes defined here:\n",
      "     |  \n",
      "     |  __pyx_vtable__ = <capsule object NULL>\n",
      "\n",
      "FUNCTIONS\n",
      "    beta(...) method of numpy.random.mtrand.RandomState instance\n",
      "        beta(a, b, size=None)\n",
      "        \n",
      "        Draw samples from a Beta distribution.\n",
      "        \n",
      "        The Beta distribution is a special case of the Dirichlet distribution,\n",
      "        and is related to the Gamma distribution.  It has the probability\n",
      "        distribution function\n",
      "        \n",
      "        .. math:: f(x; a,b) = \\frac{1}{B(\\alpha, \\beta)} x^{\\alpha - 1}\n",
      "                                                         (1 - x)^{\\beta - 1},\n",
      "        \n",
      "        where the normalization, B, is the beta function,\n",
      "        \n",
      "        .. math:: B(\\alpha, \\beta) = \\int_0^1 t^{\\alpha - 1}\n",
      "                                     (1 - t)^{\\beta - 1} dt.\n",
      "        \n",
      "        It is often seen in Bayesian inference and order statistics.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``beta`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : float or array_like of floats\n",
      "            Alpha, positive (>0).\n",
      "        b : float or array_like of floats\n",
      "            Beta, positive (>0).\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``a`` and ``b`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(a, b).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized beta distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.beta: which should be used for new code.\n",
      "    \n",
      "    binomial(...) method of numpy.random.mtrand.RandomState instance\n",
      "        binomial(n, p, size=None)\n",
      "        \n",
      "        Draw samples from a binomial distribution.\n",
      "        \n",
      "        Samples are drawn from a binomial distribution with specified\n",
      "        parameters, n trials and p probability of success where\n",
      "        n an integer >= 0 and p is in the interval [0,1]. (n may be\n",
      "        input as a float, but it is truncated to an integer in use)\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``binomial`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n : int or array_like of ints\n",
      "            Parameter of the distribution, >= 0. Floats are also accepted,\n",
      "            but they will be truncated to integers.\n",
      "        p : float or array_like of floats\n",
      "            Parameter of the distribution, >= 0 and <=1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized binomial distribution, where\n",
      "            each sample is equal to the number of successes over the n trials.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.binom : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.binomial: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the binomial distribution is\n",
      "        \n",
      "        .. math:: P(N) = \\binom{n}{N}p^N(1-p)^{n-N},\n",
      "        \n",
      "        where :math:`n` is the number of trials, :math:`p` is the probability\n",
      "        of success, and :math:`N` is the number of successes.\n",
      "        \n",
      "        When estimating the standard error of a proportion in a population by\n",
      "        using a random sample, the normal distribution works well unless the\n",
      "        product p*n <=5, where p = population proportion estimate, and n =\n",
      "        number of samples, in which case the binomial distribution is used\n",
      "        instead. For example, a sample of 15 people shows 4 who are left\n",
      "        handed, and 11 who are right handed. Then p = 4/15 = 27%. 0.27*15 = 4,\n",
      "        so the binomial distribution should be used in this case.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Dalgaard, Peter, \"Introductory Statistics with R\",\n",
      "               Springer-Verlag, 2002.\n",
      "        .. [2] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "               Fifth Edition, 2002.\n",
      "        .. [3] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "               and Quigley, 1972.\n",
      "        .. [4] Weisstein, Eric W. \"Binomial Distribution.\" From MathWorld--A\n",
      "               Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/BinomialDistribution.html\n",
      "        .. [5] Wikipedia, \"Binomial distribution\",\n",
      "               https://en.wikipedia.org/wiki/Binomial_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> n, p = 10, .5  # number of trials, probability of each trial\n",
      "        >>> s = np.random.binomial(n, p, 1000)\n",
      "        # result of flipping a coin 10 times, tested 1000 times.\n",
      "        \n",
      "        A real world example. A company drills 9 wild-cat oil exploration\n",
      "        wells, each with an estimated probability of success of 0.1. All nine\n",
      "        wells fail. What is the probability of that happening?\n",
      "        \n",
      "        Let's do 20,000 trials of the model, and count the number that\n",
      "        generate zero positive results.\n",
      "        \n",
      "        >>> sum(np.random.binomial(9, 0.1, 20000) == 0)/20000.\n",
      "        # answer = 0.38885, or 38%.\n",
      "    \n",
      "    bytes(...) method of numpy.random.mtrand.RandomState instance\n",
      "        bytes(length)\n",
      "        \n",
      "        Return random bytes.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``bytes`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        length : int\n",
      "            Number of random bytes.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : str\n",
      "            String of length `length`.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.bytes: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.bytes(10)\n",
      "        ' eh\\x85\\x022SZ\\xbf\\xa4' #random\n",
      "    \n",
      "    chisquare(...) method of numpy.random.mtrand.RandomState instance\n",
      "        chisquare(df, size=None)\n",
      "        \n",
      "        Draw samples from a chi-square distribution.\n",
      "        \n",
      "        When `df` independent random variables, each with standard normal\n",
      "        distributions (mean 0, variance 1), are squared and summed, the\n",
      "        resulting distribution is chi-square (see Notes).  This distribution\n",
      "        is often used in hypothesis testing.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``chisquare`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        df : float or array_like of floats\n",
      "             Number of degrees of freedom, must be > 0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "            ``np.array(df).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized chi-square distribution.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            When `df` <= 0 or when an inappropriate `size` (e.g. ``size=-1``)\n",
      "            is given.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.chisquare: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The variable obtained by summing the squares of `df` independent,\n",
      "        standard normally distributed random variables:\n",
      "        \n",
      "        .. math:: Q = \\sum_{i=0}^{\\mathtt{df}} X^2_i\n",
      "        \n",
      "        is chi-square distributed, denoted\n",
      "        \n",
      "        .. math:: Q \\sim \\chi^2_k.\n",
      "        \n",
      "        The probability density function of the chi-squared distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{(1/2)^{k/2}}{\\Gamma(k/2)}\n",
      "                         x^{k/2 - 1} e^{-x/2},\n",
      "        \n",
      "        where :math:`\\Gamma` is the gamma function,\n",
      "        \n",
      "        .. math:: \\Gamma(x) = \\int_0^{-\\infty} t^{x - 1} e^{-t} dt.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] NIST \"Engineering Statistics Handbook\"\n",
      "               https://www.itl.nist.gov/div898/handbook/eda/section3/eda3666.htm\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.chisquare(2,4)\n",
      "        array([ 1.89920014,  9.00867716,  3.13710533,  5.62318272]) # random\n",
      "    \n",
      "    choice(...) method of numpy.random.mtrand.RandomState instance\n",
      "        choice(a, size=None, replace=True, p=None)\n",
      "        \n",
      "        Generates a random sample from a given 1-D array\n",
      "        \n",
      "                .. versionadded:: 1.7.0\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``choice`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : 1-D array-like or int\n",
      "            If an ndarray, a random sample is generated from its elements.\n",
      "            If an int, the random sample is generated as if a were np.arange(a)\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        replace : boolean, optional\n",
      "            Whether the sample is with or without replacement\n",
      "        p : 1-D array-like, optional\n",
      "            The probabilities associated with each entry in a.\n",
      "            If not given the sample assumes a uniform distribution over all\n",
      "            entries in a.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        samples : single item or ndarray\n",
      "            The generated random samples\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            If a is an int and less than zero, if a or p are not 1-dimensional,\n",
      "            if a is an array-like of size 0, if p is not a vector of\n",
      "            probabilities, if a and p have different lengths, or if\n",
      "            replace=False and the sample size is greater than the population\n",
      "            size\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        randint, shuffle, permutation\n",
      "        Generator.choice: which should be used in new code\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Generate a uniform random sample from np.arange(5) of size 3:\n",
      "        \n",
      "        >>> np.random.choice(5, 3)\n",
      "        array([0, 3, 4]) # random\n",
      "        >>> #This is equivalent to np.random.randint(0,5,3)\n",
      "        \n",
      "        Generate a non-uniform random sample from np.arange(5) of size 3:\n",
      "        \n",
      "        >>> np.random.choice(5, 3, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "        array([3, 3, 0]) # random\n",
      "        \n",
      "        Generate a uniform random sample from np.arange(5) of size 3 without\n",
      "        replacement:\n",
      "        \n",
      "        >>> np.random.choice(5, 3, replace=False)\n",
      "        array([3,1,0]) # random\n",
      "        >>> #This is equivalent to np.random.permutation(np.arange(5))[:3]\n",
      "        \n",
      "        Generate a non-uniform random sample from np.arange(5) of size\n",
      "        3 without replacement:\n",
      "        \n",
      "        >>> np.random.choice(5, 3, replace=False, p=[0.1, 0, 0.3, 0.6, 0])\n",
      "        array([2, 3, 0]) # random\n",
      "        \n",
      "        Any of the above can be repeated with an arbitrary array-like\n",
      "        instead of just integers. For instance:\n",
      "        \n",
      "        >>> aa_milne_arr = ['pooh', 'rabbit', 'piglet', 'Christopher']\n",
      "        >>> np.random.choice(aa_milne_arr, 5, p=[0.5, 0.1, 0.1, 0.3])\n",
      "        array(['pooh', 'pooh', 'pooh', 'Christopher', 'piglet'], # random\n",
      "              dtype='<U11')\n",
      "    \n",
      "    default_rng(...)\n",
      "        Construct a new Generator with the default BitGenerator (PCG64).\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        seed : {None, int, array_like[ints], SeedSequence, BitGenerator, Generator}, optional\n",
      "            A seed to initialize the `BitGenerator`. If None, then fresh,\n",
      "            unpredictable entropy will be pulled from the OS. If an ``int`` or\n",
      "            ``array_like[ints]`` is passed, then it will be passed to\n",
      "            `SeedSequence` to derive the initial `BitGenerator` state. One may also\n",
      "            pass in a`SeedSequence` instance\n",
      "            Additionally, when passed a `BitGenerator`, it will be wrapped by\n",
      "            `Generator`. If passed a `Generator`, it will be returned unaltered.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Generator\n",
      "            The initialized generator object.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        If ``seed`` is not a `BitGenerator` or a `Generator`, a new `BitGenerator`\n",
      "        is instantiated. This function does not manage a default global instance.\n",
      "    \n",
      "    dirichlet(...) method of numpy.random.mtrand.RandomState instance\n",
      "        dirichlet(alpha, size=None)\n",
      "        \n",
      "        Draw samples from the Dirichlet distribution.\n",
      "        \n",
      "        Draw `size` samples of dimension k from a Dirichlet distribution. A\n",
      "        Dirichlet-distributed random variable can be seen as a multivariate\n",
      "        generalization of a Beta distribution. The Dirichlet distribution\n",
      "        is a conjugate prior of a multinomial distribution in Bayesian\n",
      "        inference.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``dirichlet`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        alpha : sequence of floats, length k\n",
      "            Parameter of the distribution (length ``k`` for sample of\n",
      "            length ``k``).\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            vector of length ``k`` is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        samples : ndarray,\n",
      "            The drawn samples, of shape ``(size, k)``.\n",
      "        \n",
      "        Raises\n",
      "        -------\n",
      "        ValueError\n",
      "            If any value in ``alpha`` is less than or equal to zero\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.dirichlet: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Dirichlet distribution is a distribution over vectors\n",
      "        :math:`x` that fulfil the conditions :math:`x_i>0` and\n",
      "        :math:`\\sum_{i=1}^k x_i = 1`.\n",
      "        \n",
      "        The probability density function :math:`p` of a\n",
      "        Dirichlet-distributed random vector :math:`X` is\n",
      "        proportional to\n",
      "        \n",
      "        .. math:: p(x) \\propto \\prod_{i=1}^{k}{x^{\\alpha_i-1}_i},\n",
      "        \n",
      "        where :math:`\\alpha` is a vector containing the positive\n",
      "        concentration parameters.\n",
      "        \n",
      "        The method uses the following property for computation: let :math:`Y`\n",
      "        be a random vector which has components that follow a standard gamma\n",
      "        distribution, then :math:`X = \\frac{1}{\\sum_{i=1}^k{Y_i}} Y`\n",
      "        is Dirichlet-distributed\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] David McKay, \"Information Theory, Inference and Learning\n",
      "               Algorithms,\" chapter 23,\n",
      "               http://www.inference.org.uk/mackay/itila/\n",
      "        .. [2] Wikipedia, \"Dirichlet distribution\",\n",
      "               https://en.wikipedia.org/wiki/Dirichlet_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Taking an example cited in Wikipedia, this distribution can be used if\n",
      "        one wanted to cut strings (each of initial length 1.0) into K pieces\n",
      "        with different lengths, where each piece had, on average, a designated\n",
      "        average length, but allowing some variation in the relative sizes of\n",
      "        the pieces.\n",
      "        \n",
      "        >>> s = np.random.dirichlet((10, 5, 3), 20).transpose()\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> plt.barh(range(20), s[0])\n",
      "        >>> plt.barh(range(20), s[1], left=s[0], color='g')\n",
      "        >>> plt.barh(range(20), s[2], left=s[0]+s[1], color='r')\n",
      "        >>> plt.title(\"Lengths of Strings\")\n",
      "    \n",
      "    exponential(...) method of numpy.random.mtrand.RandomState instance\n",
      "        exponential(scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from an exponential distribution.\n",
      "        \n",
      "        Its probability density function is\n",
      "        \n",
      "        .. math:: f(x; \\frac{1}{\\beta}) = \\frac{1}{\\beta} \\exp(-\\frac{x}{\\beta}),\n",
      "        \n",
      "        for ``x > 0`` and 0 elsewhere. :math:`\\beta` is the scale parameter,\n",
      "        which is the inverse of the rate parameter :math:`\\lambda = 1/\\beta`.\n",
      "        The rate parameter is an alternative, widely used parameterization\n",
      "        of the exponential distribution [3]_.\n",
      "        \n",
      "        The exponential distribution is a continuous analogue of the\n",
      "        geometric distribution.  It describes many common situations, such as\n",
      "        the size of raindrops measured over many rainstorms [1]_, or the time\n",
      "        between page requests to Wikipedia [2]_.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``exponential`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scale : float or array_like of floats\n",
      "            The scale parameter, :math:`\\beta = 1/\\lambda`. Must be\n",
      "            non-negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "            ``np.array(scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized exponential distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.exponential: which should be used for new code.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Peyton Z. Peebles Jr., \"Probability, Random Variables and\n",
      "               Random Signal Principles\", 4th ed, 2001, p. 57.\n",
      "        .. [2] Wikipedia, \"Poisson process\",\n",
      "               https://en.wikipedia.org/wiki/Poisson_process\n",
      "        .. [3] Wikipedia, \"Exponential distribution\",\n",
      "               https://en.wikipedia.org/wiki/Exponential_distribution\n",
      "    \n",
      "    f(...) method of numpy.random.mtrand.RandomState instance\n",
      "        f(dfnum, dfden, size=None)\n",
      "        \n",
      "        Draw samples from an F distribution.\n",
      "        \n",
      "        Samples are drawn from an F distribution with specified parameters,\n",
      "        `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "        freedom in denominator), where both parameters must be greater than\n",
      "        zero.\n",
      "        \n",
      "        The random variate of the F distribution (also known as the\n",
      "        Fisher distribution) is a continuous probability distribution\n",
      "        that arises in ANOVA tests, and is the ratio of two chi-square\n",
      "        variates.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``f`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dfnum : float or array_like of floats\n",
      "            Degrees of freedom in numerator, must be > 0.\n",
      "        dfden : float or array_like of float\n",
      "            Degrees of freedom in denominator, must be > 0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``dfnum`` and ``dfden`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(dfnum, dfden).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Fisher distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.f : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.f: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The F statistic is used to compare in-group variances to between-group\n",
      "        variances. Calculating the distribution depends on the sampling, and\n",
      "        so it is a function of the respective degrees of freedom in the\n",
      "        problem.  The variable `dfnum` is the number of samples minus one, the\n",
      "        between-groups degrees of freedom, while `dfden` is the within-groups\n",
      "        degrees of freedom, the sum of the number of samples in each group\n",
      "        minus the number of groups.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Glantz, Stanton A. \"Primer of Biostatistics.\", McGraw-Hill,\n",
      "               Fifth Edition, 2002.\n",
      "        .. [2] Wikipedia, \"F-distribution\",\n",
      "               https://en.wikipedia.org/wiki/F-distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        An example from Glantz[1], pp 47-40:\n",
      "        \n",
      "        Two groups, children of diabetics (25 people) and children from people\n",
      "        without diabetes (25 controls). Fasting blood glucose was measured,\n",
      "        case group had a mean value of 86.1, controls had a mean value of\n",
      "        82.2. Standard deviations were 2.09 and 2.49 respectively. Are these\n",
      "        data consistent with the null hypothesis that the parents diabetic\n",
      "        status does not affect their children's blood glucose levels?\n",
      "        Calculating the F statistic from the data gives a value of 36.01.\n",
      "        \n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> dfnum = 1. # between group degrees of freedom\n",
      "        >>> dfden = 48. # within groups degrees of freedom\n",
      "        >>> s = np.random.f(dfnum, dfden, 1000)\n",
      "        \n",
      "        The lower bound for the top 1% of the samples is :\n",
      "        \n",
      "        >>> np.sort(s)[-10]\n",
      "        7.61988120985 # random\n",
      "        \n",
      "        So there is about a 1% chance that the F statistic will exceed 7.62,\n",
      "        the measured value is 36, so the null hypothesis is rejected at the 1%\n",
      "        level.\n",
      "    \n",
      "    gamma(...) method of numpy.random.mtrand.RandomState instance\n",
      "        gamma(shape, scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a Gamma distribution.\n",
      "        \n",
      "        Samples are drawn from a Gamma distribution with specified parameters,\n",
      "        `shape` (sometimes designated \"k\") and `scale` (sometimes designated\n",
      "        \"theta\"), where both parameters are > 0.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``gamma`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : float or array_like of floats\n",
      "            The shape of the gamma distribution. Must be non-negative.\n",
      "        scale : float or array_like of floats, optional\n",
      "            The scale of the gamma distribution. Must be non-negative.\n",
      "            Default is equal to 1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``shape`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(shape, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized gamma distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.gamma : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.gamma: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Gamma distribution is\n",
      "        \n",
      "        .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "        \n",
      "        where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "        and :math:`\\Gamma` is the Gamma function.\n",
      "        \n",
      "        The Gamma distribution is often used to model the times to failure of\n",
      "        electronic components, and arises naturally in processes for which the\n",
      "        waiting times between Poisson distributed events are relevant.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "               Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/GammaDistribution.html\n",
      "        .. [2] Wikipedia, \"Gamma distribution\",\n",
      "               https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> shape, scale = 2., 2.  # mean=4, std=2*sqrt(2)\n",
      "        >>> s = np.random.gamma(shape, scale, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> import scipy.special as sps  # doctest: +SKIP\n",
      "        >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "        >>> y = bins**(shape-1)*(np.exp(-bins/scale) /  # doctest: +SKIP\n",
      "        ...                      (sps.gamma(shape)*scale**shape))\n",
      "        >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "        >>> plt.show()\n",
      "    \n",
      "    geometric(...) method of numpy.random.mtrand.RandomState instance\n",
      "        geometric(p, size=None)\n",
      "        \n",
      "        Draw samples from the geometric distribution.\n",
      "        \n",
      "        Bernoulli trials are experiments with one of two outcomes:\n",
      "        success or failure (an example of such an experiment is flipping\n",
      "        a coin).  The geometric distribution models the number of trials\n",
      "        that must be run in order to achieve success.  It is therefore\n",
      "        supported on the positive integers, ``k = 1, 2, ...``.\n",
      "        \n",
      "        The probability mass function of the geometric distribution is\n",
      "        \n",
      "        .. math:: f(k) = (1 - p)^{k - 1} p\n",
      "        \n",
      "        where `p` is the probability of success of an individual trial.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``geometric`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        p : float or array_like of floats\n",
      "            The probability of success of an individual trial.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "            ``np.array(p).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized geometric distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.geometric: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw ten thousand values from the geometric distribution,\n",
      "        with the probability of an individual success equal to 0.35:\n",
      "        \n",
      "        >>> z = np.random.geometric(p=0.35, size=10000)\n",
      "        \n",
      "        How many trials succeeded after a single run?\n",
      "        \n",
      "        >>> (z == 1).sum() / 10000.\n",
      "        0.34889999999999999 #random\n",
      "    \n",
      "    get_state(...) method of numpy.random.mtrand.RandomState instance\n",
      "        get_state()\n",
      "        \n",
      "        Return a tuple representing the internal state of the generator.\n",
      "        \n",
      "        For more details, see `set_state`.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : {tuple(str, ndarray of 624 uints, int, int, float), dict}\n",
      "            The returned tuple has the following items:\n",
      "        \n",
      "            1. the string 'MT19937'.\n",
      "            2. a 1-D array of 624 unsigned integer keys.\n",
      "            3. an integer ``pos``.\n",
      "            4. an integer ``has_gauss``.\n",
      "            5. a float ``cached_gaussian``.\n",
      "        \n",
      "            If `legacy` is False, or the BitGenerator is not NT19937, then\n",
      "            state is returned as a dictionary.\n",
      "        \n",
      "        legacy : bool\n",
      "            Flag indicating the return a legacy tuple state when the BitGenerator\n",
      "            is MT19937.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        set_state\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `set_state` and `get_state` are not needed to work with any of the\n",
      "        random distributions in NumPy. If the internal state is manually altered,\n",
      "        the user should know exactly what he/she is doing.\n",
      "    \n",
      "    gumbel(...) method of numpy.random.mtrand.RandomState instance\n",
      "        gumbel(loc=0.0, scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a Gumbel distribution.\n",
      "        \n",
      "        Draw samples from a Gumbel distribution with specified location and\n",
      "        scale.  For more information on the Gumbel distribution, see\n",
      "        Notes and References below.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``gumbel`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        loc : float or array_like of floats, optional\n",
      "            The location of the mode of the distribution. Default is 0.\n",
      "        scale : float or array_like of floats, optional\n",
      "            The scale parameter of the distribution. Default is 1. Must be non-\n",
      "            negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Gumbel distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.gumbel_l\n",
      "        scipy.stats.gumbel_r\n",
      "        scipy.stats.genextreme\n",
      "        weibull\n",
      "        Generator.gumbel: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Gumbel (or Smallest Extreme Value (SEV) or the Smallest Extreme\n",
      "        Value Type I) distribution is one of a class of Generalized Extreme\n",
      "        Value (GEV) distributions used in modeling extreme value problems.\n",
      "        The Gumbel is a special case of the Extreme Value Type I distribution\n",
      "        for maximums from distributions with \"exponential-like\" tails.\n",
      "        \n",
      "        The probability density for the Gumbel distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{e^{-(x - \\mu)/ \\beta}}{\\beta} e^{ -e^{-(x - \\mu)/\n",
      "                  \\beta}},\n",
      "        \n",
      "        where :math:`\\mu` is the mode, a location parameter, and\n",
      "        :math:`\\beta` is the scale parameter.\n",
      "        \n",
      "        The Gumbel (named for German mathematician Emil Julius Gumbel) was used\n",
      "        very early in the hydrology literature, for modeling the occurrence of\n",
      "        flood events. It is also used for modeling maximum wind speed and\n",
      "        rainfall rates.  It is a \"fat-tailed\" distribution - the probability of\n",
      "        an event in the tail of the distribution is larger than if one used a\n",
      "        Gaussian, hence the surprisingly frequent occurrence of 100-year\n",
      "        floods. Floods were initially modeled as a Gaussian process, which\n",
      "        underestimated the frequency of extreme events.\n",
      "        \n",
      "        It is one of a class of extreme value distributions, the Generalized\n",
      "        Extreme Value (GEV) distributions, which also includes the Weibull and\n",
      "        Frechet.\n",
      "        \n",
      "        The function has a mean of :math:`\\mu + 0.57721\\beta` and a variance\n",
      "        of :math:`\\frac{\\pi^2}{6}\\beta^2`.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Gumbel, E. J., \"Statistics of Extremes,\"\n",
      "               New York: Columbia University Press, 1958.\n",
      "        .. [2] Reiss, R.-D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "               Values from Insurance, Finance, Hydrology and Other Fields,\"\n",
      "               Basel: Birkhauser Verlag, 2001.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> mu, beta = 0, 0.1 # location and scale\n",
      "        >>> s = np.random.gumbel(mu, beta, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "        >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "        ...          * np.exp( -np.exp( -(bins - mu) /beta) ),\n",
      "        ...          linewidth=2, color='r')\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Show how an extreme value distribution can arise from a Gaussian process\n",
      "        and compare to a Gaussian:\n",
      "        \n",
      "        >>> means = []\n",
      "        >>> maxima = []\n",
      "        >>> for i in range(0,1000) :\n",
      "        ...    a = np.random.normal(mu, beta, 1000)\n",
      "        ...    means.append(a.mean())\n",
      "        ...    maxima.append(a.max())\n",
      "        >>> count, bins, ignored = plt.hist(maxima, 30, density=True)\n",
      "        >>> beta = np.std(maxima) * np.sqrt(6) / np.pi\n",
      "        >>> mu = np.mean(maxima) - 0.57721*beta\n",
      "        >>> plt.plot(bins, (1/beta)*np.exp(-(bins - mu)/beta)\n",
      "        ...          * np.exp(-np.exp(-(bins - mu)/beta)),\n",
      "        ...          linewidth=2, color='r')\n",
      "        >>> plt.plot(bins, 1/(beta * np.sqrt(2 * np.pi))\n",
      "        ...          * np.exp(-(bins - mu)**2 / (2 * beta**2)),\n",
      "        ...          linewidth=2, color='g')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    hypergeometric(...) method of numpy.random.mtrand.RandomState instance\n",
      "        hypergeometric(ngood, nbad, nsample, size=None)\n",
      "        \n",
      "        Draw samples from a Hypergeometric distribution.\n",
      "        \n",
      "        Samples are drawn from a hypergeometric distribution with specified\n",
      "        parameters, `ngood` (ways to make a good selection), `nbad` (ways to make\n",
      "        a bad selection), and `nsample` (number of items sampled, which is less\n",
      "        than or equal to the sum ``ngood + nbad``).\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``hypergeometric`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        ngood : int or array_like of ints\n",
      "            Number of ways to make a good selection.  Must be nonnegative.\n",
      "        nbad : int or array_like of ints\n",
      "            Number of ways to make a bad selection.  Must be nonnegative.\n",
      "        nsample : int or array_like of ints\n",
      "            Number of items sampled.  Must be at least 1 and at most\n",
      "            ``ngood + nbad``.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if `ngood`, `nbad`, and `nsample`\n",
      "            are all scalars.  Otherwise, ``np.broadcast(ngood, nbad, nsample).size``\n",
      "            samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized hypergeometric distribution. Each\n",
      "            sample is the number of good items within a randomly selected subset of\n",
      "            size `nsample` taken from a set of `ngood` good items and `nbad` bad items.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.hypergeom : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.hypergeometric: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Hypergeometric distribution is\n",
      "        \n",
      "        .. math:: P(x) = \\frac{\\binom{g}{x}\\binom{b}{n-x}}{\\binom{g+b}{n}},\n",
      "        \n",
      "        where :math:`0 \\le x \\le n` and :math:`n-b \\le x \\le g`\n",
      "        \n",
      "        for P(x) the probability of ``x`` good results in the drawn sample,\n",
      "        g = `ngood`, b = `nbad`, and n = `nsample`.\n",
      "        \n",
      "        Consider an urn with black and white marbles in it, `ngood` of them\n",
      "        are black and `nbad` are white. If you draw `nsample` balls without\n",
      "        replacement, then the hypergeometric distribution describes the\n",
      "        distribution of black balls in the drawn sample.\n",
      "        \n",
      "        Note that this distribution is very similar to the binomial\n",
      "        distribution, except that in this case, samples are drawn without\n",
      "        replacement, whereas in the Binomial case samples are drawn with\n",
      "        replacement (or the sample space is infinite). As the sample space\n",
      "        becomes large, this distribution approaches the binomial.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Lentner, Marvin, \"Elementary Applied Statistics\", Bogden\n",
      "               and Quigley, 1972.\n",
      "        .. [2] Weisstein, Eric W. \"Hypergeometric Distribution.\" From\n",
      "               MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/HypergeometricDistribution.html\n",
      "        .. [3] Wikipedia, \"Hypergeometric distribution\",\n",
      "               https://en.wikipedia.org/wiki/Hypergeometric_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> ngood, nbad, nsamp = 100, 2, 10\n",
      "        # number of good, number of bad, and number of samples\n",
      "        >>> s = np.random.hypergeometric(ngood, nbad, nsamp, 1000)\n",
      "        >>> from matplotlib.pyplot import hist\n",
      "        >>> hist(s)\n",
      "        #   note that it is very unlikely to grab both bad items\n",
      "        \n",
      "        Suppose you have an urn with 15 white and 15 black marbles.\n",
      "        If you pull 15 marbles at random, how likely is it that\n",
      "        12 or more of them are one color?\n",
      "        \n",
      "        >>> s = np.random.hypergeometric(15, 15, 15, 100000)\n",
      "        >>> sum(s>=12)/100000. + sum(s<=3)/100000.\n",
      "        #   answer = 0.003 ... pretty unlikely!\n",
      "    \n",
      "    laplace(...) method of numpy.random.mtrand.RandomState instance\n",
      "        laplace(loc=0.0, scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from the Laplace or double exponential distribution with\n",
      "        specified location (or mean) and scale (decay).\n",
      "        \n",
      "        The Laplace distribution is similar to the Gaussian/normal distribution,\n",
      "        but is sharper at the peak and has fatter tails. It represents the\n",
      "        difference between two independent, identically distributed exponential\n",
      "        random variables.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``laplace`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        loc : float or array_like of floats, optional\n",
      "            The position, :math:`\\mu`, of the distribution peak. Default is 0.\n",
      "        scale : float or array_like of floats, optional\n",
      "            :math:`\\lambda`, the exponential decay. Default is 1. Must be non-\n",
      "            negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Laplace distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.laplace: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        It has the probability density function\n",
      "        \n",
      "        .. math:: f(x; \\mu, \\lambda) = \\frac{1}{2\\lambda}\n",
      "                                       \\exp\\left(-\\frac{|x - \\mu|}{\\lambda}\\right).\n",
      "        \n",
      "        The first law of Laplace, from 1774, states that the frequency\n",
      "        of an error can be expressed as an exponential function of the\n",
      "        absolute magnitude of the error, which leads to the Laplace\n",
      "        distribution. For many problems in economics and health\n",
      "        sciences, this distribution seems to model the data better\n",
      "        than the standard Gaussian distribution.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "               Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "               Tables, 9th printing,\" New York: Dover, 1972.\n",
      "        .. [2] Kotz, Samuel, et. al. \"The Laplace Distribution and\n",
      "               Generalizations, \" Birkhauser, 2001.\n",
      "        .. [3] Weisstein, Eric W. \"Laplace Distribution.\"\n",
      "               From MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/LaplaceDistribution.html\n",
      "        .. [4] Wikipedia, \"Laplace distribution\",\n",
      "               https://en.wikipedia.org/wiki/Laplace_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution\n",
      "        \n",
      "        >>> loc, scale = 0., 1.\n",
      "        >>> s = np.random.laplace(loc, scale, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "        >>> x = np.arange(-8., 8., .01)\n",
      "        >>> pdf = np.exp(-abs(x-loc)/scale)/(2.*scale)\n",
      "        >>> plt.plot(x, pdf)\n",
      "        \n",
      "        Plot Gaussian for comparison:\n",
      "        \n",
      "        >>> g = (1/(scale * np.sqrt(2 * np.pi)) *\n",
      "        ...      np.exp(-(x - loc)**2 / (2 * scale**2)))\n",
      "        >>> plt.plot(x,g)\n",
      "    \n",
      "    logistic(...) method of numpy.random.mtrand.RandomState instance\n",
      "        logistic(loc=0.0, scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a logistic distribution.\n",
      "        \n",
      "        Samples are drawn from a logistic distribution with specified\n",
      "        parameters, loc (location or mean, also median), and scale (>0).\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``logistic`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        loc : float or array_like of floats, optional\n",
      "            Parameter of the distribution. Default is 0.\n",
      "        scale : float or array_like of floats, optional\n",
      "            Parameter of the distribution. Must be non-negative.\n",
      "            Default is 1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized logistic distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.logistic : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.logistic: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Logistic distribution is\n",
      "        \n",
      "        .. math:: P(x) = P(x) = \\frac{e^{-(x-\\mu)/s}}{s(1+e^{-(x-\\mu)/s})^2},\n",
      "        \n",
      "        where :math:`\\mu` = location and :math:`s` = scale.\n",
      "        \n",
      "        The Logistic distribution is used in Extreme Value problems where it\n",
      "        can act as a mixture of Gumbel distributions, in Epidemiology, and by\n",
      "        the World Chess Federation (FIDE) where it is used in the Elo ranking\n",
      "        system, assuming the performance of each player is a logistically\n",
      "        distributed random variable.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Reiss, R.-D. and Thomas M. (2001), \"Statistical Analysis of\n",
      "               Extreme Values, from Insurance, Finance, Hydrology and Other\n",
      "               Fields,\" Birkhauser Verlag, Basel, pp 132-133.\n",
      "        .. [2] Weisstein, Eric W. \"Logistic Distribution.\" From\n",
      "               MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/LogisticDistribution.html\n",
      "        .. [3] Wikipedia, \"Logistic-distribution\",\n",
      "               https://en.wikipedia.org/wiki/Logistic_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> loc, scale = 10, 1\n",
      "        >>> s = np.random.logistic(loc, scale, 10000)\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, bins=50)\n",
      "        \n",
      "        #   plot against distribution\n",
      "        \n",
      "        >>> def logist(x, loc, scale):\n",
      "        ...     return np.exp((loc-x)/scale)/(scale*(1+np.exp((loc-x)/scale))**2)\n",
      "        >>> lgst_val = logist(bins, loc, scale)\n",
      "        >>> plt.plot(bins, lgst_val * count.max() / lgst_val.max())\n",
      "        >>> plt.show()\n",
      "    \n",
      "    lognormal(...) method of numpy.random.mtrand.RandomState instance\n",
      "        lognormal(mean=0.0, sigma=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a log-normal distribution.\n",
      "        \n",
      "        Draw samples from a log-normal distribution with specified mean,\n",
      "        standard deviation, and array shape.  Note that the mean and standard\n",
      "        deviation are not the values for the distribution itself, but of the\n",
      "        underlying normal distribution it is derived from.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``lognormal`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : float or array_like of floats, optional\n",
      "            Mean value of the underlying normal distribution. Default is 0.\n",
      "        sigma : float or array_like of floats, optional\n",
      "            Standard deviation of the underlying normal distribution. Must be\n",
      "            non-negative. Default is 1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``mean`` and ``sigma`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(mean, sigma).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized log-normal distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.lognorm : probability density function, distribution,\n",
      "            cumulative density function, etc.\n",
      "        Generator.lognormal: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        A variable `x` has a log-normal distribution if `log(x)` is normally\n",
      "        distributed.  The probability density function for the log-normal\n",
      "        distribution is:\n",
      "        \n",
      "        .. math:: p(x) = \\frac{1}{\\sigma x \\sqrt{2\\pi}}\n",
      "                         e^{(-\\frac{(ln(x)-\\mu)^2}{2\\sigma^2})}\n",
      "        \n",
      "        where :math:`\\mu` is the mean and :math:`\\sigma` is the standard\n",
      "        deviation of the normally distributed logarithm of the variable.\n",
      "        A log-normal distribution results if a random variable is the *product*\n",
      "        of a large number of independent, identically-distributed variables in\n",
      "        the same way that a normal distribution results if the variable is the\n",
      "        *sum* of a large number of independent, identically-distributed\n",
      "        variables.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Limpert, E., Stahel, W. A., and Abbt, M., \"Log-normal\n",
      "               Distributions across the Sciences: Keys and Clues,\"\n",
      "               BioScience, Vol. 51, No. 5, May, 2001.\n",
      "               https://stat.ethz.ch/~stahel/lognormal/bioscience.pdf\n",
      "        .. [2] Reiss, R.D. and Thomas, M., \"Statistical Analysis of Extreme\n",
      "               Values,\" Basel: Birkhauser Verlag, 2001, pp. 31-32.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> mu, sigma = 3., 1. # mean and standard deviation\n",
      "        >>> s = np.random.lognormal(mu, sigma, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 100, density=True, align='mid')\n",
      "        \n",
      "        >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "        >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "        ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "        \n",
      "        >>> plt.plot(x, pdf, linewidth=2, color='r')\n",
      "        >>> plt.axis('tight')\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Demonstrate that taking the products of random samples from a uniform\n",
      "        distribution can be fit well by a log-normal probability density\n",
      "        function.\n",
      "        \n",
      "        >>> # Generate a thousand samples: each is the product of 100 random\n",
      "        >>> # values, drawn from a normal distribution.\n",
      "        >>> b = []\n",
      "        >>> for i in range(1000):\n",
      "        ...    a = 10. + np.random.standard_normal(100)\n",
      "        ...    b.append(np.product(a))\n",
      "        \n",
      "        >>> b = np.array(b) / np.min(b) # scale values to be positive\n",
      "        >>> count, bins, ignored = plt.hist(b, 100, density=True, align='mid')\n",
      "        >>> sigma = np.std(np.log(b))\n",
      "        >>> mu = np.mean(np.log(b))\n",
      "        \n",
      "        >>> x = np.linspace(min(bins), max(bins), 10000)\n",
      "        >>> pdf = (np.exp(-(np.log(x) - mu)**2 / (2 * sigma**2))\n",
      "        ...        / (x * sigma * np.sqrt(2 * np.pi)))\n",
      "        \n",
      "        >>> plt.plot(x, pdf, color='r', linewidth=2)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    logseries(...) method of numpy.random.mtrand.RandomState instance\n",
      "        logseries(p, size=None)\n",
      "        \n",
      "        Draw samples from a logarithmic series distribution.\n",
      "        \n",
      "        Samples are drawn from a log series distribution with specified\n",
      "        shape parameter, 0 < ``p`` < 1.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``logseries`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        p : float or array_like of floats\n",
      "            Shape parameter for the distribution.  Must be in the range (0, 1).\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``p`` is a scalar.  Otherwise,\n",
      "            ``np.array(p).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized logarithmic series distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.logser : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.logseries: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Log Series distribution is\n",
      "        \n",
      "        .. math:: P(k) = \\frac{-p^k}{k \\ln(1-p)},\n",
      "        \n",
      "        where p = probability.\n",
      "        \n",
      "        The log series distribution is frequently used to represent species\n",
      "        richness and occurrence, first proposed by Fisher, Corbet, and\n",
      "        Williams in 1943 [2].  It may also be used to model the numbers of\n",
      "        occupants seen in cars [3].\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Buzas, Martin A.; Culver, Stephen J.,  Understanding regional\n",
      "               species diversity through the log series distribution of\n",
      "               occurrences: BIODIVERSITY RESEARCH Diversity & Distributions,\n",
      "               Volume 5, Number 5, September 1999 , pp. 187-195(9).\n",
      "        .. [2] Fisher, R.A,, A.S. Corbet, and C.B. Williams. 1943. The\n",
      "               relation between the number of species and the number of\n",
      "               individuals in a random sample of an animal population.\n",
      "               Journal of Animal Ecology, 12:42-58.\n",
      "        .. [3] D. J. Hand, F. Daly, D. Lunn, E. Ostrowski, A Handbook of Small\n",
      "               Data Sets, CRC Press, 1994.\n",
      "        .. [4] Wikipedia, \"Logarithmic distribution\",\n",
      "               https://en.wikipedia.org/wiki/Logarithmic_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> a = .6\n",
      "        >>> s = np.random.logseries(a, 10000)\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s)\n",
      "        \n",
      "        #   plot against distribution\n",
      "        \n",
      "        >>> def logseries(k, p):\n",
      "        ...     return -p**k/(k*np.log(1-p))\n",
      "        >>> plt.plot(bins, logseries(bins, a)*count.max()/\n",
      "        ...          logseries(bins, a).max(), 'r')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    multinomial(...) method of numpy.random.mtrand.RandomState instance\n",
      "        multinomial(n, pvals, size=None)\n",
      "        \n",
      "        Draw samples from a multinomial distribution.\n",
      "        \n",
      "        The multinomial distribution is a multivariate generalization of the\n",
      "        binomial distribution.  Take an experiment with one of ``p``\n",
      "        possible outcomes.  An example of such an experiment is throwing a dice,\n",
      "        where the outcome can be 1 through 6.  Each sample drawn from the\n",
      "        distribution represents `n` such experiments.  Its values,\n",
      "        ``X_i = [X_0, X_1, ..., X_p]``, represent the number of times the\n",
      "        outcome was ``i``.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``multinomial`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n : int\n",
      "            Number of experiments.\n",
      "        pvals : sequence of floats, length p\n",
      "            Probabilities of each of the ``p`` different outcomes.  These\n",
      "            must sum to 1 (however, the last element is always assumed to\n",
      "            account for the remaining probability, as long as\n",
      "            ``sum(pvals[:-1]) <= 1)``.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "            the shape is ``(N,)``.\n",
      "        \n",
      "            In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "            value drawn from the distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.multinomial: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Throw a dice 20 times:\n",
      "        \n",
      "        >>> np.random.multinomial(20, [1/6.]*6, size=1)\n",
      "        array([[4, 1, 7, 5, 2, 1]]) # random\n",
      "        \n",
      "        It landed 4 times on 1, once on 2, etc.\n",
      "        \n",
      "        Now, throw the dice 20 times, and 20 times again:\n",
      "        \n",
      "        >>> np.random.multinomial(20, [1/6.]*6, size=2)\n",
      "        array([[3, 4, 3, 3, 4, 3], # random\n",
      "               [2, 4, 3, 4, 0, 7]])\n",
      "        \n",
      "        For the first run, we threw 3 times 1, 4 times 2, etc.  For the second,\n",
      "        we threw 2 times 1, 4 times 2, etc.\n",
      "        \n",
      "        A loaded die is more likely to land on number 6:\n",
      "        \n",
      "        >>> np.random.multinomial(100, [1/7.]*5 + [2/7.])\n",
      "        array([11, 16, 14, 17, 16, 26]) # random\n",
      "        \n",
      "        The probability inputs should be normalized. As an implementation\n",
      "        detail, the value of the last entry is ignored and assumed to take\n",
      "        up any leftover probability mass, but this should not be relied on.\n",
      "        A biased coin which has twice as much weight on one side as on the\n",
      "        other should be sampled like so:\n",
      "        \n",
      "        >>> np.random.multinomial(100, [1.0 / 3, 2.0 / 3])  # RIGHT\n",
      "        array([38, 62]) # random\n",
      "        \n",
      "        not like:\n",
      "        \n",
      "        >>> np.random.multinomial(100, [1.0, 2.0])  # WRONG\n",
      "        Traceback (most recent call last):\n",
      "        ValueError: pvals < 0, pvals > 1 or pvals contains NaNs\n",
      "    \n",
      "    multivariate_normal(...) method of numpy.random.mtrand.RandomState instance\n",
      "        multivariate_normal(mean, cov, size=None, check_valid='warn', tol=1e-8)\n",
      "        \n",
      "        Draw random samples from a multivariate normal distribution.\n",
      "        \n",
      "        The multivariate normal, multinormal or Gaussian distribution is a\n",
      "        generalization of the one-dimensional normal distribution to higher\n",
      "        dimensions.  Such a distribution is specified by its mean and\n",
      "        covariance matrix.  These parameters are analogous to the mean\n",
      "        (average or \"center\") and variance (standard deviation, or \"width,\"\n",
      "        squared) of the one-dimensional normal distribution.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``multivariate_normal`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : 1-D array_like, of length N\n",
      "            Mean of the N-dimensional distribution.\n",
      "        cov : 2-D array_like, of shape (N, N)\n",
      "            Covariance matrix of the distribution. It must be symmetric and\n",
      "            positive-semidefinite for proper sampling.\n",
      "        size : int or tuple of ints, optional\n",
      "            Given a shape of, for example, ``(m,n,k)``, ``m*n*k`` samples are\n",
      "            generated, and packed in an `m`-by-`n`-by-`k` arrangement.  Because\n",
      "            each sample is `N`-dimensional, the output shape is ``(m,n,k,N)``.\n",
      "            If no shape is specified, a single (`N`-D) sample is returned.\n",
      "        check_valid : { 'warn', 'raise', 'ignore' }, optional\n",
      "            Behavior when the covariance matrix is not positive semidefinite.\n",
      "        tol : float, optional\n",
      "            Tolerance when checking the singular values in covariance matrix.\n",
      "            cov is cast to double before the check.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            The drawn samples, of shape *size*, if that was provided.  If not,\n",
      "            the shape is ``(N,)``.\n",
      "        \n",
      "            In other words, each entry ``out[i,j,...,:]`` is an N-dimensional\n",
      "            value drawn from the distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.multivariate_normal: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The mean is a coordinate in N-dimensional space, which represents the\n",
      "        location where samples are most likely to be generated.  This is\n",
      "        analogous to the peak of the bell curve for the one-dimensional or\n",
      "        univariate normal distribution.\n",
      "        \n",
      "        Covariance indicates the level to which two variables vary together.\n",
      "        From the multivariate normal distribution, we draw N-dimensional\n",
      "        samples, :math:`X = [x_1, x_2, ... x_N]`.  The covariance matrix\n",
      "        element :math:`C_{ij}` is the covariance of :math:`x_i` and :math:`x_j`.\n",
      "        The element :math:`C_{ii}` is the variance of :math:`x_i` (i.e. its\n",
      "        \"spread\").\n",
      "        \n",
      "        Instead of specifying the full covariance matrix, popular\n",
      "        approximations include:\n",
      "        \n",
      "          - Spherical covariance (`cov` is a multiple of the identity matrix)\n",
      "          - Diagonal covariance (`cov` has non-negative elements, and only on\n",
      "            the diagonal)\n",
      "        \n",
      "        This geometrical property can be seen in two dimensions by plotting\n",
      "        generated data-points:\n",
      "        \n",
      "        >>> mean = [0, 0]\n",
      "        >>> cov = [[1, 0], [0, 100]]  # diagonal covariance\n",
      "        \n",
      "        Diagonal covariance means that points are oriented along x or y-axis:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> x, y = np.random.multivariate_normal(mean, cov, 5000).T\n",
      "        >>> plt.plot(x, y, 'x')\n",
      "        >>> plt.axis('equal')\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Note that the covariance matrix must be positive semidefinite (a.k.a.\n",
      "        nonnegative-definite). Otherwise, the behavior of this method is\n",
      "        undefined and backwards compatibility is not guaranteed.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Papoulis, A., \"Probability, Random Variables, and Stochastic\n",
      "               Processes,\" 3rd ed., New York: McGraw-Hill, 1991.\n",
      "        .. [2] Duda, R. O., Hart, P. E., and Stork, D. G., \"Pattern\n",
      "               Classification,\" 2nd ed., New York: Wiley, 2001.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> mean = (1, 2)\n",
      "        >>> cov = [[1, 0], [0, 1]]\n",
      "        >>> x = np.random.multivariate_normal(mean, cov, (3, 3))\n",
      "        >>> x.shape\n",
      "        (3, 3, 2)\n",
      "        \n",
      "        The following is probably true, given that 0.6 is roughly twice the\n",
      "        standard deviation:\n",
      "        \n",
      "        >>> list((x[0,0,:] - mean) < 0.6)\n",
      "        [True, True] # random\n",
      "    \n",
      "    negative_binomial(...) method of numpy.random.mtrand.RandomState instance\n",
      "        negative_binomial(n, p, size=None)\n",
      "        \n",
      "        Draw samples from a negative binomial distribution.\n",
      "        \n",
      "        Samples are drawn from a negative binomial distribution with specified\n",
      "        parameters, `n` successes and `p` probability of success where `n`\n",
      "        is > 0 and `p` is in the interval [0, 1].\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``negative_binomial`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        n : float or array_like of floats\n",
      "            Parameter of the distribution, > 0.\n",
      "        p : float or array_like of floats\n",
      "            Parameter of the distribution, >= 0 and <=1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``n`` and ``p`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(n, p).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized negative binomial distribution,\n",
      "            where each sample is equal to N, the number of failures that\n",
      "            occurred before a total of n successes was reached.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.negative_binomial: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability mass function of the negative binomial distribution is\n",
      "        \n",
      "        .. math:: P(N;n,p) = \\frac{\\Gamma(N+n)}{N!\\Gamma(n)}p^{n}(1-p)^{N},\n",
      "        \n",
      "        where :math:`n` is the number of successes, :math:`p` is the\n",
      "        probability of success, :math:`N+n` is the number of trials, and\n",
      "        :math:`\\Gamma` is the gamma function. When :math:`n` is an integer,\n",
      "        :math:`\\frac{\\Gamma(N+n)}{N!\\Gamma(n)} = \\binom{N+n-1}{N}`, which is\n",
      "        the more common form of this term in the the pmf. The negative\n",
      "        binomial distribution gives the probability of N failures given n\n",
      "        successes, with a success on the last trial.\n",
      "        \n",
      "        If one throws a die repeatedly until the third time a \"1\" appears,\n",
      "        then the probability distribution of the number of non-\"1\"s that\n",
      "        appear before the third \"1\" is a negative binomial distribution.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Weisstein, Eric W. \"Negative Binomial Distribution.\" From\n",
      "               MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/NegativeBinomialDistribution.html\n",
      "        .. [2] Wikipedia, \"Negative binomial distribution\",\n",
      "               https://en.wikipedia.org/wiki/Negative_binomial_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        A real world example. A company drills wild-cat oil\n",
      "        exploration wells, each with an estimated probability of\n",
      "        success of 0.1.  What is the probability of having one success\n",
      "        for each successive well, that is what is the probability of a\n",
      "        single success after drilling 5 wells, after 6 wells, etc.?\n",
      "        \n",
      "        >>> s = np.random.negative_binomial(1, 0.1, 100000)\n",
      "        >>> for i in range(1, 11): # doctest: +SKIP\n",
      "        ...    probability = sum(s<i) / 100000.\n",
      "        ...    print(i, \"wells drilled, probability of one success =\", probability)\n",
      "    \n",
      "    noncentral_chisquare(...) method of numpy.random.mtrand.RandomState instance\n",
      "        noncentral_chisquare(df, nonc, size=None)\n",
      "        \n",
      "        Draw samples from a noncentral chi-square distribution.\n",
      "        \n",
      "        The noncentral :math:`\\chi^2` distribution is a generalization of\n",
      "        the :math:`\\chi^2` distribution.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``noncentral_chisquare`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        df : float or array_like of floats\n",
      "            Degrees of freedom, must be > 0.\n",
      "        \n",
      "            .. versionchanged:: 1.10.0\n",
      "               Earlier NumPy versions required dfnum > 1.\n",
      "        nonc : float or array_like of floats\n",
      "            Non-centrality, must be non-negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``df`` and ``nonc`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(df, nonc).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized noncentral chi-square distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.noncentral_chisquare: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the noncentral Chi-square\n",
      "        distribution is\n",
      "        \n",
      "        .. math:: P(x;df,nonc) = \\sum^{\\infty}_{i=0}\n",
      "                               \\frac{e^{-nonc/2}(nonc/2)^{i}}{i!}\n",
      "                               P_{Y_{df+2i}}(x),\n",
      "        \n",
      "        where :math:`Y_{q}` is the Chi-square with q degrees of freedom.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Wikipedia, \"Noncentral chi-squared distribution\"\n",
      "               https://en.wikipedia.org/wiki/Noncentral_chi-squared_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw values from the distribution and plot the histogram\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      "        ...                   bins=200, density=True)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Draw values from a noncentral chisquare with very small noncentrality,\n",
      "        and compare to a chisquare.\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> values = plt.hist(np.random.noncentral_chisquare(3, .0000001, 100000),\n",
      "        ...                   bins=np.arange(0., 25, .1), density=True)\n",
      "        >>> values2 = plt.hist(np.random.chisquare(3, 100000),\n",
      "        ...                    bins=np.arange(0., 25, .1), density=True)\n",
      "        >>> plt.plot(values[1][0:-1], values[0]-values2[0], 'ob')\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Demonstrate how large values of non-centrality lead to a more symmetric\n",
      "        distribution.\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> values = plt.hist(np.random.noncentral_chisquare(3, 20, 100000),\n",
      "        ...                   bins=200, density=True)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    noncentral_f(...) method of numpy.random.mtrand.RandomState instance\n",
      "        noncentral_f(dfnum, dfden, nonc, size=None)\n",
      "        \n",
      "        Draw samples from the noncentral F distribution.\n",
      "        \n",
      "        Samples are drawn from an F distribution with specified parameters,\n",
      "        `dfnum` (degrees of freedom in numerator) and `dfden` (degrees of\n",
      "        freedom in denominator), where both parameters > 1.\n",
      "        `nonc` is the non-centrality parameter.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``noncentral_f`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        dfnum : float or array_like of floats\n",
      "            Numerator degrees of freedom, must be > 0.\n",
      "        \n",
      "            .. versionchanged:: 1.14.0\n",
      "               Earlier NumPy versions required dfnum > 1.\n",
      "        dfden : float or array_like of floats\n",
      "            Denominator degrees of freedom, must be > 0.\n",
      "        nonc : float or array_like of floats\n",
      "            Non-centrality parameter, the sum of the squares of the numerator\n",
      "            means, must be >= 0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``dfnum``, ``dfden``, and ``nonc``\n",
      "            are all scalars.  Otherwise, ``np.broadcast(dfnum, dfden, nonc).size``\n",
      "            samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized noncentral Fisher distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.noncentral_f: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        When calculating the power of an experiment (power = probability of\n",
      "        rejecting the null hypothesis when a specific alternative is true) the\n",
      "        non-central F statistic becomes important.  When the null hypothesis is\n",
      "        true, the F statistic follows a central F distribution. When the null\n",
      "        hypothesis is not true, then it follows a non-central F statistic.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Weisstein, Eric W. \"Noncentral F-Distribution.\"\n",
      "               From MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/NoncentralF-Distribution.html\n",
      "        .. [2] Wikipedia, \"Noncentral F-distribution\",\n",
      "               https://en.wikipedia.org/wiki/Noncentral_F-distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        In a study, testing for a specific alternative to the null hypothesis\n",
      "        requires use of the Noncentral F distribution. We need to calculate the\n",
      "        area in the tail of the distribution that exceeds the value of the F\n",
      "        distribution for the null hypothesis.  We'll plot the two probability\n",
      "        distributions for comparison.\n",
      "        \n",
      "        >>> dfnum = 3 # between group deg of freedom\n",
      "        >>> dfden = 20 # within groups degrees of freedom\n",
      "        >>> nonc = 3.0\n",
      "        >>> nc_vals = np.random.noncentral_f(dfnum, dfden, nonc, 1000000)\n",
      "        >>> NF = np.histogram(nc_vals, bins=50, density=True)\n",
      "        >>> c_vals = np.random.f(dfnum, dfden, 1000000)\n",
      "        >>> F = np.histogram(c_vals, bins=50, density=True)\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> plt.plot(F[1][1:], F[0])\n",
      "        >>> plt.plot(NF[1][1:], NF[0])\n",
      "        >>> plt.show()\n",
      "    \n",
      "    normal(...) method of numpy.random.mtrand.RandomState instance\n",
      "        normal(loc=0.0, scale=1.0, size=None)\n",
      "        \n",
      "        Draw random samples from a normal (Gaussian) distribution.\n",
      "        \n",
      "        The probability density function of the normal distribution, first\n",
      "        derived by De Moivre and 200 years later by both Gauss and Laplace\n",
      "        independently [2]_, is often called the bell curve because of\n",
      "        its characteristic shape (see the example below).\n",
      "        \n",
      "        The normal distributions occurs often in nature.  For example, it\n",
      "        describes the commonly occurring distribution of samples influenced\n",
      "        by a large number of tiny, random disturbances, each with its own\n",
      "        unique distribution [2]_.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``normal`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        loc : float or array_like of floats\n",
      "            Mean (\"centre\") of the distribution.\n",
      "        scale : float or array_like of floats\n",
      "            Standard deviation (spread or \"width\") of the distribution. Must be\n",
      "            non-negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``loc`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(loc, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized normal distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.norm : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.normal: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Gaussian distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{1}{\\sqrt{ 2 \\pi \\sigma^2 }}\n",
      "                         e^{ - \\frac{ (x - \\mu)^2 } {2 \\sigma^2} },\n",
      "        \n",
      "        where :math:`\\mu` is the mean and :math:`\\sigma` the standard\n",
      "        deviation. The square of the standard deviation, :math:`\\sigma^2`,\n",
      "        is called the variance.\n",
      "        \n",
      "        The function has its peak at the mean, and its \"spread\" increases with\n",
      "        the standard deviation (the function reaches 0.607 times its maximum at\n",
      "        :math:`x + \\sigma` and :math:`x - \\sigma` [2]_).  This implies that\n",
      "        normal is more likely to return samples lying close to the mean, rather\n",
      "        than those far away.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Wikipedia, \"Normal distribution\",\n",
      "               https://en.wikipedia.org/wiki/Normal_distribution\n",
      "        .. [2] P. R. Peebles Jr., \"Central Limit Theorem\" in \"Probability,\n",
      "               Random Variables and Random Signal Principles\", 4th ed., 2001,\n",
      "               pp. 51, 51, 125.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> mu, sigma = 0, 0.1 # mean and standard deviation\n",
      "        >>> s = np.random.normal(mu, sigma, 1000)\n",
      "        \n",
      "        Verify the mean and the variance:\n",
      "        \n",
      "        >>> abs(mu - np.mean(s))\n",
      "        0.0  # may vary\n",
      "        \n",
      "        >>> abs(sigma - np.std(s, ddof=1))\n",
      "        0.1  # may vary\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 30, density=True)\n",
      "        >>> plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *\n",
      "        ...                np.exp( - (bins - mu)**2 / (2 * sigma**2) ),\n",
      "        ...          linewidth=2, color='r')\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Two-by-four array of samples from N(3, 6.25):\n",
      "        \n",
      "        >>> np.random.normal(3, 2.5, size=(2, 4))\n",
      "        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "    \n",
      "    pareto(...) method of numpy.random.mtrand.RandomState instance\n",
      "        pareto(a, size=None)\n",
      "        \n",
      "        Draw samples from a Pareto II or Lomax distribution with\n",
      "        specified shape.\n",
      "        \n",
      "        The Lomax or Pareto II distribution is a shifted Pareto\n",
      "        distribution. The classical Pareto distribution can be\n",
      "        obtained from the Lomax distribution by adding 1 and\n",
      "        multiplying by the scale parameter ``m`` (see Notes).  The\n",
      "        smallest value of the Lomax distribution is zero while for the\n",
      "        classical Pareto distribution it is ``mu``, where the standard\n",
      "        Pareto distribution has location ``mu = 1``.  Lomax can also\n",
      "        be considered as a simplified version of the Generalized\n",
      "        Pareto distribution (available in SciPy), with the scale set\n",
      "        to one and the location set to zero.\n",
      "        \n",
      "        The Pareto distribution must be greater than zero, and is\n",
      "        unbounded above.  It is also known as the \"80-20 rule\".  In\n",
      "        this distribution, 80 percent of the weights are in the lowest\n",
      "        20 percent of the range, while the other 20 percent fill the\n",
      "        remaining 80 percent of the range.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``pareto`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : float or array_like of floats\n",
      "            Shape of the distribution. Must be positive.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "            ``np.array(a).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Pareto distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.lomax : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        scipy.stats.genpareto : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.pareto: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Pareto distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{am^a}{x^{a+1}}\n",
      "        \n",
      "        where :math:`a` is the shape and :math:`m` the scale.\n",
      "        \n",
      "        The Pareto distribution, named after the Italian economist\n",
      "        Vilfredo Pareto, is a power law probability distribution\n",
      "        useful in many real world problems.  Outside the field of\n",
      "        economics it is generally referred to as the Bradford\n",
      "        distribution. Pareto developed the distribution to describe\n",
      "        the distribution of wealth in an economy.  It has also found\n",
      "        use in insurance, web page access statistics, oil field sizes,\n",
      "        and many other problems, including the download frequency for\n",
      "        projects in Sourceforge [1]_.  It is one of the so-called\n",
      "        \"fat-tailed\" distributions.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Francis Hunt and Paul Johnson, On the Pareto Distribution of\n",
      "               Sourceforge projects.\n",
      "        .. [2] Pareto, V. (1896). Course of Political Economy. Lausanne.\n",
      "        .. [3] Reiss, R.D., Thomas, M.(2001), Statistical Analysis of Extreme\n",
      "               Values, Birkhauser Verlag, Basel, pp 23-30.\n",
      "        .. [4] Wikipedia, \"Pareto distribution\",\n",
      "               https://en.wikipedia.org/wiki/Pareto_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> a, m = 3., 2.  # shape and mode\n",
      "        >>> s = (np.random.pareto(a, 1000) + 1) * m\n",
      "        \n",
      "        Display the histogram of the samples, along with the probability\n",
      "        density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, _ = plt.hist(s, 100, density=True)\n",
      "        >>> fit = a*m**a / bins**(a+1)\n",
      "        >>> plt.plot(bins, max(count)*fit/max(fit), linewidth=2, color='r')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    permutation(...) method of numpy.random.mtrand.RandomState instance\n",
      "        permutation(x)\n",
      "        \n",
      "        Randomly permute a sequence, or return a permuted range.\n",
      "        \n",
      "        If `x` is a multi-dimensional array, it is only shuffled along its\n",
      "        first index.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``permutation`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : int or array_like\n",
      "            If `x` is an integer, randomly permute ``np.arange(x)``.\n",
      "            If `x` is an array, make a copy and shuffle the elements\n",
      "            randomly.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray\n",
      "            Permuted sequence or array range.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.permutation: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.permutation(10)\n",
      "        array([1, 7, 4, 3, 0, 9, 2, 5, 8, 6]) # random\n",
      "        \n",
      "        >>> np.random.permutation([1, 4, 9, 12, 15])\n",
      "        array([15,  1,  9,  4, 12]) # random\n",
      "        \n",
      "        >>> arr = np.arange(9).reshape((3, 3))\n",
      "        >>> np.random.permutation(arr)\n",
      "        array([[6, 7, 8], # random\n",
      "               [0, 1, 2],\n",
      "               [3, 4, 5]])\n",
      "    \n",
      "    poisson(...) method of numpy.random.mtrand.RandomState instance\n",
      "        poisson(lam=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a Poisson distribution.\n",
      "        \n",
      "        The Poisson distribution is the limit of the binomial distribution\n",
      "        for large N.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``poisson`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        lam : float or array_like of floats\n",
      "            Expectation of interval, must be >= 0. A sequence of expectation\n",
      "            intervals must be broadcastable over the requested size.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``lam`` is a scalar. Otherwise,\n",
      "            ``np.array(lam).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Poisson distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.poisson: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Poisson distribution\n",
      "        \n",
      "        .. math:: f(k; \\lambda)=\\frac{\\lambda^k e^{-\\lambda}}{k!}\n",
      "        \n",
      "        For events with an expected separation :math:`\\lambda` the Poisson\n",
      "        distribution :math:`f(k; \\lambda)` describes the probability of\n",
      "        :math:`k` events occurring within the observed\n",
      "        interval :math:`\\lambda`.\n",
      "        \n",
      "        Because the output is limited to the range of the C int64 type, a\n",
      "        ValueError is raised when `lam` is within 10 sigma of the maximum\n",
      "        representable value.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Weisstein, Eric W. \"Poisson Distribution.\"\n",
      "               From MathWorld--A Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/PoissonDistribution.html\n",
      "        .. [2] Wikipedia, \"Poisson distribution\",\n",
      "               https://en.wikipedia.org/wiki/Poisson_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> import numpy as np\n",
      "        >>> s = np.random.poisson(5, 10000)\n",
      "        \n",
      "        Display histogram of the sample:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 14, density=True)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Draw each 100 values for lambda 100 and 500:\n",
      "        \n",
      "        >>> s = np.random.poisson(lam=(100., 500.), size=(100, 2))\n",
      "    \n",
      "    power(...) method of numpy.random.mtrand.RandomState instance\n",
      "        power(a, size=None)\n",
      "        \n",
      "        Draws samples in [0, 1] from a power distribution with positive\n",
      "        exponent a - 1.\n",
      "        \n",
      "        Also known as the power function distribution.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``power`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : float or array_like of floats\n",
      "            Parameter of the distribution. Must be non-negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "            ``np.array(a).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized power distribution.\n",
      "        \n",
      "        Raises\n",
      "        ------\n",
      "        ValueError\n",
      "            If a < 1.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.power: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function is\n",
      "        \n",
      "        .. math:: P(x; a) = ax^{a-1}, 0 \\le x \\le 1, a>0.\n",
      "        \n",
      "        The power function distribution is just the inverse of the Pareto\n",
      "        distribution. It may also be seen as a special case of the Beta\n",
      "        distribution.\n",
      "        \n",
      "        It is used, for example, in modeling the over-reporting of insurance\n",
      "        claims.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Christian Kleiber, Samuel Kotz, \"Statistical size distributions\n",
      "               in economics and actuarial sciences\", Wiley, 2003.\n",
      "        .. [2] Heckert, N. A. and Filliben, James J. \"NIST Handbook 148:\n",
      "               Dataplot Reference Manual, Volume 2: Let Subcommands and Library\n",
      "               Functions\", National Institute of Standards and Technology\n",
      "               Handbook Series, June 2003.\n",
      "               https://www.itl.nist.gov/div898/software/dataplot/refman2/auxillar/powpdf.pdf\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> a = 5. # shape\n",
      "        >>> samples = 1000\n",
      "        >>> s = np.random.power(a, samples)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, bins=30)\n",
      "        >>> x = np.linspace(0, 1, 100)\n",
      "        >>> y = a*x**(a-1.)\n",
      "        >>> normed_y = samples*np.diff(bins)[0]*y\n",
      "        >>> plt.plot(x, normed_y)\n",
      "        >>> plt.show()\n",
      "        \n",
      "        Compare the power function distribution to the inverse of the Pareto.\n",
      "        \n",
      "        >>> from scipy import stats # doctest: +SKIP\n",
      "        >>> rvs = np.random.power(5, 1000000)\n",
      "        >>> rvsp = np.random.pareto(5, 1000000)\n",
      "        >>> xx = np.linspace(0,1,100)\n",
      "        >>> powpdf = stats.powerlaw.pdf(xx,5)  # doctest: +SKIP\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> plt.hist(rvs, bins=50, density=True)\n",
      "        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "        >>> plt.title('np.random.power(5)')\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "        >>> plt.title('inverse of 1 + np.random.pareto(5)')\n",
      "        \n",
      "        >>> plt.figure()\n",
      "        >>> plt.hist(1./(1.+rvsp), bins=50, density=True)\n",
      "        >>> plt.plot(xx,powpdf,'r-')  # doctest: +SKIP\n",
      "        >>> plt.title('inverse of stats.pareto(5)')\n",
      "    \n",
      "    rand(...) method of numpy.random.mtrand.RandomState instance\n",
      "        rand(d0, d1, ..., dn)\n",
      "        \n",
      "        Random values in a given shape.\n",
      "        \n",
      "        .. note::\n",
      "            This is a convenience function for users porting code from Matlab,\n",
      "            and wraps `random_sample`. That function takes a\n",
      "            tuple to specify the size of the output, which is consistent with\n",
      "            other NumPy functions like `numpy.zeros` and `numpy.ones`.\n",
      "        \n",
      "        Create an array of the given shape and populate it with\n",
      "        random samples from a uniform distribution\n",
      "        over ``[0, 1)``.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        d0, d1, ..., dn : int, optional\n",
      "            The dimensions of the returned array, must be non-negative.\n",
      "            If no argument is given a single Python float is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray, shape ``(d0, d1, ..., dn)``\n",
      "            Random values.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        random\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.rand(3,2)\n",
      "        array([[ 0.14022471,  0.96360618],  #random\n",
      "               [ 0.37601032,  0.25528411],  #random\n",
      "               [ 0.49313049,  0.94909878]]) #random\n",
      "    \n",
      "    randint(...) method of numpy.random.mtrand.RandomState instance\n",
      "        randint(low, high=None, size=None, dtype=int)\n",
      "        \n",
      "        Return random integers from `low` (inclusive) to `high` (exclusive).\n",
      "        \n",
      "        Return random integers from the \"discrete uniform\" distribution of\n",
      "        the specified dtype in the \"half-open\" interval [`low`, `high`). If\n",
      "        `high` is None (the default), then results are from [0, `low`).\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``integers`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        low : int or array-like of ints\n",
      "            Lowest (signed) integers to be drawn from the distribution (unless\n",
      "            ``high=None``, in which case this parameter is one above the\n",
      "            *highest* such integer).\n",
      "        high : int or array-like of ints, optional\n",
      "            If provided, one above the largest (signed) integer to be drawn\n",
      "            from the distribution (see above for behavior if ``high=None``).\n",
      "            If array-like, must contain integer values\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        dtype : dtype, optional\n",
      "            Desired dtype of the result. Byteorder must be native.\n",
      "            The default value is int.\n",
      "        \n",
      "            .. versionadded:: 1.11.0\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : int or ndarray of ints\n",
      "            `size`-shaped array of random integers from the appropriate\n",
      "            distribution, or a single such random int if `size` not provided.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        random_integers : similar to `randint`, only for the closed\n",
      "            interval [`low`, `high`], and 1 is the lowest value if `high` is\n",
      "            omitted.\n",
      "        Generator.integers: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.randint(2, size=10)\n",
      "        array([1, 0, 0, 0, 1, 1, 0, 0, 1, 0]) # random\n",
      "        >>> np.random.randint(1, size=10)\n",
      "        array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n",
      "        \n",
      "        Generate a 2 x 4 array of ints between 0 and 4, inclusive:\n",
      "        \n",
      "        >>> np.random.randint(5, size=(2, 4))\n",
      "        array([[4, 0, 2, 1], # random\n",
      "               [3, 2, 2, 0]])\n",
      "        \n",
      "        Generate a 1 x 3 array with 3 different upper bounds\n",
      "        \n",
      "        >>> np.random.randint(1, [3, 5, 10])\n",
      "        array([2, 2, 9]) # random\n",
      "        \n",
      "        Generate a 1 by 3 array with 3 different lower bounds\n",
      "        \n",
      "        >>> np.random.randint([1, 5, 7], 10)\n",
      "        array([9, 8, 7]) # random\n",
      "        \n",
      "        Generate a 2 by 4 array using broadcasting with dtype of uint8\n",
      "        \n",
      "        >>> np.random.randint([1, 3, 5, 7], [[10], [20]], dtype=np.uint8)\n",
      "        array([[ 8,  6,  9,  7], # random\n",
      "               [ 1, 16,  9, 12]], dtype=uint8)\n",
      "    \n",
      "    randn(...) method of numpy.random.mtrand.RandomState instance\n",
      "        randn(d0, d1, ..., dn)\n",
      "        \n",
      "        Return a sample (or samples) from the \"standard normal\" distribution.\n",
      "        \n",
      "        .. note::\n",
      "            This is a convenience function for users porting code from Matlab,\n",
      "            and wraps `standard_normal`. That function takes a\n",
      "            tuple to specify the size of the output, which is consistent with\n",
      "            other NumPy functions like `numpy.zeros` and `numpy.ones`.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_normal`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        If positive int_like arguments are provided, `randn` generates an array\n",
      "        of shape ``(d0, d1, ..., dn)``, filled\n",
      "        with random floats sampled from a univariate \"normal\" (Gaussian)\n",
      "        distribution of mean 0 and variance 1. A single float randomly sampled\n",
      "        from the distribution is returned if no argument is provided.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        d0, d1, ..., dn : int, optional\n",
      "            The dimensions of the returned array, must be non-negative.\n",
      "            If no argument is given a single Python float is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        Z : ndarray or float\n",
      "            A ``(d0, d1, ..., dn)``-shaped array of floating-point samples from\n",
      "            the standard normal distribution, or a single such float if\n",
      "            no parameters were supplied.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        standard_normal : Similar, but takes a tuple as its argument.\n",
      "        normal : Also accepts mu and sigma arguments.\n",
      "        Generator.standard_normal: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For random samples from :math:`N(\\mu, \\sigma^2)`, use:\n",
      "        \n",
      "        ``sigma * np.random.randn(...) + mu``\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.randn()\n",
      "        2.1923875335537315  # random\n",
      "        \n",
      "        Two-by-four array of samples from N(3, 6.25):\n",
      "        \n",
      "        >>> 3 + 2.5 * np.random.randn(2, 4)\n",
      "        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "    \n",
      "    random(...) method of numpy.random.mtrand.RandomState instance\n",
      "        random(size=None)\n",
      "        \n",
      "        Return random floats in the half-open interval [0.0, 1.0). Alias for\n",
      "        `random_sample` to ease forward-porting to the new random API.\n",
      "    \n",
      "    random_integers(...) method of numpy.random.mtrand.RandomState instance\n",
      "        random_integers(low, high=None, size=None)\n",
      "        \n",
      "        Random integers of type `np.int_` between `low` and `high`, inclusive.\n",
      "        \n",
      "        Return random integers of type `np.int_` from the \"discrete uniform\"\n",
      "        distribution in the closed interval [`low`, `high`].  If `high` is\n",
      "        None (the default), then results are from [1, `low`]. The `np.int_`\n",
      "        type translates to the C long integer type and its precision\n",
      "        is platform dependent.\n",
      "        \n",
      "        This function has been deprecated. Use randint instead.\n",
      "        \n",
      "        .. deprecated:: 1.11.0\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        low : int\n",
      "            Lowest (signed) integer to be drawn from the distribution (unless\n",
      "            ``high=None``, in which case this parameter is the *highest* such\n",
      "            integer).\n",
      "        high : int, optional\n",
      "            If provided, the largest (signed) integer to be drawn from the\n",
      "            distribution (see above for behavior if ``high=None``).\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : int or ndarray of ints\n",
      "            `size`-shaped array of random integers from the appropriate\n",
      "            distribution, or a single such random int if `size` not provided.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        randint : Similar to `random_integers`, only for the half-open\n",
      "            interval [`low`, `high`), and 0 is the lowest value if `high` is\n",
      "            omitted.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        To sample from N evenly spaced floating-point numbers between a and b,\n",
      "        use::\n",
      "        \n",
      "          a + (b - a) * (np.random.random_integers(N) - 1) / (N - 1.)\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.random_integers(5)\n",
      "        4 # random\n",
      "        >>> type(np.random.random_integers(5))\n",
      "        <class 'numpy.int64'>\n",
      "        >>> np.random.random_integers(5, size=(3,2))\n",
      "        array([[5, 4], # random\n",
      "               [3, 3],\n",
      "               [4, 5]])\n",
      "        \n",
      "        Choose five random numbers from the set of five evenly-spaced\n",
      "        numbers between 0 and 2.5, inclusive (*i.e.*, from the set\n",
      "        :math:`{0, 5/8, 10/8, 15/8, 20/8}`):\n",
      "        \n",
      "        >>> 2.5 * (np.random.random_integers(5, size=(5,)) - 1) / 4.\n",
      "        array([ 0.625,  1.25 ,  0.625,  0.625,  2.5  ]) # random\n",
      "        \n",
      "        Roll two six sided dice 1000 times and sum the results:\n",
      "        \n",
      "        >>> d1 = np.random.random_integers(1, 6, 1000)\n",
      "        >>> d2 = np.random.random_integers(1, 6, 1000)\n",
      "        >>> dsums = d1 + d2\n",
      "        \n",
      "        Display results as a histogram:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(dsums, 11, density=True)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    random_sample(...) method of numpy.random.mtrand.RandomState instance\n",
      "        random_sample(size=None)\n",
      "        \n",
      "        Return random floats in the half-open interval [0.0, 1.0).\n",
      "        \n",
      "        Results are from the \"continuous uniform\" distribution over the\n",
      "        stated interval.  To sample :math:`Unif[a, b), b > a` multiply\n",
      "        the output of `random_sample` by `(b-a)` and add `a`::\n",
      "        \n",
      "          (b - a) * random_sample() + a\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``random`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : float or ndarray of floats\n",
      "            Array of random floats of shape `size` (unless ``size=None``, in which\n",
      "            case a single float is returned).\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.random: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.random_sample()\n",
      "        0.47108547995356098 # random\n",
      "        >>> type(np.random.random_sample())\n",
      "        <class 'float'>\n",
      "        >>> np.random.random_sample((5,))\n",
      "        array([ 0.30220482,  0.86820401,  0.1654503 ,  0.11659149,  0.54323428]) # random\n",
      "        \n",
      "        Three-by-two array of random numbers from [-5, 0):\n",
      "        \n",
      "        >>> 5 * np.random.random_sample((3, 2)) - 5\n",
      "        array([[-3.99149989, -0.52338984], # random\n",
      "               [-2.99091858, -0.79479508],\n",
      "               [-1.23204345, -1.75224494]])\n",
      "    \n",
      "    ranf(...)\n",
      "        This is an alias of `random_sample`. See `random_sample`  for the complete\n",
      "        documentation.\n",
      "    \n",
      "    rayleigh(...) method of numpy.random.mtrand.RandomState instance\n",
      "        rayleigh(scale=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a Rayleigh distribution.\n",
      "        \n",
      "        The :math:`\\chi` and Weibull distributions are generalizations of the\n",
      "        Rayleigh.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``rayleigh`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        scale : float or array_like of floats, optional\n",
      "            Scale, also equals the mode. Must be non-negative. Default is 1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``scale`` is a scalar.  Otherwise,\n",
      "            ``np.array(scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Rayleigh distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.rayleigh: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the Rayleigh distribution is\n",
      "        \n",
      "        .. math:: P(x;scale) = \\frac{x}{scale^2}e^{\\frac{-x^2}{2 \\cdotp scale^2}}\n",
      "        \n",
      "        The Rayleigh distribution would arise, for example, if the East\n",
      "        and North components of the wind velocity had identical zero-mean\n",
      "        Gaussian distributions.  Then the wind speed would have a Rayleigh\n",
      "        distribution.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Brighton Webs Ltd., \"Rayleigh Distribution,\"\n",
      "               https://web.archive.org/web/20090514091424/http://brighton-webs.co.uk:80/distributions/rayleigh.asp\n",
      "        .. [2] Wikipedia, \"Rayleigh distribution\"\n",
      "               https://en.wikipedia.org/wiki/Rayleigh_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw values from the distribution and plot the histogram\n",
      "        \n",
      "        >>> from matplotlib.pyplot import hist\n",
      "        >>> values = hist(np.random.rayleigh(3, 100000), bins=200, density=True)\n",
      "        \n",
      "        Wave heights tend to follow a Rayleigh distribution. If the mean wave\n",
      "        height is 1 meter, what fraction of waves are likely to be larger than 3\n",
      "        meters?\n",
      "        \n",
      "        >>> meanvalue = 1\n",
      "        >>> modevalue = np.sqrt(2 / np.pi) * meanvalue\n",
      "        >>> s = np.random.rayleigh(modevalue, 1000000)\n",
      "        \n",
      "        The percentage of waves larger than 3 meters is:\n",
      "        \n",
      "        >>> 100.*sum(s>3)/1000000.\n",
      "        0.087300000000000003 # random\n",
      "    \n",
      "    sample(...)\n",
      "        This is an alias of `random_sample`. See `random_sample`  for the complete\n",
      "        documentation.\n",
      "    \n",
      "    seed(...) method of numpy.random.mtrand.RandomState instance\n",
      "        seed(self, seed=None)\n",
      "        \n",
      "        Reseed a legacy MT19937 BitGenerator\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        This is a convenience, legacy function.\n",
      "        \n",
      "        The best practice is to **not** reseed a BitGenerator, rather to\n",
      "        recreate a new one. This method is here for legacy reasons.\n",
      "        This example demonstrates best practice.\n",
      "        \n",
      "        >>> from numpy.random import MT19937\n",
      "        >>> from numpy.random import RandomState, SeedSequence\n",
      "        >>> rs = RandomState(MT19937(SeedSequence(123456789)))\n",
      "        # Later, you want to restart the stream\n",
      "        >>> rs = RandomState(MT19937(SeedSequence(987654321)))\n",
      "    \n",
      "    set_state(...) method of numpy.random.mtrand.RandomState instance\n",
      "        set_state(state)\n",
      "        \n",
      "        Set the internal state of the generator from a tuple.\n",
      "        \n",
      "        For use if one has reason to manually (re-)set the internal state of\n",
      "        the bit generator used by the RandomState instance. By default,\n",
      "        RandomState uses the \"Mersenne Twister\"[1]_ pseudo-random number\n",
      "        generating algorithm.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        state : {tuple(str, ndarray of 624 uints, int, int, float), dict}\n",
      "            The `state` tuple has the following items:\n",
      "        \n",
      "            1. the string 'MT19937', specifying the Mersenne Twister algorithm.\n",
      "            2. a 1-D array of 624 unsigned integers ``keys``.\n",
      "            3. an integer ``pos``.\n",
      "            4. an integer ``has_gauss``.\n",
      "            5. a float ``cached_gaussian``.\n",
      "        \n",
      "            If state is a dictionary, it is directly set using the BitGenerators\n",
      "            `state` property.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : None\n",
      "            Returns 'None' on success.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        get_state\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        `set_state` and `get_state` are not needed to work with any of the\n",
      "        random distributions in NumPy. If the internal state is manually altered,\n",
      "        the user should know exactly what he/she is doing.\n",
      "        \n",
      "        For backwards compatibility, the form (str, array of 624 uints, int) is\n",
      "        also accepted although it is missing some information about the cached\n",
      "        Gaussian value: ``state = ('MT19937', keys, pos)``.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] M. Matsumoto and T. Nishimura, \"Mersenne Twister: A\n",
      "           623-dimensionally equidistributed uniform pseudorandom number\n",
      "           generator,\" *ACM Trans. on Modeling and Computer Simulation*,\n",
      "           Vol. 8, No. 1, pp. 3-30, Jan. 1998.\n",
      "    \n",
      "    shuffle(...) method of numpy.random.mtrand.RandomState instance\n",
      "        shuffle(x)\n",
      "        \n",
      "        Modify a sequence in-place by shuffling its contents.\n",
      "        \n",
      "        This function only shuffles the array along the first axis of a\n",
      "        multi-dimensional array. The order of sub-arrays is changed but\n",
      "        their contents remains the same.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``shuffle`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        x : array_like\n",
      "            The array or list to be shuffled.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        None\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.shuffle: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> arr = np.arange(10)\n",
      "        >>> np.random.shuffle(arr)\n",
      "        >>> arr\n",
      "        [1 7 5 2 9 4 3 6 0 8] # random\n",
      "        \n",
      "        Multi-dimensional arrays are only shuffled along the first axis:\n",
      "        \n",
      "        >>> arr = np.arange(9).reshape((3, 3))\n",
      "        >>> np.random.shuffle(arr)\n",
      "        >>> arr\n",
      "        array([[3, 4, 5], # random\n",
      "               [6, 7, 8],\n",
      "               [0, 1, 2]])\n",
      "    \n",
      "    standard_cauchy(...) method of numpy.random.mtrand.RandomState instance\n",
      "        standard_cauchy(size=None)\n",
      "        \n",
      "        Draw samples from a standard Cauchy distribution with mode = 0.\n",
      "        \n",
      "        Also known as the Lorentz distribution.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_cauchy`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        samples : ndarray or scalar\n",
      "            The drawn samples.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.standard_cauchy: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the full Cauchy distribution is\n",
      "        \n",
      "        .. math:: P(x; x_0, \\gamma) = \\frac{1}{\\pi \\gamma \\bigl[ 1+\n",
      "                  (\\frac{x-x_0}{\\gamma})^2 \\bigr] }\n",
      "        \n",
      "        and the Standard Cauchy distribution just sets :math:`x_0=0` and\n",
      "        :math:`\\gamma=1`\n",
      "        \n",
      "        The Cauchy distribution arises in the solution to the driven harmonic\n",
      "        oscillator problem, and also describes spectral line broadening. It\n",
      "        also describes the distribution of values at which a line tilted at\n",
      "        a random angle will cut the x axis.\n",
      "        \n",
      "        When studying hypothesis tests that assume normality, seeing how the\n",
      "        tests perform on data from a Cauchy distribution is a good indicator of\n",
      "        their sensitivity to a heavy-tailed distribution, since the Cauchy looks\n",
      "        very much like a Gaussian distribution, but with heavier tails.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] NIST/SEMATECH e-Handbook of Statistical Methods, \"Cauchy\n",
      "              Distribution\",\n",
      "              https://www.itl.nist.gov/div898/handbook/eda/section3/eda3663.htm\n",
      "        .. [2] Weisstein, Eric W. \"Cauchy Distribution.\" From MathWorld--A\n",
      "              Wolfram Web Resource.\n",
      "              http://mathworld.wolfram.com/CauchyDistribution.html\n",
      "        .. [3] Wikipedia, \"Cauchy distribution\"\n",
      "              https://en.wikipedia.org/wiki/Cauchy_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples and plot the distribution:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> s = np.random.standard_cauchy(1000000)\n",
      "        >>> s = s[(s>-25) & (s<25)]  # truncate distribution so it plots well\n",
      "        >>> plt.hist(s, bins=100)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    standard_exponential(...) method of numpy.random.mtrand.RandomState instance\n",
      "        standard_exponential(size=None)\n",
      "        \n",
      "        Draw samples from the standard exponential distribution.\n",
      "        \n",
      "        `standard_exponential` is identical to the exponential distribution\n",
      "        with a scale parameter of 1.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_exponential`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : float or ndarray\n",
      "            Drawn samples.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.standard_exponential: which should be used for new code.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Output a 3x8000 array:\n",
      "        \n",
      "        >>> n = np.random.standard_exponential((3, 8000))\n",
      "    \n",
      "    standard_gamma(...) method of numpy.random.mtrand.RandomState instance\n",
      "        standard_gamma(shape, size=None)\n",
      "        \n",
      "        Draw samples from a standard Gamma distribution.\n",
      "        \n",
      "        Samples are drawn from a Gamma distribution with specified parameters,\n",
      "        shape (sometimes designated \"k\") and scale=1.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_gamma`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        shape : float or array_like of floats\n",
      "            Parameter, must be non-negative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``shape`` is a scalar.  Otherwise,\n",
      "            ``np.array(shape).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized standard gamma distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.gamma : probability density function, distribution or\n",
      "            cumulative density function, etc.\n",
      "        Generator.standard_gamma: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Gamma distribution is\n",
      "        \n",
      "        .. math:: p(x) = x^{k-1}\\frac{e^{-x/\\theta}}{\\theta^k\\Gamma(k)},\n",
      "        \n",
      "        where :math:`k` is the shape and :math:`\\theta` the scale,\n",
      "        and :math:`\\Gamma` is the Gamma function.\n",
      "        \n",
      "        The Gamma distribution is often used to model the times to failure of\n",
      "        electronic components, and arises naturally in processes for which the\n",
      "        waiting times between Poisson distributed events are relevant.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Weisstein, Eric W. \"Gamma Distribution.\" From MathWorld--A\n",
      "               Wolfram Web Resource.\n",
      "               http://mathworld.wolfram.com/GammaDistribution.html\n",
      "        .. [2] Wikipedia, \"Gamma distribution\",\n",
      "               https://en.wikipedia.org/wiki/Gamma_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> shape, scale = 2., 1. # mean and width\n",
      "        >>> s = np.random.standard_gamma(shape, 1000000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> import scipy.special as sps  # doctest: +SKIP\n",
      "        >>> count, bins, ignored = plt.hist(s, 50, density=True)\n",
      "        >>> y = bins**(shape-1) * ((np.exp(-bins/scale))/  # doctest: +SKIP\n",
      "        ...                       (sps.gamma(shape) * scale**shape))\n",
      "        >>> plt.plot(bins, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "        >>> plt.show()\n",
      "    \n",
      "    standard_normal(...) method of numpy.random.mtrand.RandomState instance\n",
      "        standard_normal(size=None)\n",
      "        \n",
      "        Draw samples from a standard Normal distribution (mean=0, stdev=1).\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_normal`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  Default is None, in which case a\n",
      "            single value is returned.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : float or ndarray\n",
      "            A floating-point array of shape ``size`` of drawn samples, or a\n",
      "            single sample if ``size`` was not specified.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        normal :\n",
      "            Equivalent function with additional ``loc`` and ``scale`` arguments\n",
      "            for setting the mean and standard deviation.\n",
      "        Generator.standard_normal: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        For random samples from :math:`N(\\mu, \\sigma^2)`, use one of::\n",
      "        \n",
      "            mu + sigma * np.random.standard_normal(size=...)\n",
      "            np.random.normal(mu, sigma, size=...)\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        >>> np.random.standard_normal()\n",
      "        2.1923875335537315 #random\n",
      "        \n",
      "        >>> s = np.random.standard_normal(8000)\n",
      "        >>> s\n",
      "        array([ 0.6888893 ,  0.78096262, -0.89086505, ...,  0.49876311,  # random\n",
      "               -0.38672696, -0.4685006 ])                                # random\n",
      "        >>> s.shape\n",
      "        (8000,)\n",
      "        >>> s = np.random.standard_normal(size=(3, 4, 2))\n",
      "        >>> s.shape\n",
      "        (3, 4, 2)\n",
      "        \n",
      "        Two-by-four array of samples from :math:`N(3, 6.25)`:\n",
      "        \n",
      "        >>> 3 + 2.5 * np.random.standard_normal(size=(2, 4))\n",
      "        array([[-4.49401501,  4.00950034, -1.81814867,  7.29718677],   # random\n",
      "               [ 0.39924804,  4.68456316,  4.99394529,  4.84057254]])  # random\n",
      "    \n",
      "    standard_t(...) method of numpy.random.mtrand.RandomState instance\n",
      "        standard_t(df, size=None)\n",
      "        \n",
      "        Draw samples from a standard Student's t distribution with `df` degrees\n",
      "        of freedom.\n",
      "        \n",
      "        A special case of the hyperbolic distribution.  As `df` gets\n",
      "        large, the result resembles that of the standard normal\n",
      "        distribution (`standard_normal`).\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``standard_t`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        df : float or array_like of floats\n",
      "            Degrees of freedom, must be > 0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``df`` is a scalar.  Otherwise,\n",
      "            ``np.array(df).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized standard Student's t distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.standard_t: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the t distribution is\n",
      "        \n",
      "        .. math:: P(x, df) = \\frac{\\Gamma(\\frac{df+1}{2})}{\\sqrt{\\pi df}\n",
      "                  \\Gamma(\\frac{df}{2})}\\Bigl( 1+\\frac{x^2}{df} \\Bigr)^{-(df+1)/2}\n",
      "        \n",
      "        The t test is based on an assumption that the data come from a\n",
      "        Normal distribution. The t test provides a way to test whether\n",
      "        the sample mean (that is the mean calculated from the data) is\n",
      "        a good estimate of the true mean.\n",
      "        \n",
      "        The derivation of the t-distribution was first published in\n",
      "        1908 by William Gosset while working for the Guinness Brewery\n",
      "        in Dublin. Due to proprietary issues, he had to publish under\n",
      "        a pseudonym, and so he used the name Student.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Dalgaard, Peter, \"Introductory Statistics With R\",\n",
      "               Springer, 2002.\n",
      "        .. [2] Wikipedia, \"Student's t-distribution\"\n",
      "               https://en.wikipedia.org/wiki/Student's_t-distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        From Dalgaard page 83 [1]_, suppose the daily energy intake for 11\n",
      "        women in kilojoules (kJ) is:\n",
      "        \n",
      "        >>> intake = np.array([5260., 5470, 5640, 6180, 6390, 6515, 6805, 7515, \\\n",
      "        ...                    7515, 8230, 8770])\n",
      "        \n",
      "        Does their energy intake deviate systematically from the recommended\n",
      "        value of 7725 kJ?\n",
      "        \n",
      "        We have 10 degrees of freedom, so is the sample mean within 95% of the\n",
      "        recommended value?\n",
      "        \n",
      "        >>> s = np.random.standard_t(10, size=100000)\n",
      "        >>> np.mean(intake)\n",
      "        6753.636363636364\n",
      "        >>> intake.std(ddof=1)\n",
      "        1142.1232221373727\n",
      "        \n",
      "        Calculate the t statistic, setting the ddof parameter to the unbiased\n",
      "        value so the divisor in the standard deviation will be degrees of\n",
      "        freedom, N-1.\n",
      "        \n",
      "        >>> t = (np.mean(intake)-7725)/(intake.std(ddof=1)/np.sqrt(len(intake)))\n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> h = plt.hist(s, bins=100, density=True)\n",
      "        \n",
      "        For a one-sided t-test, how far out in the distribution does the t\n",
      "        statistic appear?\n",
      "        \n",
      "        >>> np.sum(s<t) / float(len(s))\n",
      "        0.0090699999999999999  #random\n",
      "        \n",
      "        So the p-value is about 0.009, which says the null hypothesis has a\n",
      "        probability of about 99% of being true.\n",
      "    \n",
      "    triangular(...) method of numpy.random.mtrand.RandomState instance\n",
      "        triangular(left, mode, right, size=None)\n",
      "        \n",
      "        Draw samples from the triangular distribution over the\n",
      "        interval ``[left, right]``.\n",
      "        \n",
      "        The triangular distribution is a continuous probability\n",
      "        distribution with lower limit left, peak at mode, and upper\n",
      "        limit right. Unlike the other distributions, these parameters\n",
      "        directly define the shape of the pdf.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``triangular`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        left : float or array_like of floats\n",
      "            Lower limit.\n",
      "        mode : float or array_like of floats\n",
      "            The value where the peak of the distribution occurs.\n",
      "            The value must fulfill the condition ``left <= mode <= right``.\n",
      "        right : float or array_like of floats\n",
      "            Upper limit, must be larger than `left`.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``left``, ``mode``, and ``right``\n",
      "            are all scalars.  Otherwise, ``np.broadcast(left, mode, right).size``\n",
      "            samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized triangular distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.triangular: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the triangular distribution is\n",
      "        \n",
      "        .. math:: P(x;l, m, r) = \\begin{cases}\n",
      "                  \\frac{2(x-l)}{(r-l)(m-l)}& \\text{for $l \\leq x \\leq m$},\\\\\n",
      "                  \\frac{2(r-x)}{(r-l)(r-m)}& \\text{for $m \\leq x \\leq r$},\\\\\n",
      "                  0& \\text{otherwise}.\n",
      "                  \\end{cases}\n",
      "        \n",
      "        The triangular distribution is often used in ill-defined\n",
      "        problems where the underlying distribution is not known, but\n",
      "        some knowledge of the limits and mode exists. Often it is used\n",
      "        in simulations.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Wikipedia, \"Triangular distribution\"\n",
      "               https://en.wikipedia.org/wiki/Triangular_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw values from the distribution and plot the histogram:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> h = plt.hist(np.random.triangular(-3, 0, 8, 100000), bins=200,\n",
      "        ...              density=True)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    uniform(...) method of numpy.random.mtrand.RandomState instance\n",
      "        uniform(low=0.0, high=1.0, size=None)\n",
      "        \n",
      "        Draw samples from a uniform distribution.\n",
      "        \n",
      "        Samples are uniformly distributed over the half-open interval\n",
      "        ``[low, high)`` (includes low, but excludes high).  In other words,\n",
      "        any value within the given interval is equally likely to be drawn\n",
      "        by `uniform`.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``uniform`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        low : float or array_like of floats, optional\n",
      "            Lower boundary of the output interval.  All values generated will be\n",
      "            greater than or equal to low.  The default value is 0.\n",
      "        high : float or array_like of floats\n",
      "            Upper boundary of the output interval.  All values generated will be\n",
      "            less than high.  The default value is 1.0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``low`` and ``high`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(low, high).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized uniform distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        randint : Discrete uniform distribution, yielding integers.\n",
      "        random_integers : Discrete uniform distribution over the closed\n",
      "                          interval ``[low, high]``.\n",
      "        random_sample : Floats uniformly distributed over ``[0, 1)``.\n",
      "        random : Alias for `random_sample`.\n",
      "        rand : Convenience function that accepts dimensions as input, e.g.,\n",
      "               ``rand(2,2)`` would generate a 2-by-2 array of floats,\n",
      "               uniformly distributed over ``[0, 1)``.\n",
      "        Generator.uniform: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function of the uniform distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{1}{b - a}\n",
      "        \n",
      "        anywhere within the interval ``[a, b)``, and zero elsewhere.\n",
      "        \n",
      "        When ``high`` == ``low``, values of ``low`` will be returned.\n",
      "        If ``high`` < ``low``, the results are officially undefined\n",
      "        and may eventually raise an error, i.e. do not rely on this\n",
      "        function to behave when passed arguments satisfying that\n",
      "        inequality condition.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> s = np.random.uniform(-1,0,1000)\n",
      "        \n",
      "        All values are within the given interval:\n",
      "        \n",
      "        >>> np.all(s >= -1)\n",
      "        True\n",
      "        >>> np.all(s < 0)\n",
      "        True\n",
      "        \n",
      "        Display the histogram of the samples, along with the\n",
      "        probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> count, bins, ignored = plt.hist(s, 15, density=True)\n",
      "        >>> plt.plot(bins, np.ones_like(bins), linewidth=2, color='r')\n",
      "        >>> plt.show()\n",
      "    \n",
      "    vonmises(...) method of numpy.random.mtrand.RandomState instance\n",
      "        vonmises(mu, kappa, size=None)\n",
      "        \n",
      "        Draw samples from a von Mises distribution.\n",
      "        \n",
      "        Samples are drawn from a von Mises distribution with specified mode\n",
      "        (mu) and dispersion (kappa), on the interval [-pi, pi].\n",
      "        \n",
      "        The von Mises distribution (also known as the circular normal\n",
      "        distribution) is a continuous probability distribution on the unit\n",
      "        circle.  It may be thought of as the circular analogue of the normal\n",
      "        distribution.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``vonmises`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mu : float or array_like of floats\n",
      "            Mode (\"center\") of the distribution.\n",
      "        kappa : float or array_like of floats\n",
      "            Dispersion of the distribution, has to be >=0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``mu`` and ``kappa`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(mu, kappa).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized von Mises distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.vonmises : probability density function, distribution, or\n",
      "            cumulative density function, etc.\n",
      "        Generator.vonmises: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the von Mises distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{e^{\\kappa cos(x-\\mu)}}{2\\pi I_0(\\kappa)},\n",
      "        \n",
      "        where :math:`\\mu` is the mode and :math:`\\kappa` the dispersion,\n",
      "        and :math:`I_0(\\kappa)` is the modified Bessel function of order 0.\n",
      "        \n",
      "        The von Mises is named for Richard Edler von Mises, who was born in\n",
      "        Austria-Hungary, in what is now the Ukraine.  He fled to the United\n",
      "        States in 1939 and became a professor at Harvard.  He worked in\n",
      "        probability theory, aerodynamics, fluid mechanics, and philosophy of\n",
      "        science.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Abramowitz, M. and Stegun, I. A. (Eds.). \"Handbook of\n",
      "               Mathematical Functions with Formulas, Graphs, and Mathematical\n",
      "               Tables, 9th printing,\" New York: Dover, 1972.\n",
      "        .. [2] von Mises, R., \"Mathematical Theory of Probability\n",
      "               and Statistics\", New York: Academic Press, 1964.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> mu, kappa = 0.0, 4.0 # mean and dispersion\n",
      "        >>> s = np.random.vonmises(mu, kappa, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from scipy.special import i0  # doctest: +SKIP\n",
      "        >>> plt.hist(s, 50, density=True)\n",
      "        >>> x = np.linspace(-np.pi, np.pi, num=51)\n",
      "        >>> y = np.exp(kappa*np.cos(x-mu))/(2*np.pi*i0(kappa))  # doctest: +SKIP\n",
      "        >>> plt.plot(x, y, linewidth=2, color='r')  # doctest: +SKIP\n",
      "        >>> plt.show()\n",
      "    \n",
      "    wald(...) method of numpy.random.mtrand.RandomState instance\n",
      "        wald(mean, scale, size=None)\n",
      "        \n",
      "        Draw samples from a Wald, or inverse Gaussian, distribution.\n",
      "        \n",
      "        As the scale approaches infinity, the distribution becomes more like a\n",
      "        Gaussian. Some references claim that the Wald is an inverse Gaussian\n",
      "        with mean equal to 1, but this is by no means universal.\n",
      "        \n",
      "        The inverse Gaussian distribution was first studied in relationship to\n",
      "        Brownian motion. In 1956 M.C.K. Tweedie used the name inverse Gaussian\n",
      "        because there is an inverse relationship between the time to cover a\n",
      "        unit distance and distance covered in unit time.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``wald`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        mean : float or array_like of floats\n",
      "            Distribution mean, must be > 0.\n",
      "        scale : float or array_like of floats\n",
      "            Scale parameter, must be > 0.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``mean`` and ``scale`` are both scalars.\n",
      "            Otherwise, ``np.broadcast(mean, scale).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Wald distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        Generator.wald: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density function for the Wald distribution is\n",
      "        \n",
      "        .. math:: P(x;mean,scale) = \\sqrt{\\frac{scale}{2\\pi x^3}}e^\n",
      "                                    \\frac{-scale(x-mean)^2}{2\\cdotp mean^2x}\n",
      "        \n",
      "        As noted above the inverse Gaussian distribution first arise\n",
      "        from attempts to model Brownian motion. It is also a\n",
      "        competitor to the Weibull for use in reliability modeling and\n",
      "        modeling stock returns and interest rate processes.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Brighton Webs Ltd., Wald Distribution,\n",
      "               https://web.archive.org/web/20090423014010/http://www.brighton-webs.co.uk:80/distributions/wald.asp\n",
      "        .. [2] Chhikara, Raj S., and Folks, J. Leroy, \"The Inverse Gaussian\n",
      "               Distribution: Theory : Methodology, and Applications\", CRC Press,\n",
      "               1988.\n",
      "        .. [3] Wikipedia, \"Inverse Gaussian distribution\"\n",
      "               https://en.wikipedia.org/wiki/Inverse_Gaussian_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw values from the distribution and plot the histogram:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> h = plt.hist(np.random.wald(3, 2, 100000), bins=200, density=True)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    weibull(...) method of numpy.random.mtrand.RandomState instance\n",
      "        weibull(a, size=None)\n",
      "        \n",
      "        Draw samples from a Weibull distribution.\n",
      "        \n",
      "        Draw samples from a 1-parameter Weibull distribution with the given\n",
      "        shape parameter `a`.\n",
      "        \n",
      "        .. math:: X = (-ln(U))^{1/a}\n",
      "        \n",
      "        Here, U is drawn from the uniform distribution over (0,1].\n",
      "        \n",
      "        The more common 2-parameter Weibull, including a scale parameter\n",
      "        :math:`\\lambda` is just :math:`X = \\lambda(-ln(U))^{1/a}`.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``weibull`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : float or array_like of floats\n",
      "            Shape parameter of the distribution.  Must be nonnegative.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``a`` is a scalar.  Otherwise,\n",
      "            ``np.array(a).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Weibull distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.weibull_max\n",
      "        scipy.stats.weibull_min\n",
      "        scipy.stats.genextreme\n",
      "        gumbel\n",
      "        Generator.weibull: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The Weibull (or Type III asymptotic extreme value distribution\n",
      "        for smallest values, SEV Type III, or Rosin-Rammler\n",
      "        distribution) is one of a class of Generalized Extreme Value\n",
      "        (GEV) distributions used in modeling extreme value problems.\n",
      "        This class includes the Gumbel and Frechet distributions.\n",
      "        \n",
      "        The probability density for the Weibull distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{a}\n",
      "                         {\\lambda}(\\frac{x}{\\lambda})^{a-1}e^{-(x/\\lambda)^a},\n",
      "        \n",
      "        where :math:`a` is the shape and :math:`\\lambda` the scale.\n",
      "        \n",
      "        The function has its peak (the mode) at\n",
      "        :math:`\\lambda(\\frac{a-1}{a})^{1/a}`.\n",
      "        \n",
      "        When ``a = 1``, the Weibull distribution reduces to the exponential\n",
      "        distribution.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Waloddi Weibull, Royal Technical University, Stockholm,\n",
      "               1939 \"A Statistical Theory Of The Strength Of Materials\",\n",
      "               Ingeniorsvetenskapsakademiens Handlingar Nr 151, 1939,\n",
      "               Generalstabens Litografiska Anstalts Forlag, Stockholm.\n",
      "        .. [2] Waloddi Weibull, \"A Statistical Distribution Function of\n",
      "               Wide Applicability\", Journal Of Applied Mechanics ASME Paper\n",
      "               1951.\n",
      "        .. [3] Wikipedia, \"Weibull distribution\",\n",
      "               https://en.wikipedia.org/wiki/Weibull_distribution\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> a = 5. # shape\n",
      "        >>> s = np.random.weibull(a, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> x = np.arange(1,100.)/50.\n",
      "        >>> def weib(x,n,a):\n",
      "        ...     return (a / n) * (x / n)**(a - 1) * np.exp(-(x / n)**a)\n",
      "        \n",
      "        >>> count, bins, ignored = plt.hist(np.random.weibull(5.,1000))\n",
      "        >>> x = np.arange(1,100.)/50.\n",
      "        >>> scale = count.max()/weib(x, 1., 5.).max()\n",
      "        >>> plt.plot(x, weib(x, 1., 5.)*scale)\n",
      "        >>> plt.show()\n",
      "    \n",
      "    zipf(...) method of numpy.random.mtrand.RandomState instance\n",
      "        zipf(a, size=None)\n",
      "        \n",
      "        Draw samples from a Zipf distribution.\n",
      "        \n",
      "        Samples are drawn from a Zipf distribution with specified parameter\n",
      "        `a` > 1.\n",
      "        \n",
      "        The Zipf distribution (also known as the zeta distribution) is a\n",
      "        continuous probability distribution that satisfies Zipf's law: the\n",
      "        frequency of an item is inversely proportional to its rank in a\n",
      "        frequency table.\n",
      "        \n",
      "        .. note::\n",
      "            New code should use the ``zipf`` method of a ``default_rng()``\n",
      "            instance instead; see `random-quick-start`.\n",
      "        \n",
      "        Parameters\n",
      "        ----------\n",
      "        a : float or array_like of floats\n",
      "            Distribution parameter. Must be greater than 1.\n",
      "        size : int or tuple of ints, optional\n",
      "            Output shape.  If the given shape is, e.g., ``(m, n, k)``, then\n",
      "            ``m * n * k`` samples are drawn.  If size is ``None`` (default),\n",
      "            a single value is returned if ``a`` is a scalar. Otherwise,\n",
      "            ``np.array(a).size`` samples are drawn.\n",
      "        \n",
      "        Returns\n",
      "        -------\n",
      "        out : ndarray or scalar\n",
      "            Drawn samples from the parameterized Zipf distribution.\n",
      "        \n",
      "        See Also\n",
      "        --------\n",
      "        scipy.stats.zipf : probability density function, distribution, or\n",
      "            cumulative density function, etc.\n",
      "        Generator.zipf: which should be used for new code.\n",
      "        \n",
      "        Notes\n",
      "        -----\n",
      "        The probability density for the Zipf distribution is\n",
      "        \n",
      "        .. math:: p(x) = \\frac{x^{-a}}{\\zeta(a)},\n",
      "        \n",
      "        where :math:`\\zeta` is the Riemann Zeta function.\n",
      "        \n",
      "        It is named for the American linguist George Kingsley Zipf, who noted\n",
      "        that the frequency of any word in a sample of a language is inversely\n",
      "        proportional to its rank in the frequency table.\n",
      "        \n",
      "        References\n",
      "        ----------\n",
      "        .. [1] Zipf, G. K., \"Selected Studies of the Principle of Relative\n",
      "               Frequency in Language,\" Cambridge, MA: Harvard Univ. Press,\n",
      "               1932.\n",
      "        \n",
      "        Examples\n",
      "        --------\n",
      "        Draw samples from the distribution:\n",
      "        \n",
      "        >>> a = 2. # parameter\n",
      "        >>> s = np.random.zipf(a, 1000)\n",
      "        \n",
      "        Display the histogram of the samples, along with\n",
      "        the probability density function:\n",
      "        \n",
      "        >>> import matplotlib.pyplot as plt\n",
      "        >>> from scipy import special  # doctest: +SKIP\n",
      "        \n",
      "        Truncate s values at 50 so plot is interesting:\n",
      "        \n",
      "        >>> count, bins, ignored = plt.hist(s[s<50], 50, density=True)\n",
      "        >>> x = np.arange(1., 50.)\n",
      "        >>> y = x**(-a) / special.zetac(a)  # doctest: +SKIP\n",
      "        >>> plt.plot(x, y/max(y), linewidth=2, color='r')  # doctest: +SKIP\n",
      "        >>> plt.show()\n",
      "\n",
      "DATA\n",
      "    __all__ = ['beta', 'binomial', 'bytes', 'chisquare', 'choice', 'dirich...\n",
      "\n",
      "FILE\n",
      "    c:\\users\\pierr\\anaconda3\\lib\\site-packages\\numpy\\random\\__init__.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(rd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
